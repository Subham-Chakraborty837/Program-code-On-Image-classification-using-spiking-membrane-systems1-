{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDixk71bDGjd5gBAk5LQ9U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4KBBxRP3Lu42"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","N_CLASS_INDEX = 13\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'N'\n","# ------------------------\n","def encode_letter_N():\n","    grid = np.array([\n","    [1, 0, 0, 0, 1],\n","    [1, 1, 0, 0, 1],\n","    [1, 0, 1, 0, 1],\n","    [1, 0, 0, 1, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_N()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([N_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_N = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_N = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_N)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_N()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == N_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == N_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_N()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"e3d1200d-c504-4d90-a7d8-8632b638154e","executionInfo":{"status":"ok","timestamp":1764574216660,"user_tz":-330,"elapsed":403876,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 304.4711, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 13\n","Output: [[  35.564445   -84.06141     -1.0964813   -4.800215   -16.55468\n","   -60.46739   -188.6555    -113.34615     49.02486    -19.97667\n","    19.033737   196.98988     29.646368   576.8384    -126.67349\n","   136.92587    139.22755   -292.1148      60.393463     2.1059341\n","     7.629158   -49.866905  -142.4745    -146.37315   -141.69653\n","    36.530365 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 13\n","Output: [[ 120.459915   47.32013   105.68575   -63.966125  121.114624  -29.732296\n","  -293.2606   -104.70444    24.18608  -141.55313    69.5407    340.96057\n","    -8.338394  821.2294   -221.98906   174.61087   258.84146  -389.78653\n","   120.83589   -17.447952  188.05357  -174.89706  -191.33943  -165.82799\n","  -197.85345    38.853294]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 13\n","Output: [[  32.736008     9.393822    14.174233    -2.4470463   47.359108\n","   -32.653526  -273.61447    -88.47858      6.748871   -50.193504\n","    23.463518   209.45193     17.331646   605.05725   -110.6405\n","   161.19193    171.72086   -302.26782    100.92044     16.432419\n","    66.51025    -79.85669   -147.26674   -170.57123   -127.269394\n","    21.09895  ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 13\n","Output: [[ 7.8081390e+01  7.4621086e+01  6.8730316e+01 -3.4338886e+01\n","   1.0236607e+02 -2.0925751e+01 -3.0172559e+02 -9.1013306e+01\n","  -1.6723587e+01 -1.1810429e+02  4.1649815e+01  2.6679868e+02\n","   2.9315948e-03  6.5139905e+02 -1.2617664e+02  1.5608452e+02\n","   2.1479236e+02 -3.2400015e+02  1.1823185e+02 -4.2171707e+00\n","   1.2028989e+02 -1.2648238e+02 -1.5076964e+02 -1.5434311e+02\n","  -1.2756513e+02  2.5933838e+01]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 13\n","Output: [[  591.89526    724.2031     816.2411    -268.50403   1297.8386\n","    755.667     -223.12485   -111.10718     92.03473   -994.3523\n","    380.1735     973.0368    -262.47888   8895.912     -744.8629\n","    494.12296    740.0925    -342.17084     41.272675  -191.79605\n","  -6437.51     -1088.6862      27.883179   153.172     -235.70761\n","   -306.4803  ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 13\n","Output: [[ 1.7225459e+02  2.0947964e+02  1.5411508e+02  2.2578960e+01\n","   2.8690082e+02  2.0291100e+02 -2.3276982e+02 -8.3830627e+01\n","   2.3711411e+01 -3.0335840e+02  9.7859123e+01  3.1018121e+02\n","  -1.3979511e+00  2.9871941e+03 -2.6411703e+02  2.1649931e+02\n","   3.4008282e+02 -2.7387375e+02  4.6721306e+01  4.8905075e+01\n","  -2.0992485e+03 -2.5085786e+02 -1.3755341e+02 -1.1262744e+02\n","  -1.4155653e+02 -2.4828796e+01]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 13\n","Output: [[ -19.619217  -67.250206 -119.19557    86.71238  -152.36203   -80.77974\n","  -247.0918   -116.42035   -10.561295   32.952435  -13.176067   81.82051\n","    83.68844   501.5838    -44.747032  109.93596   106.33713  -265.86603\n","    84.53323    78.71771  -232.87439    93.254105 -144.04785  -203.90201\n","   -80.57753    84.274475]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 13\n","Output: [[  275.81973    294.00555    299.47925    -69.59701    464.20615\n","    241.60382   -166.9715     -66.174164    16.360382  -460.98096\n","    127.94361    384.53708    -45.460823  3733.0356    -328.2482\n","    168.94913    347.14465   -194.9624       8.59214    -54.53807\n","  -2824.4102    -342.82898    -59.04904     48.26735   -160.85535\n","    -73.80707 ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 13\n","Output: [[  926.76917   1185.7677    1326.1808    -359.98538   2188.4612\n","   1269.938      238.04971    108.354126   246.27197  -1751.5112\n","    467.52054    986.5242    -402.20712  11609.67     -1077.2002\n","    525.26465    975.07153    180.4086    -333.43137   -233.93954\n","  -9244.095    -1531.0051     126.56787    734.3843    -383.87823\n","   -604.80334 ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 13\n","Output: [[ 1.38938904e-01 -4.96636353e+01 -1.18425621e+02  6.90374374e+01\n","  -2.04964340e+02 -1.45795258e+02 -3.02258423e+02 -1.21815002e+02\n","  -5.12592087e+01  2.82302189e+01 -1.79033318e+01  9.53446350e+01\n","   9.27556534e+01  5.49613403e+02 -2.88877335e+01  6.54271240e+01\n","   1.21210205e+02 -3.12146790e+02  1.20066513e+02  6.80785065e+01\n","  -2.81600952e+02  1.30580673e+02 -1.83916504e+02 -2.18862213e+02\n","  -9.02249832e+01  1.30176346e+02]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 13\n","Output: [[ -15.838097   -77.31746   -102.79006     59.167507  -146.67369\n","   -96.77695   -234.0479    -119.73755    -15.478405    34.98172\n","   -11.4809475   90.51641     72.92107    467.38007    -36.12065\n","    90.372116    77.28673   -251.86765     86.212685    45.016663\n","  -225.41745     91.06347   -109.35116   -173.62723    -72.13042\n","    77.44988  ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 13\n","Output: [[ -15.838097   -77.31746   -102.79006     59.167507  -146.67369\n","   -96.77695   -234.0479    -119.73755    -15.478405    34.98172\n","   -11.4809475   90.51641     72.92107    467.38007    -36.12065\n","    90.372116    77.28673   -251.86765     86.212685    45.016663\n","  -225.41745     91.06347   -109.35116   -173.62723    -72.13042\n","    77.44988  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 13\n","Output: [[  897.7178   1221.9663   1490.5001   -483.72272  2418.2515   1323.7761\n","    585.7606    208.508     330.12903 -1938.3196    435.7068    805.71747\n","   -562.63885 11107.657   -1005.8522    515.00903   846.41846   587.4721\n","   -531.4284   -348.90152 -9295.573   -1631.6868    227.70709  1111.9723\n","   -346.15384  -739.8751 ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 13\n","Output: [[ -15.409115  -68.88011  -121.23975    81.015945 -170.0925   -102.50351\n","  -268.3915   -124.01176   -21.089539   33.968742  -14.484402   90.68931\n","    87.3976    529.0862    -41.5549    101.233955  108.41221  -285.92145\n","    96.82547    72.82436  -253.2933    105.51585  -152.2099   -210.48672\n","   -84.77163    96.96338 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 13\n","Output: [[  -9.954632   -62.675575  -109.58577     66.95068   -166.95378\n","  -110.42421   -257.5033    -116.98058    -28.104687    31.097822\n","   -14.0379715   88.496124    80.983795   494.7455     -34.10025\n","    82.25062     98.21092   -271.9795      96.99349     59.494247\n","  -243.29977    104.69119   -142.55283   -192.95241    -79.08064\n","    97.46867  ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 13\n","Output: [[  -8.281315  -46.403805 -114.33723    80.43028  -169.50337  -102.34774\n","  -259.65903  -106.6322    -30.202738   26.197601  -15.286675   77.60701\n","    85.337326  494.60846   -35.271976   82.83112   117.06003  -272.03586\n","    95.48209    79.86518  -240.76314   106.05718  -167.59244  -205.69281\n","   -81.83677   104.79857 ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 13\n","Output: [[  604.20166    830.9989     971.87494   -305.51358   1568.5432\n","    879.9529     411.29456    152.96002    229.57425  -1321.3756\n","    272.5224     484.4432    -379.38135   7303.534     -660.3997\n","    332.62427    575.2774     411.23923   -383.9875    -210.58224\n","  -6197.7285   -1062.3457      85.588684   744.99146   -241.14145\n","   -475.54285 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 13\n","Output: [[   6.2396393  -56.32717   -112.267075    49.568565  -219.85068\n","  -175.51761   -317.0362    -131.06503    -64.24598     30.261171\n","   -18.364105   108.5614      91.08113    560.014      -21.382412\n","    46.94319    108.76009   -325.20306    133.19844     45.334656\n","  -298.29138    141.7471    -174.73024   -210.30954    -90.19551\n","   139.45297  ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 13\n","Output: [[  -9.308411  -75.543655 -115.08122    61.547085 -184.97882  -132.22588\n","  -283.16925  -133.26176   -34.076332   35.99968   -14.945147  103.90608\n","    85.72308   539.4869    -34.049595   82.750015   95.9621   -298.97772\n","   109.9574     50.080505 -269.98376   116.68229  -143.02359  -201.93404\n","   -84.74216   106.23997 ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 13\n","Output: [[  4505.3076   6349.855    7624.4307  -2674.586   12287.082    7316.8745\n","    5214.2705   2023.5889   2036.4436  -9798.716    2039.4271   2757.7705\n","   -3330.2122  48596.21    -4606.1997   1598.6233   3250.9849   5023.2734\n","   -3668.9785  -2004.3206 -42715.78    -8427.545    1667.1323   6721.9404\n","   -1066.0251  -4230.829 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 13\n","Output: [[  1576.1056    2198.9788    2607.419     -893.8425    4224.8403\n","    2547.2915    1752.4546     667.5808     720.3834   -3431.4001\n","     705.2608     989.6553   -1133.5485   17201.098    -1639.606\n","     588.63306   1167.425     1659.8279   -1266.5261    -669.8908\n","  -15065.144    -2906.2368     524.12634   2272.0747    -401.8382\n","   -1450.6658 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 13\n","Output: [[  4160.8013   5909.101    6984.582   -2408.871   11354.738    6990.7617\n","    5161.1055   2021.2998   2005.0488  -9096.669    1868.6135   2373.0818\n","   -3109.5498  44172.387   -4281.7905   1386.5023   2910.835    4899.27\n","   -3576.713   -1804.8296 -39058.426   -7838.6943   1559.7417   6276.8877\n","    -895.4946  -4025.5332]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 13\n","Output: [[  3500.7515   4939.369    5824.9775  -2014.7002   9468.735    5887.7485\n","    4355.595    1693.8721   1706.7698  -7638.701    1560.2573   1986.0787\n","   -2606.3357  37020.67    -3610.0005   1150.7175   2415.4849   4107.81\n","   -3026.5864  -1523.2046 -32760.055   -6570.371    1298.4722   5253.8438\n","    -738.0869  -3386.6245]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 13\n","Output: [[  2789.5474    3900.6365    4568.57     -1590.9166    7408.0146\n","    4641.178     3446.9214    1346.3279    1348.2883   -6035.5527\n","    1227.9763    1560.2744   -2044.3052   29233.188    -2862.5044\n","     867.23706   1910.4736    3219.3765   -2396.9458   -1200.7842\n","  -25882.645    -5177.606      980.06494   4116.7334    -577.8593\n","   -2659.6677 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 13\n","Output: [[ -16.055317  -56.012047 -115.74429    86.41955  -152.06744   -80.70185\n","  -242.72552  -107.73058   -15.117891   29.066864  -13.577213   75.27936\n","    82.65831   484.3449    -41.605564  100.734535  110.661026 -258.92322\n","    83.86156    82.23811  -226.60931    93.52476  -151.73914  -201.50505\n","   -79.11011    88.19206 ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 13\n","Output: [[ 1009.9595   1403.108    1592.6947   -515.30975  2612.7754   1678.6819\n","   1172.504     453.86688   492.30292 -2181.9985    434.49188   577.77515\n","   -705.5967  10733.701   -1061.4213    351.24847   738.0754   1073.6526\n","   -850.6458   -380.71246 -9449.781   -1833.6694    275.86646  1396.8445\n","   -241.79913  -921.0589 ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 13\n","Output: [[ -18.755768 -101.42369  -111.7368     54.05673  -164.99333  -118.6565\n","  -264.0801   -144.70851   -16.893448   43.769157  -11.986971  112.46752\n","    78.690506  529.3603    -39.21145   100.07293    70.713974 -285.80872\n","    99.84828    32.08251  -258.36658   102.78387  -102.130646 -185.00587\n","   -79.25936    82.30357 ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 13\n","Output: [[  1085.298     1526.4543    1678.789     -501.9923    2807.4824\n","    1870.3411    1288.8188     510.3745     560.13983  -2358.2183\n","     465.01324    592.553     -745.53937  11578.525    -1169.3188\n","     406.97736    837.92786   1157.0669    -946.24243   -347.69666\n","  -10168.644    -1986.589      240.48889   1453.358     -263.62378\n","   -1002.02734]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 13\n","Output: [[  2302.772     3228.5464    3666.8103   -1226.1013    5989.3125\n","    3918.5623    2994.3792    1178.4406    1156.8173   -4943.044\n","     984.4595    1163.7242   -1677.0249   23354.822    -2337.4421\n","     622.6472    1522.6469    2738.1694   -2054.8503    -922.1909\n","  -20847.275    -4221.1235     758.0188    3336.4475    -426.64026\n","   -2176.9077 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.60% (488/500)\n","Noise 6% ‚Üí Accuracy: 96.80% (484/500)\n","Noise 9% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 12% ‚Üí Accuracy: 93.80% (469/500)\n","Noise 14% ‚Üí Accuracy: 92.80% (464/500)\n","Noise 17% ‚Üí Accuracy: 89.80% (449/500)\n","Noise 20% ‚Üí Accuracy: 93.40% (467/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 17/17)\n","Noise 3% ‚Üí Avg Retention: 97.59% (avg 16/17)\n","Noise 6% ‚Üí Avg Retention: 94.12% (avg 16/17)\n","Noise 9% ‚Üí Avg Retention: 90.65% (avg 15/17)\n","Noise 12% ‚Üí Avg Retention: 87.82% (avg 14/17)\n","Noise 14% ‚Üí Avg Retention: 85.35% (avg 14/17)\n","Noise 17% ‚Üí Avg Retention: 82.97% (avg 14/17)\n","Noise 20% ‚Üí Avg Retention: 80.41% (avg 13/17)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}