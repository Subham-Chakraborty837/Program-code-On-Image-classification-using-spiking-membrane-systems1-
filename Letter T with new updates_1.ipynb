{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQlBw9hJNANeMkLL16nsgh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DihfbhI1o51A"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","T_CLASS_INDEX = 19\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'T'\n","# ------------------------\n","def encode_letter_T():\n","    grid = np.array([\n","    [1, 1, 1, 1, 1],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_T()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([T_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_T = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_T = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_T)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_T()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == T_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == T_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_T()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"539fb376-4f82-40cb-e44f-8c1bce1b824d","executionInfo":{"status":"ok","timestamp":1764579686909,"user_tz":-330,"elapsed":230615,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 181.4374, Predicted Index: 8\n","Output: [[-107.46562   -86.58119   -65.648544   56.368416  -16.921783  -46.78425\n","  -146.7969    -30.6078    233.31049    94.30464  -106.851974   -7.716512\n","    15.722309  -71.16066    45.64531    95.45817     5.073925 -218.95131\n","    75.063416   51.873108   80.125595  169.40639  -201.54193  -210.65039\n","  -121.93263   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 19\n","Output: [[  37.069916  -152.68835     -9.525879    88.41672     87.87171\n","   -20.536926   -13.1137085 -104.18677     32.797222    69.636246\n","    -5.4912148   60.83066     54.371708   -94.23057   -111.109924\n","   108.082184   117.67637   -280.8188     -46.94993    675.31354\n","   -97.169235   -87.99504   -231.04285   -199.34723    -44.167618\n","    24.412334 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 19\n","Output: [[ 106.57391   -171.86087     88.60051     61.618423   242.50183\n","    74.51219    -29.436172  -161.6387      92.069       11.723633\n","     5.6574097  169.1018       9.747028  -159.05592   -203.57202\n","   109.424484   149.46938   -403.20615    -73.82484    816.8008\n","   -29.360893  -230.70164   -392.22455   -229.69226    -99.57272\n","   -12.280411 ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 19\n","Output: [[  27.860138 -125.56088     6.212204   68.24393   142.2477     25.933163\n","   -62.33406  -130.146      56.46005    72.53778   -15.124825   66.633224\n","    38.738075 -122.467445 -102.846344  144.17654   120.16404  -321.07074\n","   -11.830341  710.1864    -74.51124  -120.62847  -276.26855  -206.74698\n","   -68.84895    18.88834 ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 19\n","Output: [[  77.21268   -105.3975      70.710396    63.030495  -977.6903\n","    48.722763   -75.836365  -186.75021     76.70882     13.065598\n","     7.3845253  103.37117     42.5783     -91.033226  -128.30968\n","   122.318245   171.15503   -421.03665     -4.6764793 1931.4136\n","   -75.84398   -146.82214   -313.86417   -212.49959    -81.71247\n","    55.512573 ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 19\n","Output: [[  505.11072    81.5788   1136.0693    -80.40323 -4143.385    1016.5242\n","    108.2336   -531.12213   612.0801   -775.46014   186.8323    771.3119\n","   -371.9869   -467.0879   -505.59177   132.9823    350.39575  -655.04065\n","   -306.5819   6478.662     689.4797  -1072.1064   -640.704      86.1077\n","   -371.12943  -486.69894]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 19\n","Output: [[  131.73883      23.475418    274.96857      91.7599    -1322.5978\n","    265.26117      -5.0780716  -196.75266     196.9635     -190.00777\n","     27.76667     134.19083     -20.506485   -149.83444    -156.3274\n","    156.67203     243.51392    -397.6879      -71.968735   2561.797\n","     62.343132   -277.35083    -357.43246    -156.66031    -135.97453\n","    -42.013496 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -39.948296  -97.55194  -124.15673   121.988495 -167.2106    -78.272545\n","   -62.65526   -90.50311    12.323135  134.85228   -32.556496  -82.72186\n","   115.2644    -32.932945  -28.79913   156.72379   126.33587  -293.77103\n","    37.844322  843.8353   -191.53476    45.251793 -179.27428  -240.51338\n","   -16.516392  119.27494 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 19\n","Output: [[  206.93146    103.93216    501.5522     -16.943253 -1737.4597\n","    288.6393     -24.6464    -236.20628    236.3471    -397.75806\n","     47.958694   248.68295   -101.16872   -180.29956   -144.81544\n","     83.116      223.70549   -406.33197    -76.24628   2966.7944\n","    177.9923    -361.68155   -308.09985    -26.2789    -188.59418\n","   -109.55332 ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 19\n","Output: [[  708.2626    674.2883   2006.2402   -207.44568 -5465.8833   1379.8612\n","    165.22865  -514.7632    905.79126 -1788.0647    244.6622    902.3832\n","   -612.5759   -613.246    -469.3745     83.04208   541.9459   -619.6101\n","   -444.192    8515.856    1141.0153  -1417.4633   -637.10364   415.93677\n","   -635.32935  -769.73926]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -20.520287   -81.57843   -125.03328    105.504974  -205.0062\n","  -142.72208   -111.21208    -95.750885   -26.758408   133.93745\n","   -36.88059    -75.33893    126.63466     -5.3475494  -13.168472\n","   116.66125    143.93262   -341.46744     70.33694    850.82227\n","  -230.36237     70.51674   -219.60907   -257.21954    -21.791304\n","   167.51715  ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -34.452538 -105.26143  -107.65178    91.5078   -172.50812   -94.39835\n","   -64.81996   -96.10422     5.730175  128.52669   -29.043755  -60.512367\n","   102.131004  -34.528946  -21.631058  133.87743    96.03657  -277.59982\n","    43.091217  762.4809   -176.2865     44.656322 -141.47803  -207.33534\n","   -12.937648  109.793625]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -34.452538 -105.26143  -107.65178    91.5078   -172.50812   -94.39835\n","   -64.81996   -96.10422     5.730175  128.52669   -29.043755  -60.512367\n","   102.131004  -34.528946  -21.631058  133.87743    96.03657  -277.59982\n","    43.091217  762.4809   -176.2865     44.656322 -141.47803  -207.33534\n","   -12.937648  109.793625]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 19\n","Output: [[  658.21313    959.48694   2020.4039    -311.17065  -5338.3477\n","   1380.0388     130.89493   -354.61664    851.04144  -2013.8656\n","    279.24597    795.83997   -680.53174   -689.8321    -446.19858\n","    -51.103027   467.04492   -314.0901    -448.33264   8112.272\n","   1201.4572   -1444.0469    -431.43903    561.397     -671.6509\n","   -875.3435  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -36.42591   -100.49651   -126.78255    117.629944  -184.82669\n","   -99.77799    -76.84561    -97.299355     2.8981476  139.84106\n","   -34.32273    -80.261185   120.50002    -28.834435   -25.19937\n","   150.55954    129.71025   -315.02148     47.974667   868.67346\n","  -206.05385     52.874447  -188.5766    -248.62996    -17.694412\n","   133.60172  ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -29.247612  -91.94765  -115.02964   100.68568  -179.94913  -107.807495\n","   -80.920815  -92.529434   -5.801628  128.73766   -32.079056  -69.156\n","   111.76504   -21.987514  -19.199646  128.35144   118.297424 -298.90842\n","    51.648903  794.2326   -196.06485    53.7752   -175.8924   -228.21918\n","   -16.775469  131.49197 ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -27.56501    -75.689255  -119.78168    114.22209   -169.77405\n","   -99.711205   -82.831345   -82.1584      -7.9084244  123.95984\n","   -33.348156   -80.260315   116.16341    -13.544556   -20.367994\n","   128.98965    137.1839    -298.9665      50.076252   801.14606\n","  -201.32413     55.271435  -201.0044    -240.98639    -19.435295\n","   138.86357  ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 19\n","Output: [[  460.7198    686.9835   1301.6431   -191.94394 -3551.4983    891.79083\n","    104.28121  -196.92618   541.587   -1360.9271    194.11322   458.49612\n","   -429.80148  -458.59796  -303.57312   -62.73831   338.63235  -184.44995\n","   -290.7185   5432.4375    682.3839   -919.2406   -331.23895   367.62292\n","   -430.47827  -551.52295]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -14.2500305  -88.377754  -119.40657     85.90607   -225.27104\n","  -172.29042   -126.48475   -105.34769    -39.47987    135.76346\n","   -36.890434   -61.773502   125.30361     -2.0470428   -5.98468\n","    99.07387    132.15732   -354.63232     83.090744   834.9834\n","  -237.25735     77.84166   -210.01334   -248.74713    -21.179943\n","   177.10326  ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -30.15567   -107.29582   -121.15586     98.03102   -205.09152\n","  -129.34631    -92.1183    -106.89614     -9.8233185  141.66707\n","   -34.332558   -66.69574    119.16895    -25.533947   -18.01557\n","   132.97218    117.93494   -328.18634     60.728474   852.8344\n","  -212.94884     60.199368  -178.98083   -240.15753    -17.083046\n","   143.18785  ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 19\n","Output: [[  3635.3325   5596.344   10135.515   -2105.7004 -24346.621    7300.2197\n","    1767.003    -556.989    4030.1646 -10848.519    1625.3956   3779.436\n","   -3913.9734  -3122.0198  -2176.3748  -1585.0347   1558.063    1030.4929\n","   -2652.8525  33038.164    6307.1406  -6922.6484   -919.4922   4346.6543\n","   -2698.5952  -5011.862 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 19\n","Output: [[ 1266.2915   1926.5327   3501.2302   -693.1659  -8622.799    2532.1445\n","    623.3208   -228.70001  1438.3386  -3764.6243    552.7636   1288.9489\n","  -1332.1545  -1106.3706   -783.96136  -504.9651    590.3954    250.875\n","   -922.7899  11921.037    2137.73    -2410.6147   -383.36792  1432.7699\n","   -934.4627  -1711.7985 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 19\n","Output: [[  3391.2383   5275.245    9372.645   -1939.2131 -22306.5      6935.3403\n","    1913.8378   -352.7069   3824.7085 -10157.322    1510.1003   3460.2432\n","   -3688.2134  -2842.186   -2075.1982  -1575.6831   1389.9324   1265.492\n","   -2588.3682  29841.74     5981.7456  -6425.2593   -719.3262   4161.037\n","   -2373.8164  -4746.316 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 19\n","Output: [[  2857.3125   4417.5      7840.7246  -1617.2452 -18745.729    5835.605\n","    1666.819    -274.517    3227.5923  -8525.924    1274.5599   2891.9\n","   -3088.9136  -2379.3682  -1762.158   -1347.4039   1161.6711   1077.5251\n","   -2210.4639  25033.537    5014.5996  -5382.633    -574.5366   3487.158\n","   -1947.4877  -3980.432 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 19\n","Output: [[  2273.321     3499.6292    6163.885    -1269.5847  -14834.779\n","    4602.4453    1357.7886    -181.52576   2538.0522   -6741.122\n","    1009.1656    2267.4717   -2424.2427   -1858.0366   -1410.1101\n","   -1107.2927     938.55396    847.04443  -1766.4576   19756.887\n","    3933.3987   -4228.749     -466.39648   2734.5286   -1494.7987\n","   -3118.335  ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -35.517853  -85.148315 -120.656334  120.28458  -159.68428   -78.23916\n","   -65.64813   -82.93262     6.919857  126.91167   -32.069225  -82.721436\n","   113.096085  -25.287998  -26.38344   145.9388    130.07272  -285.74353\n","    38.895103  810.0716   -189.16988    46.450268 -185.48816  -236.6916\n","   -17.38684   121.905846]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 19\n","Output: [[  816.1234   1245.8187   2178.1929   -396.0119  -5427.1953   1649.8938\n","    489.83612   -88.39345   936.5019  -2402.806     347.8136    778.05225\n","   -832.8644   -674.83014  -527.6395   -344.51376   405.54517   206.17767\n","   -637.552    7469.302    1349.2129  -1512.6504   -249.78003   890.67316\n","   -536.09576 -1082.232  ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 19\n","Output: [[ -39.791084  -133.01326   -117.27843     90.55707   -205.17682\n","  -115.9706     -73.024506  -118.04144      7.1117783  149.39673\n","   -31.784534   -58.05256    111.70325    -45.72033    -22.86268\n","   149.28317     91.93724   -314.90527     51.11998    854.84644\n","  -195.53539     49.88201   -138.3526    -223.09552    -12.374806\n","   118.85855  ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 19\n","Output: [[  875.89575   1360.4403    2314.7732    -362.43628  -5822.3887\n","   1838.105      578.13806    -56.048065  1028.8696   -2590.7383\n","    373.10748    792.745     -876.9959    -721.5546    -592.87897\n","   -345.02686    493.7235     231.88141   -729.2765    8128.332\n","   1443.4944   -1627.8195    -312.80273    911.98254   -559.9084\n","  -1170.4872  ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 19\n","Output: [[  1900.5044     2924.0046     5002.4116     -993.9624   -11933.385\n","    3831.5986     1269.0693      -27.713074   2096.81      -5567.98\n","     815.90027    1811.0112    -1997.2434    -1451.6409    -1168.3171\n","    -997.18445     789.83923     858.4503    -1537.9636    15635.109\n","    3251.109     -3418.3545     -332.7743     2274.2578    -1120.9946\n","   -2584.8396  ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 75.80% (379/500)\n","Noise 6% ‚Üí Accuracy: 66.60% (333/500)\n","Noise 9% ‚Üí Accuracy: 60.20% (301/500)\n","Noise 12% ‚Üí Accuracy: 53.40% (267/500)\n","Noise 14% ‚Üí Accuracy: 56.00% (280/500)\n","Noise 17% ‚Üí Accuracy: 44.20% (221/500)\n","Noise 20% ‚Üí Accuracy: 40.40% (202/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 11/11)\n","Noise 3% ‚Üí Avg Retention: 96.95% (avg 10/11)\n","Noise 6% ‚Üí Avg Retention: 93.82% (avg 10/11)\n","Noise 9% ‚Üí Avg Retention: 91.05% (avg 10/11)\n","Noise 12% ‚Üí Avg Retention: 88.14% (avg 9/11)\n","Noise 14% ‚Üí Avg Retention: 86.23% (avg 9/11)\n","Noise 17% ‚Üí Avg Retention: 82.86% (avg 9/11)\n","Noise 20% ‚Üí Avg Retention: 79.86% (avg 8/11)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}