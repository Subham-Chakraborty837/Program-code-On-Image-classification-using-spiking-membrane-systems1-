{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlCVupVo0h+tNioK/gicKq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n"],"metadata":{"id":"AooaXTfpxBjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","L_CLASS_INDEX = 11\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'L'\n","# ------------------------\n","def encode_letter_L():\n","    grid = np.array([\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 1, 1, 1, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_L()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([L_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_L = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_L = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_L)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_L()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == L_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == L_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_L()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"7113f273-2f98-468c-eb67-5668dcb8a53b","executionInfo":{"status":"ok","timestamp":1764573907138,"user_tz":-330,"elapsed":423628,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 241.0270, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -37.789368 -123.783875   63.425297    8.282616  109.80989   -54.51123\n","  -149.67633  -114.721924   24.80989     2.232647  -22.7341    506.40674\n","   -29.176239  -31.349106  -11.150913  143.17648   129.58464  -220.20651\n","    36.601128  -77.73074   275.70685  -150.74522  -216.81757  -130.28322\n","   -57.208046   -9.210083]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 11\n","Output: [[   8.4401245    2.6715927  210.4669      -9.12796    199.22575\n","    -3.5312195 -208.73471   -142.36823     -3.7630844 -161.72925\n","    19.267273   683.2656     -60.17661     12.54747    -19.38234\n","    84.66647    260.3506    -351.0251      73.020706  -117.153244\n","   461.68793   -192.05334   -297.87857   -188.18039    -43.079468\n","    22.44777  ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 11\n","Output: [[-7.2029190e+00 -3.4805450e+01  6.8210945e+01  3.5758133e+01\n","   7.7073456e+01 -4.7815624e+01 -1.9996635e+02 -1.4761380e+02\n","  -7.9863052e+00 -7.3192154e+01 -3.4369461e+01  1.1167427e+03\n","  -2.7400623e+01  6.4548569e+00  7.8315163e-01  9.9525398e+01\n","   1.4753598e+02 -2.7422821e+02  9.7281876e+01 -8.1779930e+01\n","  -3.4010046e+02 -8.9535065e+01 -2.1731276e+02 -2.1151126e+02\n","  -3.5100189e+01  3.4542538e+01]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 11\n","Output: [[  48.89544    31.390759  136.26071    23.452099   97.29649   -53.63197\n","  -212.9007   -157.20193   -33.04433  -139.90317   -25.149078 1301.691\n","   -31.225616   25.98671    14.677212   61.394913  203.6935   -319.08066\n","   112.976105  -98.38127  -414.05566  -113.674324 -209.39577  -218.57867\n","   -24.431587   66.2426  ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 5.32084473e+02  7.12296265e+02  1.05965845e+03 -8.17214203e+00\n","   8.88638306e+02  6.23135620e+02  8.20064850e+01 -2.80750214e+02\n","   7.18334351e+01 -1.06463440e+03  2.38988541e+02  3.84509570e+03\n","  -2.14893738e+02  3.56579590e+01 -1.04455505e+02  1.95791626e+00\n","   8.63779785e+02 -6.19026245e+02 -3.94412231e+01 -1.92219727e+02\n","  -1.18592505e+03 -7.25773804e+02  2.28164673e+01 -1.53418610e+02\n","   1.85037262e+02  5.17501450e+01]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 113.02606    194.31775    235.12698     65.22291    257.8596\n","   166.49681   -132.2471    -139.34863     67.10826   -301.05695\n","    -3.1844406 1502.2043     -57.995472    -3.085617   -29.026104\n","    97.64395    293.96906   -297.1643      48.78688    -31.850079\n","  -481.12982   -233.87988   -163.50424   -183.57004     -8.566475\n","    29.866888 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -75.00563   -109.151825   -87.947365    57.9673     -26.340786\n","   -98.7106    -195.62288   -109.01903     20.054718    71.20236\n","   -84.571045   584.31024     -1.2938957  -23.774921    21.33527\n","   131.07016     27.619139  -182.26846     97.14048    -28.465584\n","  -160.24573    -10.504671  -198.35791   -203.69115    -68.827866\n","    20.122105 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 207.7804    326.81067   396.10092   -29.588455  362.40195   214.39998\n","  -120.480576 -155.02534   103.00568  -462.4884     25.04448  1699.3044\n","   -94.21089   -33.869095  -17.386108   25.978508  292.8502   -308.97485\n","    39.848812  -89.18671  -578.4569   -305.29636   -25.269684  -46.9352\n","   -15.884087   27.572721]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 11\n","Output: [[  798.69165   1451.4736    1571.3457    -126.94333   1556.4314\n","   1218.2374     202.89462   -189.24677    467.94763  -1799.1725\n","    276.27817   4323.1553    -342.4201    -196.86005   -162.50223\n","    -34.272125   991.80505   -457.89636   -249.02536    -84.09155\n","  -1511.291    -1133.6487     391.9798     319.80103     38.00688\n","    -94.83583 ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -57.324837   -93.809265   -87.09998     38.52279    -74.01941\n","  -164.19841   -250.34354   -115.05655    -18.552402    67.37176\n","   -91.32776    629.76135      4.6745186    4.4285545   39.324123\n","    89.673355    40.567608  -225.07878    132.4443     -43.764877\n","  -206.42264     12.374172  -239.50906   -218.79433    -76.732124\n","    63.803448 ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -66.980774  -115.54668    -73.9036      32.510677   -30.701738\n","  -113.116776  -186.77377   -112.286285    12.953434    70.26077\n","   -76.97133    555.37354     -4.976097   -26.36522     24.696293\n","   109.82693      5.1408787 -175.16644     97.529434   -52.98198\n","  -149.48203     -5.2303047 -158.7991    -173.31491    -61.62273\n","    18.19186  ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -66.980774  -115.54668    -73.9036      32.510677   -30.701738\n","  -113.116776  -186.77377   -112.286285    12.953434    70.26077\n","   -76.97133    555.37354     -4.976097   -26.36522     24.696293\n","   109.82693      5.1408787 -175.16644     97.529434   -52.98198\n","  -149.48203     -5.2303047 -158.7991    -173.31491    -61.62273\n","    18.19186  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 11\n","Output: [[  867.00916    1538.5933     1676.086      -170.5202     1708.4958\n","   1301.2998      524.62213     -44.098022    540.82574   -1861.8167\n","    356.00925    3754.4663     -368.15714    -382.3128     -193.01465\n","   -111.35834     915.7063     -145.0774     -435.77472     -66.918274\n","  -1516.0919    -1173.2944      564.5874      612.46893       4.1918945\n","   -189.95769  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -73.02173   -112.51218    -88.96867     50.93862    -39.04902\n","  -121.06346   -215.23483   -116.37953     10.999443    73.62809\n","   -88.51142    616.43835     -0.8551674  -19.312263    27.062576\n","   123.71358     26.874504  -198.99802    109.714035   -38.594177\n","  -175.83623     -4.83712   -208.38345   -210.27469    -72.338776\n","    30.268547 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 11\n","Output: [[-6.31447601e+01 -1.02997795e+02 -7.99911270e+01  3.90310707e+01\n","  -4.60064545e+01 -1.27481148e+02 -2.08752716e+02 -1.09991150e+02\n","   1.72814560e+00  6.76034088e+01 -8.21793518e+01  5.76503418e+02\n","  -3.70155334e-01 -1.31996498e+01  2.91465454e+01  1.03428444e+02\n","   2.32265701e+01 -1.91757843e+02  1.08700081e+02 -4.33091202e+01\n","  -1.70157089e+02  7.38161087e-01 -1.94141296e+02 -1.92762848e+02\n","  -6.74219666e+01  3.59244270e+01]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 11\n","Output: [[-6.12926102e+01 -8.70885620e+01 -8.50573349e+01  5.25801353e+01\n","  -4.86029243e+01 -1.19492706e+02 -2.11119659e+02 -1.00335510e+02\n","  -4.41856384e-01  6.25202942e+01 -8.34470215e+01  5.65505310e+02\n","   3.79705811e+00 -4.49674606e+00  2.78695011e+01  1.04386505e+02\n","   4.20568657e+01 -1.91619659e+02  1.07297180e+02 -2.35076828e+01\n","  -1.75241669e+02  1.03906250e+00 -2.19458008e+02 -2.05627274e+02\n","  -6.97102737e+01  4.35105705e+01]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 11\n","Output: [[  622.5214    1041.4397    1072.3278     -70.63536   1089.3322\n","    897.0942     438.37402     17.881958   393.14337  -1226.3323\n","    238.6062    2427.6064    -224.96664   -288.8186    -159.61588\n","   -122.82797    608.13995    -64.761894  -323.12567    -15.6026\n","  -1030.4739    -785.7052     301.33258    382.78802    -10.443069\n","   -114.722305]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -51.32852   -100.36702    -81.09938     18.765831   -88.90813\n","  -193.75433   -265.53094   -124.05069    -31.158314    69.32669\n","   -91.468254   647.42114      3.272152     7.5960693   46.73194\n","    71.69516     28.583847  -238.25735    145.21231    -66.151695\n","  -216.6313      20.67891   -229.75519   -210.18979    -76.64048\n","    72.98476  ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -67.02544   -119.06993    -82.96811     31.181644   -53.937737\n","  -150.61938   -230.42223   -125.373665    -1.6064758   75.58303\n","   -88.65191    634.098       -2.2575264  -16.144764    34.470387\n","   105.73538     14.8907585 -212.17654    122.482056   -60.980972\n","  -186.04486      3.4676218 -198.62955   -201.67009    -72.24713\n","    39.44985  ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 5094.509    8075.0854   8196.341    -755.5249   8070.7573   7490.848\n","   5082.7266   1023.39355  2992.1226  -9228.748    2327.5469  13166.106\n","  -1605.0225  -2212.6553  -1508.7048  -1820.4846   3982.4531   1042.9976\n","  -3275.6892    103.10889 -6193.577   -5672.497    3581.8984   4144.3413\n","    428.99835 -1196.0968 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 1776.2542    2784.441     2827.639     -234.26959   2799.2893\n","   2587.3242    1734.0438     313.85327   1077.3745   -3191.6238\n","    779.34894   4844.559     -555.29065   -804.68677   -519.55084\n","   -596.71423   1387.3427     295.30704  -1110.1797      18.020264\n","  -2232.3584   -1995.7413    1180.2292    1372.6002     116.50049\n","   -402.4268  ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 4801.652    7514.187    7524.54     -612.11914  7432.831    7128.3354\n","   5041.5566   1086.605    2882.843   -8507.254    2198.931   11595.867\n","  -1435.2112  -2124.1265  -1469.0178  -1755.4813   3609.555    1174.5266\n","  -3178.4631    185.5     -5544.872   -5263.639    3376.8552   3919.1538\n","    426.27454 -1157.3422 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 4034.215    6279.525    6285.1646   -506.95068  6216.153    5991.822\n","   4274.9043    927.1455   2451.7554  -7122.818    1841.679    9747.436\n","  -1199.5286  -1815.8918  -1251.9962  -1493.3784   2988.1758    998.6292\n","  -2680.2114    125.81592 -4654.677   -4419.0024   2816.6228   3281.2014\n","    343.5188   -987.4438 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 3207.2026   4941.4404   4942.452    -390.8883   4873.7334   4721.8354\n","   3401.6948    750.5586   1934.0837  -5614.459    1451.9261   7721.655\n","   -937.39856 -1449.906   -1010.6173  -1220.2477   2353.9014    777.61694\n","  -2125.7883     92.17456 -3715.6191  -3477.356    2167.1572   2563.0244\n","    264.55847  -778.3648 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -69.14105    -96.44002    -85.99169     58.78805    -31.117731\n","   -97.92522   -193.56528   -100.99701     14.334053    65.64846\n","   -82.038864   558.84375      1.0322113  -16.367153    21.738733\n","   121.40662     35.210316  -178.57928     95.932045   -20.922325\n","  -159.94844     -7.5665855 -203.8952    -201.36743    -67.51361\n","    26.743116 ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 1153.4565    1759.4031    1738.7728     -97.925934  1738.9519\n","   1683.9766    1185.0385     235.88385    726.4311   -1995.3167\n","    486.2605    2993.755     -331.50247   -544.386     -358.6745\n","   -392.6419     868.415      218.84259   -736.4015      44.289062\n","  -1403.8593   -1266.907      693.7674     836.57745     65.448975\n","   -261.54242 ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 11\n","Output: [[ -76.72601   -144.33064    -78.836266    23.840496   -33.856087\n","  -137.04036   -210.50089   -135.69083     15.339455    83.79431\n","   -85.97608    638.4347      -9.189571   -36.718063    29.61663\n","   121.79741    -10.786101  -199.27435    112.51984    -78.197075\n","  -165.66711     -5.4389086 -157.75006   -184.54584    -67.76218\n","    15.0962715]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 1230.2428    1900.6124    1843.8696     -54.579865  1888.9531\n","   1868.6638    1304.2808     279.39856    811.78204  -2149.077\n","    515.0321    3236.83      -354.65735   -599.67566   -410.26715\n","   -394.78003    966.56335    250.86943   -819.80365     93.46985\n","  -1520.7123   -1380.4076     675.7594     852.9717      65.01871\n","   -300.88693 ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 11\n","Output: [[ 2686.0374   4056.6724   3967.6775   -264.87726  3910.0146   3921.6294\n","   2956.6528    694.8436   1637.0026  -4538.901    1184.7244   5963.0864\n","   -747.9389  -1232.5599   -853.70825 -1059.5782   1893.6045    745.6044\n","  -1800.3884    138.5586  -2955.1318  -2834.9875   1744.2449   2098.2212\n","    234.7832   -637.7752 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 28.80% (144/500)\n","Noise 6% ‚Üí Accuracy: 11.00% (55/500)\n","Noise 9% ‚Üí Accuracy: 3.00% (15/500)\n","Noise 12% ‚Üí Accuracy: 0.80% (4/500)\n","Noise 14% ‚Üí Accuracy: 0.20% (1/500)\n","Noise 17% ‚Üí Accuracy: 0.00% (0/500)\n","Noise 20% ‚Üí Accuracy: 0.20% (1/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 11/11)\n","Noise 3% ‚Üí Avg Retention: 97.36% (avg 10/11)\n","Noise 6% ‚Üí Avg Retention: 94.18% (avg 10/11)\n","Noise 9% ‚Üí Avg Retention: 90.86% (avg 9/11)\n","Noise 12% ‚Üí Avg Retention: 88.09% (avg 9/11)\n","Noise 14% ‚Üí Avg Retention: 84.09% (avg 9/11)\n","Noise 17% ‚Üí Avg Retention: 83.05% (avg 9/11)\n","Noise 20% ‚Üí Avg Retention: 80.14% (avg 8/11)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}