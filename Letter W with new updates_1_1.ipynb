{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZpoHIkHAzSgRhtVxQ5iX5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"STVRuBqhteyL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Mj6uFbLixEHn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764580762105,"user_tz":-330,"elapsed":407966,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}},"outputId":"1134cd50-f51b-4e45-e795-d40a2cf6c957"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 434.8524, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 22\n","Output: [[  94.055115  -116.70638    -26.029034    30.386055   -23.770538\n","     2.1808338 -215.34207   -167.35895      1.8884506  -17.690514\n","    49.714363   121.21801     49.271782    14.747063   -58.345886\n","  -116.33879      2.5313663 -256.67877     62.370155    -7.231823\n","   -95.90082    -16.57196    581.11646   -194.06749   -114.21309\n","     5.300476 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 22\n","Output: [[ 185.93199    94.9445    148.58542    28.543161   68.725426   65.54126\n","  -339.2135   -196.25577   -36.30314  -124.523224  112.07539   244.25458\n","    26.581722  100.96213  -110.20487  -155.56926   117.815926 -401.63947\n","   117.09906   -31.505909  -75.572174  -29.365032  711.7264   -227.11911\n","  -173.56346    34.187107]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 22\n","Output: [[  69.19962     59.98372     36.476547    29.489275    36.62992\n","    56.82731   -287.03284   -131.61191    -12.943085   -23.602386\n","    48.62048    115.085144    38.36078     30.801468   -39.97991\n","  -114.87139     43.124084  -283.99408     89.376724    -6.335392\n","   -76.31053      1.3634319  590.50244   -206.12024   -120.327255\n","    -2.5352983]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 22\n","Output: [[  98.68353    169.72598    128.66986      1.0305405   94.70352\n","    68.83324   -312.52444   -120.86162    -44.894276   -71.537384\n","    64.35118    167.27176     14.85405     38.83528    -58.780796\n","  -126.291626   103.21167   -316.5141     111.93673    -39.750923\n","   -57.376064    -6.412054   581.41766   -189.03453   -136.66269\n","    20.943918 ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 22\n","Output: [[ 5.0885263e+02 -4.2803950e+03  1.2769309e+03 -8.6014679e+01\n","   1.2054515e+03  8.3779736e+02 -2.9907611e+02 -7.4967346e+01\n","  -3.7258789e+01 -6.9201697e+02  3.6818539e+02  8.2999255e+02\n","  -3.0218103e+02  7.4103271e+01 -5.5840936e+02  4.3707047e+01\n","   7.7607520e+02 -5.5444067e+02  6.0299744e+01 -3.3528903e+02\n","   5.1267743e+02 -4.3106772e+02  6.5907832e+03  3.4498749e+00\n","  -3.9135120e+02 -1.2383424e+02]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 22\n","Output: [[  120.136    -1349.9514     292.60065     28.054447   302.51035\n","    271.61316   -257.4624     -66.81354     34.867767  -179.91537\n","     92.79089    210.37344    -37.964207    10.943558  -128.18552\n","    -55.663895   237.81308   -316.04462     33.427628   -27.754879\n","    106.25507   -108.48131   2268.6355    -168.79329   -185.31557\n","    -65.34674 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -29.093864 -200.71945  -143.18082    38.85682  -111.04265    -9.717606\n","  -234.1549   -129.6276     41.9965     76.635735  -11.136578  -10.665077\n","    83.060005  -13.35659    40.01062   -98.30761   -59.496227 -226.109\n","    54.920948   45.95411  -101.496475   35.95695   575.1791   -225.67688\n","   -76.998     -35.37741 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 22\n","Output: [[  160.34598  -1788.8308     524.18536    -61.376602   497.50934\n","    302.6512    -241.42963    -23.673584    48.07907   -313.89337\n","    103.029755   332.9892    -149.82422    -32.894104  -155.87488\n","    -21.749039   307.00397   -315.13068     16.307625  -155.6107\n","    227.67735   -184.51392   2801.425      -14.93018   -201.0922\n","    -88.9771  ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 22\n","Output: [[  507.43198 -5684.824    2117.5342   -185.42761  2211.8887   1362.1295\n","   -167.28818   289.1814    282.63354 -1328.6683    351.80847  1069.0717\n","   -760.39777  -226.8034   -651.52936   304.5683   1225.1621   -438.78442\n","   -231.8161   -521.248    1182.4661   -898.35     8360.5       482.44308\n","   -492.42972  -411.595  ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 22\n","Output: [[-1.0387032e+01 -1.8630772e+02 -1.4265237e+02  1.9416695e+01\n","  -1.6190417e+02 -7.3044701e+01 -2.8868130e+02 -1.3528262e+02\n","   3.2473145e+00  7.3590324e+01 -1.6480705e+01  5.1004028e-01\n","   9.1447914e+01  1.4760519e+01  5.8456940e+01 -1.4264798e+02\n","  -4.8979221e+01 -2.7116257e+02  8.9522491e+01  3.4598267e+01\n","  -1.4023160e+02  7.2071022e+01  5.4819305e+02 -2.4067509e+02\n","  -8.6778847e+01  6.6161833e+00]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -25.211792  -215.3632    -124.2144      15.0049305 -108.18029\n","   -31.989819  -221.90596   -131.75272     32.813915    75.32473\n","   -10.283688     6.12144     71.60019    -16.891125    41.494915\n","   -95.25368    -74.01339   -215.08684     59.157936    15.296345\n","   -97.37807     37.199814   566.6186    -192.71284    -68.920906\n","   -32.2983   ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -25.211792  -215.3632    -124.2144      15.0049305 -108.18029\n","   -31.989819  -221.90596   -131.75272     32.813915    75.32473\n","   -10.283688     6.12144     71.60019    -16.891125    41.494915\n","   -95.25368    -74.01339   -215.08684     59.157936    15.296345\n","   -97.37807     37.199814   566.6186    -192.71284    -68.920906\n","   -32.2983   ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 22\n","Output: [[  431.49777 -5583.6934   2188.949    -237.6633   2382.8816   1411.6079\n","     84.27307   417.07758   406.73914 -1490.5121    329.66806   968.04443\n","   -876.02454  -421.7932   -643.8077    410.3015   1191.259    -209.78983\n","   -380.6662   -559.5542   1287.8455  -1073.5785   7948.4756    726.006\n","   -377.46362  -514.5501 ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -25.554531  -210.5616    -145.88586     31.249165  -126.99577\n","   -28.981728  -254.85751   -137.65875     33.523483    79.41777\n","   -12.665695    -5.0474167   86.437386    -8.6119585   46.337368\n","  -112.166      -63.27656   -244.60902     66.12556     38.97327\n","  -114.04632     45.911255   595.4337    -232.74179    -81.128\n","   -27.209127 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 22\n","Output: [[-1.95690765e+01 -1.95914429e+02 -1.32080841e+02  2.10146503e+01\n","  -1.27065674e+02 -4.28851929e+01 -2.44942352e+02 -1.29502106e+02\n","   2.22671242e+01  7.30665131e+01 -1.26176376e+01  5.06905556e-01\n","   7.98353500e+01 -3.43761730e+00  4.68125496e+01 -1.12021645e+02\n","  -5.96061325e+01 -2.33874710e+02  6.87378998e+01  2.84377289e+01\n","  -1.12529892e+02  4.96582642e+01  5.47278503e+02 -2.13161499e+02\n","  -7.57848740e+01 -1.69252071e+01]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -17.465683 -166.62349  -137.24223    34.63205  -129.99796   -34.516426\n","  -247.27603  -119.22036    20.19332    68.02623   -13.422455  -10.725315\n","    84.693146    5.27125    45.80343  -114.93126   -41.41854  -234.16254\n","    67.1133     48.559937 -115.13192    52.162422  507.68372  -226.54524\n","   -78.518845   -9.720385]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 22\n","Output: [[  283.18787 -3671.9727   1418.4468   -155.3782   1535.7195    898.4002\n","    124.02023   297.51984   269.2521  -1015.1795    233.86243   562.83325\n","   -561.69037  -332.56094  -432.70255   257.865     778.0918    -94.98337\n","   -286.40256  -344.38428   809.8939   -733.2444   5153.751     487.7262\n","   -238.01334  -328.8145 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 22\n","Output: [[-4.9066772e+00 -2.0347171e+02 -1.3587425e+02 -1.1692810e-01\n","  -1.7642613e+02 -1.0344490e+02 -3.0325946e+02 -1.4437633e+02\n","  -9.8169689e+00  7.5716881e+01 -1.7583401e+01  1.4520990e+01\n","   8.9095383e+01  1.7737883e+01  6.5525848e+01 -1.5497940e+02\n","  -6.0018147e+01 -2.8415155e+02  1.0284559e+02  1.2288551e+01\n","  -1.5072223e+02  8.2646759e+01  5.6416748e+02 -2.3125803e+02\n","  -8.6870293e+01  1.6324020e+01]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -20.074184 -227.72559  -139.10776    11.715538 -141.51772   -59.381943\n","  -269.43564  -146.75244    20.459206   81.544334  -13.768394    8.963528\n","    84.084854   -5.634595   53.406273 -124.497375  -74.31549  -257.59796\n","    79.44864    16.663567 -124.53695    56.486977  611.4081   -223.32469\n","   -81.219444  -17.501293]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 22\n","Output: [[  2168.053  -25205.24    11047.702   -1378.1975  11817.792    6650.722\n","    3047.2007   3065.5974   1861.5588  -7882.219    1820.2275   3871.7397\n","   -4582.5283  -2638.0657  -3464.7559   2623.1177   5762.1875   1179.4911\n","   -2728.0723  -2777.4956   6553.8164  -5720.71    33030.188    5166.253\n","   -1032.801   -2342.8293]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 22\n","Output: [[  744.6697  -8927.458    3813.707    -474.6878   4084.1267   2331.3118\n","   1013.8887   1028.0308    694.3671  -2726.297     630.1788   1359.1067\n","  -1576.0349   -947.0472  -1199.0789    884.7814   1972.0865    327.10312\n","   -942.2855   -963.8479   2276.809   -1991.8793  11784.838    1718.5222\n","   -388.54718  -845.2227 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 22\n","Output: [[  2007.6577 -23062.92    10203.767   -1226.6829  10934.195    6298.4976\n","    3269.076    2991.6172   1851.8193  -7324.7554   1675.9387   3505.7383\n","   -4253.2256  -2497.4539  -3273.4082   2524.416    5300.129    1331.4608\n","   -2678.1426  -2498.7961   6219.451   -5336.259   29784.732    4848.292\n","    -857.0354  -2220.276 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 22\n","Output: [[  1695.741  -19403.672    8528.583   -1028.4329   9127.152    5301.022\n","    2825.2327   2515.734    1599.914   -6148.3794   1399.7605   2929.855\n","   -3554.8938  -2118.9648  -2764.57     2102.3496   4398.362    1110.5674\n","   -2272.5273  -2098.647    5226.9556  -4460.787   24974.785    4045.681\n","    -706.4328  -1890.0503]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 22\n","Output: [[  1363.4714  -15348.785     6704.362     -811.93945   7147.03\n","    4185.061     2277.4397    1995.1709    1278.0198   -4865.2188\n","    1099.7981    2297.774    -2783.8733   -1680.474    -2181.957\n","    1614.6672    3448.4673     864.4428   -1815.846    -1654.2904\n","    4112.7373   -3503.4502   19663.84      3160.0898    -542.45746\n","   -1497.5374 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -25.04945   -178.75041   -138.859       40.54827   -112.54375\n","   -12.484955  -230.3642    -120.40841     35.33139     70.93996\n","   -11.514938   -13.504032    82.1879      -6.4149847   39.743652\n","   -99.69024    -48.567215  -220.88577     55.41481     50.74746\n","  -102.03926     39.082535   531.3041    -222.57858    -75.69344\n","   -26.633041 ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 22\n","Output: [[  486.218   -5602.8564   2364.1167   -269.81024  2536.7153   1527.7261\n","    768.7905    690.032     501.56268 -1727.4004    384.76126   815.58167\n","   -974.9978   -621.3282   -777.4316    551.8585   1228.9398    232.54088\n","   -648.1539   -566.2178   1467.6667  -1251.2448   7272.54     1041.3383\n","   -224.43262  -560.09576]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 22\n","Output: [[ -29.76133   -269.14346   -135.56313      4.014385  -121.131226\n","   -45.719208  -250.19002   -158.22223     37.671085    89.49831\n","   -11.056095    17.417038    76.7218     -26.029713    48.355614\n","  -106.34677    -99.65176   -244.03333     69.37479     -1.2711792\n","  -108.84229     40.902927   674.62317   -205.97432    -75.660034\n","   -41.618782 ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 22\n","Output: [[  523.3845  -6022.12     2503.7993   -242.21231  2729.792    1716.7815\n","    869.947     763.8141    579.8059  -1871.8098    412.8056    834.60565\n","  -1026.8228   -678.1706   -853.46204   591.086    1340.2122    259.0423\n","   -738.21436  -548.613    1589.7793  -1358.4836   7807.686    1065.3037\n","   -236.13751  -631.261  ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 22\n","Output: [[  1142.8835  -12312.219     5423.6797    -635.3441    5780.13\n","    3487.0798    2122.9258    1736.4888    1131.8748   -3979.1748\n","     864.8231    1799.2235   -2262.1047   -1402.99     -1808.8469\n","    1335.3301    2800.0815     818.6532   -1575.9017   -1300.6008\n","    3428.5435   -2844.4624   15489.145     2567.4478    -372.19104\n","   -1255.2173 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 75.00% (375/500)\n","Noise 6% ‚Üí Accuracy: 67.00% (335/500)\n","Noise 9% ‚Üí Accuracy: 61.60% (308/500)\n","Noise 12% ‚Üí Accuracy: 56.80% (284/500)\n","Noise 14% ‚Üí Accuracy: 60.20% (301/500)\n","Noise 17% ‚Üí Accuracy: 49.60% (248/500)\n","Noise 20% ‚Üí Accuracy: 47.00% (235/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged with Jitter):\n","Noise 0% ‚Üí Avg Retention: 98.33% (avg 17/18)\n","Noise 3% ‚Üí Avg Retention: 94.17% (avg 16/18)\n","Noise 6% ‚Üí Avg Retention: 92.25% (avg 16/18)\n","Noise 9% ‚Üí Avg Retention: 88.94% (avg 16/18)\n","Noise 12% ‚Üí Avg Retention: 86.14% (avg 15/18)\n","Noise 14% ‚Üí Avg Retention: 85.50% (avg 15/18)\n","Noise 17% ‚Üí Avg Retention: 81.67% (avg 14/18)\n","Noise 20% ‚Üí Avg Retention: 77.89% (avg 14/18)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.23%\n","Noise 6% ‚Üí Fidelity: 94.28%\n","Noise 9% ‚Üí Fidelity: 90.49%\n","Noise 12% ‚Üí Fidelity: 88.31%\n","Noise 14% ‚Üí Fidelity: 86.39%\n","Noise 17% ‚Üí Fidelity: 83.08%\n","Noise 20% ‚Üí Fidelity: 80.78%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","W_CLASS_INDEX = 22\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'W'\n","# ------------------------\n","def encode_letter_W():\n","    grid = np.array([\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 1, 0, 1],\n","    [1, 0, 1, 0, 1],\n","    [1, 1, 0, 1, 1],\n","    [1, 0, 0, 0, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_W()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([W_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    if use_biological_input:\n","        input_W = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_W = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_W)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_W()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == W_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == W_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged with Jitter):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200\n","jitter_prob = 0.02\n","\n","original = encode_letter_W()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","\n","\n","        jitter_mask = np.random.rand(*noisy_sample.shape) < jitter_prob\n","        noisy_array = np.where(jitter_mask, 1 - noisy_sample.numpy(), noisy_sample.numpy())\n","        noisy_sample = torch.tensor(noisy_array, dtype=torch.float32)\n","\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"]}]}