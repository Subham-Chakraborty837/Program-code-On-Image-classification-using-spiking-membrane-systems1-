{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2SXRC5BVg0W8gGE8ZGUov"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fc4xz92_D1Xv"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","K_CLASS_INDEX = 10\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'K'\n","# ------------------------\n","def encode_letter_K():\n","    grid = np.array([\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 1, 0],\n","    [1, 0, 1, 0, 0],\n","    [1, 1, 0, 0, 0],\n","    [1, 0, 1, 0, 0],\n","    [1, 0, 0, 1, 0],\n","    [1, 0, 0, 0, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_K()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([K_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_K = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_K = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_K)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_K()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == K_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == K_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_K()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"2f419953-0743-485e-8192-43970f2460d0","executionInfo":{"status":"ok","timestamp":1764566415066,"user_tz":-330,"elapsed":423085,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 340.1625, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 10\n","Output: [[-4.1637352e+01 -1.1121409e+02  2.0692062e-01  6.0558182e+01\n","   3.8961163e+01  3.1930698e+01 -7.1283615e+01 -9.0086243e+01\n","   1.3415611e+01  5.9563168e+01  4.7066528e+02  8.3234802e+01\n","   7.2110939e+01 -8.1270813e+01 -4.7386101e+01  3.3033035e+01\n","   8.7929207e+01 -1.9443134e+02 -5.1838646e+01  5.1457455e+01\n","  -1.0519243e+02 -9.0524117e+01 -1.8920532e+02 -1.4664708e+02\n","  -6.6348358e+01  1.4003342e+01]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -12.235992  -74.68277    82.00124    59.412727  121.33448   111.02695\n","   -70.03143  -101.39679    37.204643  -22.511276  656.4849    181.852\n","   102.12141   -77.218666  -90.64344   -22.573181  250.72327  -324.717\n","   -88.15004    74.38435   -42.72197  -164.74216  -328.88177  -211.16763\n","   -61.942783    8.212635]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -37.472607  -60.29161     6.171303   52.496605   69.96206    57.40884\n","  -122.77542   -87.7524     20.244167   31.610367  476.1246     92.08768\n","    86.50349   -50.745346  -40.18049    22.150352  176.10252  -254.36261\n","   -20.184677   70.51837   -95.04309   -83.00052  -233.14595  -198.46349\n","   -66.077095   11.94981 ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 10\n","Output: [[  -2.9953613  -11.22187     58.030663    28.142906   108.607864\n","    55.542812  -135.97572    -88.1306       8.411823   -37.25403\n","   507.08887    137.3688      82.673004   -25.028244   -54.66645\n","   -16.430027   243.97878   -295.34357     -5.086605    48.284145\n","   -60.858864   -96.85422   -262.09317   -191.1173     -74.61394\n","    14.233265 ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 10\n","Output: [[ 273.97913    380.74173    750.3906     -25.747513  1069.7682\n","   789.0771     288.86182   -145.97931    288.9796    -893.50653\n","  1166.6116     684.95435     13.518417   -42.786377  -495.22272\n","   -92.142334   990.73145   -542.7783    -242.27322      2.9910278\n","   687.86273   -690.3379    -414.31754    -51.69194    -60.249382\n","  -351.50446  ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 10\n","Output: [[ 6.5229721e+00  1.2199668e+02  1.6249599e+02  5.0092564e+01\n","  -1.4932892e+03  2.4716428e+02 -5.2650330e+01 -8.6718277e+01\n","   7.4603043e+01 -2.4444495e+02  2.3336030e+03  1.6211505e+02\n","   4.8436558e+01 -3.2827759e-01 -1.3236023e+02  2.6750565e+01\n","   3.4502957e+02 -2.8288773e+02 -5.2225990e+01  1.1626347e+02\n","   3.0972153e+01 -1.8485349e+02 -2.5249290e+02 -1.6418851e+02\n","  -9.5304398e+01 -4.3277618e+01]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 10\n","Output: [[-100.84184    -81.98517   -111.36864     67.0956    -101.13774\n","   -19.790962  -189.12021    -91.09509    -10.815678   106.41702\n","   356.88977     -5.161026    87.30399     -6.3660297   18.643116\n","    42.396927    41.877464  -186.92569     29.268303    88.437065\n","  -220.89262     21.17389   -140.61975   -199.03197    -75.464615\n","    70.537155 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 10\n","Output: [[   88.03145    238.2578     341.6392     -75.11853  -2015.1466\n","    262.96185     12.757095   -87.1053      60.266167  -449.38315\n","   2977.8735     233.87509    -42.000153   -27.64624   -171.88016\n","     -4.499649   345.88544   -245.58066    -44.68209     17.164629\n","    106.55011   -227.55936   -182.59338     -6.634712  -112.008995\n","   -101.012314]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 10\n","Output: [[ 5.1510492e+02  1.0981448e+03  1.4234166e+03 -3.0012506e+02\n","  -6.5890703e+03  1.2090726e+03  6.3705066e+02 -2.7952881e+00\n","   3.4515622e+02 -1.9044534e+03  9.5450703e+03  6.6352789e+02\n","  -3.8563727e+02 -1.9893616e+02 -7.2454968e+02  5.6751740e+01\n","   1.0999819e+03 -1.9519312e+02 -3.5237433e+02  3.6664429e+00\n","   8.8109790e+02 -9.7566052e+02 -2.7870203e+02  4.9275824e+02\n","  -2.2470892e+02 -6.4039484e+02]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -83.762146  -65.02924  -110.42625    48.785057 -158.72383   -83.125946\n","  -242.64354   -95.66841   -51.19909   103.88901   364.1081      5.851036\n","    96.457825   22.510632   36.480064   -4.064049   54.782703 -231.17676\n","    63.199127   78.05525  -259.5984     57.09223  -180.16324  -214.01903\n","   -85.081696  116.07213 ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -90.374054  -90.890015  -95.62816    41.162373 -106.41237   -40.940437\n","  -180.94728   -96.489685  -15.582947  102.31267   335.62552    10.832699\n","    76.21532   -10.0873     22.011845   28.50917    18.193441 -179.6374\n","    35.583668   53.90371  -203.34206    24.922117 -106.130974 -169.22412\n","   -67.49644    64.85737 ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -90.374054  -90.890015  -95.62816    41.162373 -106.41237   -40.940437\n","  -180.94728   -96.489685  -15.582947  102.31267   335.62552    10.832699\n","    76.21532   -10.0873     22.011845   28.50917    18.193441 -179.6374\n","    35.583668   53.90371  -203.34206    24.922117 -106.130974 -169.22412\n","   -67.49644    64.85737 ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 10\n","Output: [[  643.5497    1285.5582    1529.6458    -345.93195  -6497.083\n","   1240.971      791.8125     137.3753     312.86957  -2187.9949\n","   9391.326      533.7236    -535.735     -315.4969    -796.33655\n","     60.381165   990.07916    173.94803   -459.0178    -126.94354\n","    885.91516  -1101.9023     -91.32056    804.78723   -169.32837\n","   -718.7319  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -99.71393    -84.21715   -113.139145    60.656517  -119.869965\n","   -39.301754  -208.30054    -97.72683    -21.254395   110.15222\n","   371.21576      0.5153122   91.13799     -1.1546545   24.207443\n","    31.217781    41.55419   -204.15778     39.530556    82.89165\n","  -236.31168     30.914062  -148.58884   -205.4875     -79.50776\n","    82.726685 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -87.632065  -76.84366  -102.14193    48.19326  -123.202     -52.277805\n","  -202.20525   -92.76318   -28.171654  101.233246  342.7038      5.503685\n","    84.41956     3.605978   26.463799   17.812134   36.6497   -196.79102\n","    44.260265   68.75219  -223.76068    36.13708  -139.16258  -188.3938\n","   -74.26749    84.36998 ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -86.01792   -60.565323 -106.88518    61.66324  -121.25935   -44.10438\n","  -204.28284   -82.40494   -30.321642   96.418625  335.4561     -5.501663\n","    88.7898     12.087889   25.351425   18.294235   55.429253 -196.71251\n","    42.674633   89.14609  -228.76025    37.6119   -164.2251   -201.10794\n","   -76.99538    91.693054]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 10\n","Output: [[  433.8214     904.48596    990.69476   -218.26328  -4306.338\n","    803.1246     486.91205    113.802      175.62848  -1506.2725\n","   6231.7764     313.01633   -361.06824   -208.90332   -531.2011\n","     20.305115   659.8922     150.17618   -316.56406    -84.748215\n","    499.69208   -735.9415     -90.63928    540.6098    -126.55543\n","   -448.01935 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -77.400345  -71.71364  -104.32652    29.379354 -180.09337  -113.21146\n","  -257.73746  -104.99744   -64.02142   105.57202   367.802      19.524254\n","    94.74748    25.861382   43.728752  -22.18708    42.617413 -244.76474\n","    76.61906    55.24312  -266.2422     68.70652  -170.88795  -205.57065\n","   -85.14078   125.421776]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 10\n","Output: [[ -93.35217   -90.90152  -107.03944    41.2508   -141.23953   -69.38727\n","  -223.39442  -107.05586   -34.07675   111.83524   374.90964    14.188526\n","    89.42767     2.196086   31.456127   13.094765   29.388905 -217.74576\n","    52.950474   60.07954  -242.95547    42.52834  -139.31352  -197.0391\n","   -79.56685    92.07634 ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 10\n","Output: [[  3803.27       7021.4346     7833.787     -1967.6193   -30053.514\n","    6141.9043     4974.008      1507.4961     1472.3246   -11664.634\n","   42337.89       2208.0884    -3263.16      -1625.5195    -4039.921\n","     -61.755127   4258.442      2612.622     -2686.1086    -1311.2139\n","    5047.0156    -5569.7715      512.7715     5347.9834     -357.7586\n","   -3863.1365  ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 10\n","Output: [[  1302.4169    2426.9468    2689.588     -667.50415 -10574.734\n","    2149.9922    1673.6008     493.3357     518.6504   -4063.7217\n","   14959.473      784.97424  -1116.3988    -565.5736   -1409.3782\n","     -17.30481   1491.9205     846.26227   -934.6983    -436.82544\n","    1669.1945   -1931.7457     127.09839   1792.0347    -156.92122\n","   -1329.8588 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 10\n","Output: [[  3602.0833    6546.12      7221.326    -1772.3735  -27542.39\n","    5853.759     4830.9272    1518.2021    1470.2107  -10891.355\n","   38631.664     2017.1152   -3075.2642   -1484.3057   -3773.2722\n","     -77.43091   3874.8276    2616.2383   -2596.525    -1222.1016\n","    4796.0635   -5142.204      528.5625    5006.0923    -268.76917\n","   -3669.6382 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 10\n","Output: [[  3024.8179    5469.962     6039.885    -1484.7926  -23128.96\n","    4936.0244    4079.1877    1277.6758    1260.8932   -9149.336\n","   32409.059     1706.6873   -2583.002    -1254.4802   -3165.311\n","     -93.45752   3222.7153    2199.4233   -2203.6396   -1047.2125\n","    4014.0464   -4299.746      439.37207   4181.65      -218.62335\n","   -3092.1653 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 10\n","Output: [[  2407.2468    4321.1426    4756.4395   -1163.2393  -18306.46\n","    3904.2593    3214.9587    1029.3043    1000.792    -7229.169\n","   25594.611     1352.7041   -2029.9414    -975.9907   -2500.1907\n","    -121.29724   2536.806     1710.8816   -1749.6036    -836.4485\n","    3144.164    -3365.6665     311.96143   3265.078     -172.8949\n","   -2426.9387 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 10\n","Output: [[-9.3993828e+01 -7.0159256e+01 -1.0824164e+02  6.7598969e+01\n","  -1.0183243e+02 -2.2192310e+01 -1.8711136e+02 -8.3434143e+01\n","  -1.5349316e+01  9.9550217e+01  3.3900992e+02 -8.1695290e+00\n","   8.6129890e+01  2.5524044e-01  1.9215115e+01  3.5935150e+01\n","   4.8814995e+01 -1.8320305e+02  3.0840343e+01  9.1564293e+01\n","  -2.1711691e+02  2.4522804e+01 -1.4843790e+02 -1.9684216e+02\n","  -7.4208420e+01  7.5020340e+01]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 10\n","Output: [[  840.10596   1550.0242    1661.6079    -382.4585   -6642.3945\n","   1424.8623    1097.6931     351.27545    365.8673   -2595.2786\n","   9355.633      482.12677   -702.7181    -342.54993   -903.58655\n","    -25.431702   939.7388     560.35596   -628.1734    -254.17825\n","   1041.6361   -1201.454       42.42932   1094.7007     -96.350845\n","   -851.7411  ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 10\n","Output: [[-102.9422   -116.77382  -103.65263    33.716557 -123.75523   -55.648575\n","  -204.14531  -118.44334   -16.954395  119.78145   385.71112    22.526016\n","    82.39752   -18.118454   26.432184   30.25357     3.995098 -204.31479\n","    42.701828   42.103825 -226.31256    27.964453  -98.46376  -180.05917\n","   -74.05198    68.08055 ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 10\n","Output: [[ 8.9563916e+02  1.6847941e+03  1.7633387e+03 -3.5736633e+02\n","  -7.1413125e+03  1.6085414e+03  1.2040767e+03  4.0601007e+02\n","   4.2494391e+02 -2.7970527e+03  1.0103843e+04  4.8767737e+02\n","  -7.4308771e+02 -3.6879309e+02 -9.9121564e+02 -6.1588135e+00\n","   1.0435176e+03  6.0944604e+02 -7.1141357e+02 -2.1691309e+02\n","   1.1112974e+03 -1.3066184e+03 -5.9842529e+00  1.1268735e+03\n","  -1.0826979e+02 -9.2731030e+02]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 10\n","Output: [[  2029.2888    3581.75      3835.9802    -907.69006 -14741.674\n","    3277.5825    2727.5366     935.09424    869.41583  -5961.015\n","   20476.373     1070.9209   -1678.7139    -754.4292   -2067.4177\n","    -121.41431   2042.8397    1495.9165   -1476.4264    -671.9868\n","    2591.4502   -2704.8066     247.00781   2662.0837    -116.64627\n","   -2009.5422 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.40% (487/500)\n","Noise 6% ‚Üí Accuracy: 96.60% (483/500)\n","Noise 9% ‚Üí Accuracy: 96.40% (482/500)\n","Noise 12% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 14% ‚Üí Accuracy: 94.20% (471/500)\n","Noise 17% ‚Üí Accuracy: 93.60% (468/500)\n","Noise 20% ‚Üí Accuracy: 96.80% (484/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 14/14)\n","Noise 3% ‚Üí Avg Retention: 97.54% (avg 13/14)\n","Noise 6% ‚Üí Avg Retention: 93.96% (avg 13/14)\n","Noise 9% ‚Üí Avg Retention: 90.39% (avg 12/14)\n","Noise 12% ‚Üí Avg Retention: 87.82% (avg 12/14)\n","Noise 14% ‚Üí Avg Retention: 84.54% (avg 11/14)\n","Noise 17% ‚Üí Avg Retention: 82.86% (avg 11/14)\n","Noise 20% ‚Üí Avg Retention: 80.86% (avg 11/14)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}