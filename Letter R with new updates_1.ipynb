{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPD6cAGo9ObTIjIrSABvfgp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OmUYjLLznDja"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","R_CLASS_INDEX = 17\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'R'\n","# ------------------------\n","def encode_letter_R():\n","    grid = np.array([\n","    [1, 1, 1, 1, 0],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 1, 1, 1, 0],\n","    [1, 0, 1, 0, 0],\n","    [1, 0, 0, 1, 0],\n","    [1, 0, 0, 0, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_R()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([R_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_R = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_R = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_R)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_R()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == R_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == R_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_R()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"1a1f08f7-6340-4ab6-fede-1daf1857d7c8","executionInfo":{"status":"ok","timestamp":1764579547180,"user_tz":-330,"elapsed":406579,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 452.2618, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 17\n","Output: [[ -54.358963  -66.84357  -103.21866   -37.183014  144.18686    14.85334\n","  -139.7681    -35.267914  -74.48418   -46.373707    7.610073   61.20169\n","    29.58364  -189.13162   -96.62355   -50.364143   52.644047  587.6128\n","   -51.751343 -145.16455  -111.64505  -199.5788   -193.96991   -46.42023\n","  -122.28619  -119.85675 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 17\n","Output: [[ -25.09488   -61.952827  -75.73601   -91.78855   212.34076    79.18388\n","  -155.00092   -35.450485  -98.77323  -185.96764    91.99811    70.49463\n","    79.76059  -178.92374  -189.47516  -109.02806    83.398315  758.62756\n","  -121.239365 -179.93709   -34.755554 -328.58798  -238.5713    -40.483673\n","  -197.9508   -174.92886 ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 17\n","Output: [[ -80.76869    -33.325466  -107.90975    -54.354336   134.30463\n","    23.961834  -151.18622    -23.588165   -77.50104    -72.714355\n","    14.929295    -1.7475128   70.95609   -188.34363    -92.09625\n","   -85.03126     41.62457    604.1337     -61.770023  -128.91852\n","   -91.78596   -183.70349   -212.84299    -74.43213   -164.61917\n","  -109.81181  ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 17\n","Output: [[ -50.427803     5.5143585  -85.86255    -81.01318    149.27968\n","    29.884315  -148.78912    -29.065338   -87.74778   -139.18501\n","    51.188248    16.995075    85.95021   -152.91931   -141.59076\n","  -100.90948     48.586533   609.1372     -64.486595  -127.21573\n","   -69.10393   -212.7608    -226.65948    -37.70379   -178.13666\n","  -102.94115  ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 17\n","Output: [[  228.06924    250.70544    191.22256   -245.06815    890.5847\n","    751.8376     326.4312     -31.51886    151.97949  -1051.2249\n","    595.94226    193.75798    244.5817      45.12567  -1028.0328\n","     80.20944    129.98546   1256.4856    -484.36212    -37.542908\n","    662.54346  -1075.1737     -66.85486    453.32596   -324.1663\n","   -551.7416  ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 17\n","Output: [[   3.639534   138.03412    -45.882835   -33.2556     332.62247\n","   210.16342     -7.728409    -3.8413544   -2.9515152 -299.71326\n","   109.28017     10.4019165  109.63552   -108.52191   -317.01865\n","    16.452827   103.68259    683.74854   -122.83505    -10.983517\n","    46.07852   -349.5935    -215.34467     29.172138  -173.48125\n","  -167.51974  ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 17\n","Output: [[-141.78497    -15.725861  -175.47083     -4.335494   115.19821\n","   -45.198055  -181.00383    -25.272444   -81.045616    37.9262\n","   -69.90841    -45.905224    42.36366   -203.46074      7.356472\n","   -55.850975    26.37344    410.05402      2.4124746 -106.17125\n","  -232.88815    -54.936512  -226.68433   -120.505905  -119.329605\n","   -23.521704 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 17\n","Output: [[  115.39469    172.92319     62.61267   -105.6062   -3271.558\n","    214.28381     85.02577    -31.20691     11.059723  -460.16837\n","    183.9639      94.68283     86.30844    -47.109085  -416.32776\n","     22.284065    87.54574   4307.18      -160.91711    -82.97852\n","     99.13614   -432.0144    -109.13051    181.64081   -148.08102\n","   -155.68579 ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 17\n","Output: [[   720.3855      712.6615      653.8163     -223.7218   -11455.953\n","    1099.6726      898.7228       25.536987    362.78754   -1722.6816\n","     826.30237     346.65396     141.34406     213.72809   -1487.2925\n","     360.09885     337.32663   14136.629      -712.4363       80.83905\n","     942.5295    -1534.3324      153.07489     903.70135    -190.84946\n","    -561.71716 ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 17\n","Output: [[-125.660706    3.208622 -175.98038   -24.627365   90.451    -109.31969\n","  -234.21132   -27.816057 -123.31837    33.60316   -76.388306  -36.01406\n","    50.115738 -180.23633    24.97862  -102.779785   38.84792   355.2243\n","    35.71094  -121.85152  -271.77283   -20.46901  -268.67374  -133.24963\n","  -130.13678    19.100742]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 17\n","Output: [[-127.971085   -30.069536  -154.701      -24.329687    78.30095\n","   -64.21448   -173.56442    -36.102577   -80.148544    39.405685\n","   -63.400757   -26.62431     35.193962  -190.92545     11.619097\n","   -63.33718      3.9348965  390.52374     10.803594  -124.82242\n","  -214.82047    -44.64363   -185.12532    -97.361115  -107.81185\n","   -21.331264 ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 17\n","Output: [[-127.971085   -30.069536  -154.701      -24.329687    78.30095\n","   -64.21448   -173.56442    -36.102577   -80.148544    39.405685\n","   -63.400757   -26.62431     35.193962  -190.92545     11.619097\n","   -63.33718      3.9348965  390.52374     10.803594  -124.82242\n","  -214.82047    -44.64363   -185.12532    -97.361115  -107.81185\n","   -21.331264 ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 17\n","Output: [[ 8.8451447e+02  8.6834772e+02  8.7149457e+02 -2.0838603e+02\n","  -1.1491443e+04  1.1648237e+03  1.0686152e+03  6.7241516e+01\n","   4.5491888e+02 -1.7985929e+03  9.2228156e+02  3.7011905e+02\n","  -1.8507080e+00  2.4883887e+02 -1.3695188e+03  3.4683920e+02\n","   4.1953162e+02  1.3880537e+04 -7.9021252e+02  1.0396118e+02\n","   1.0257507e+03 -1.6057853e+03  2.9142957e+02  9.6282324e+02\n","  -4.0356750e+01 -4.7026227e+02]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 17\n","Output: [[-142.12952    -15.485241  -179.58301    -13.3902645  107.285934\n","   -65.652664  -199.87994    -29.440952   -94.08153     39.152077\n","   -73.31248    -41.74087     44.55802   -205.53595     12.519299\n","   -70.52019     25.472717   413.73376     11.681522  -118.88649\n","  -248.81815    -47.790894  -237.83658   -124.101074  -124.99458\n","   -14.832128 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 17\n","Output: [[-126.64361    -13.550777  -163.2846     -19.951141    88.332115\n","   -76.53981   -194.44983    -29.875067   -95.2155      35.891495\n","   -68.1925     -33.401363    41.557663  -184.54327     15.717449\n","   -75.72389     21.841763   371.03412     18.622755  -116.97935\n","  -235.33167    -36.12913   -221.3234    -113.50779   -116.141815\n","    -5.4600453]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 17\n","Output: [[-124.97159      2.7273865 -167.75603     -6.5178328  106.27557\n","   -68.410484  -196.45912    -19.47906    -97.24655     31.15144\n","   -69.580154   -44.34276     45.727013  -176.08588     14.652966\n","   -73.44139     40.64936    347.86487     17.172852   -96.421\n","  -239.91286    -34.760246  -246.36925   -126.05928   -118.80684\n","     1.721591 ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 17\n","Output: [[  594.6127     645.3827     568.902     -118.27617  -7513.051\n","    752.91473    669.6384      64.42456    282.43463  -1196.4789\n","    610.26917    230.33934    -21.122986   138.32016   -862.6172\n","    186.58563    335.78357   9092.599     -521.8342      66.87503\n","    598.001    -1067.628      112.77258    588.85803    -28.066727\n","   -252.68245 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 17\n","Output: [[-119.09829     -3.7226028 -169.70763    -43.679245    64.09009\n","  -139.28252   -249.36774    -37.39962   -135.90573     35.568752\n","   -76.53856    -22.209274    48.72524   -176.04388     32.272766\n","  -121.19208     26.72792    349.1389      49.175552  -143.89236\n","  -278.66898     -8.176949  -259.0465    -125.27238   -130.04288\n","    28.885551 ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 17\n","Output: [[-135.5671    -22.416458 -173.31027   -32.44213    80.925     -95.615456\n","  -215.03633   -39.024513 -106.668884   41.11766   -73.46272   -27.936066\n","    43.167526 -201.34352    19.813448  -88.932465   13.352732  407.64832\n","    25.146128 -140.92735  -255.71431   -35.498833 -228.20932  -116.12386\n","  -124.900665   -5.047324]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 17\n","Output: [[  5274.195     4771.2896    5293.547     -793.23486 -54439.58\n","    5952.4976    6258.8135     695.6272    2772.0356   -8809.423\n","    4824.3877    1986.9705    -577.25146   2149.9768   -6134.0996\n","    1698.605     2274.4626   62458.49     -3948.1685    1092.6875\n","    5905.8438   -7411.7183    2375.9888    4944.922      714.3773\n","   -1753.3037 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 17\n","Output: [[  1793.7751    1671.998     1778.3632    -266.1461  -19024.36\n","    2077.7905    2136.3135     238.50879    955.8211   -3063.844\n","    1660.9641     687.3393    -189.63263    663.28906  -2128.2166\n","     541.8291     799.1362   22010.988    -1390.1862     324.5432\n","    1961.773    -2601.398      722.5465    1652.3162     207.81003\n","    -607.1589 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 17\n","Output: [[  4949.573     4461.5596    4959.3613    -595.0363  -49998.41\n","    5711.7812    6040.1245     746.93555   2761.6748   -8123.558\n","    4460.416     1850.9097    -596.4773    2060.6763   -5602.925\n","    1544.1826    2117.9229   57014.918    -3735.9258    1101.4592\n","    5608.0215   -6765.9395    2199.5364    4448.259      763.514\n","   -1601.1052 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 17\n","Output: [[  4152.148     3736.904     4148.3413    -486.6397  -41898.86\n","    4820.8877    5091.027      640.24414   2350.872    -6799.815\n","    3722.8894    1576.0667    -517.4783    1695.9565   -4680.4287\n","    1249.0828    1774.0643   47765.695    -3147.7883     890.77246\n","    4687.023    -5651.1377    1811.8545    3676.8347     645.2943\n","   -1345.5356 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 17\n","Output: [[  3293.3652    2964.5737    3275.139     -394.95752 -33042.734\n","    3799.45      4010.9207     522.0762    1862.2151   -5361.07\n","    2914.934     1266.0725    -418.0349    1328.7307   -3669.2803\n","     933.2344    1421.8143   37631.       -2479.7524     672.1345\n","    3686.8447   -4439.482     1370.3647    2858.0718     503.20496\n","   -1051.6294 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 17\n","Output: [[-133.206       -6.619543  -169.55734     -0.8992796  114.693016\n","   -46.576965  -179.29343    -20.291508   -82.628136    33.925888\n","   -68.04225    -47.20616     42.948166  -188.7357       8.4233055\n","   -57.311584    33.96176    377.1196       5.1581326  -94.93849\n","  -228.43553    -48.421192  -230.95067   -121.485     -116.23572\n","   -15.244853 ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 17\n","Output: [[  1145.0004    1086.2322    1103.2607    -118.91727 -11880.434\n","    1383.2255    1395.078      192.26587    655.2529   -1921.857\n","    1025.3749     434.95013   -133.10156    403.63934  -1316.1\n","     301.88635    539.4703   13716.477     -908.84235    217.76349\n","    1227.0687   -1617.615      374.6327     948.47784    144.06685\n","    -370.5126 ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 17\n","Output: [[-145.47348   -48.041542 -170.64014   -40.2569     71.39903   -81.911255\n","  -195.86133   -50.232983  -90.019394   48.632164  -70.53716   -19.858093\n","    36.219322 -222.45073    14.648273  -75.08515   -12.142478  460.0723\n","    14.581358 -160.00319  -239.6557    -50.528667 -187.7449    -98.998116\n","  -119.66455   -29.195406]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 17\n","Output: [[  1221.4243    1200.9004    1159.4708     -88.15509 -12718.508\n","    1556.1553    1520.3291     240.10577    725.9211   -2079.1384\n","    1083.3694     443.9867    -142.0658     408.8711   -1427.2214\n","     342.2356     630.0355   14794.868    -1007.55865    267.8053\n","    1311.1512   -1763.1456     331.18762    977.26575    143.87283\n","    -420.0076 ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 17\n","Output: [[  2760.476     2483.0686    2677.9243    -240.91815 -26664.932\n","    3209.381     3381.4048     491.81482   1588.5331   -4360.5728\n","    2342.6074    1047.4226    -364.76868   1124.5549   -2936.6362\n","     718.0366    1216.0327   30151.86     -2066.9475     605.3335\n","    3016.9275   -3544.6118    1049.2427    2221.493      478.0157\n","    -811.06104]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.80% (489/500)\n","Noise 6% ‚Üí Accuracy: 96.60% (483/500)\n","Noise 9% ‚Üí Accuracy: 96.40% (482/500)\n","Noise 12% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 14% ‚Üí Accuracy: 94.80% (474/500)\n","Noise 17% ‚Üí Accuracy: 93.60% (468/500)\n","Noise 20% ‚Üí Accuracy: 96.80% (484/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 18/18)\n","Noise 3% ‚Üí Avg Retention: 97.39% (avg 17/18)\n","Noise 6% ‚Üí Avg Retention: 93.83% (avg 16/18)\n","Noise 9% ‚Üí Avg Retention: 90.50% (avg 16/18)\n","Noise 12% ‚Üí Avg Retention: 87.81% (avg 15/18)\n","Noise 14% ‚Üí Avg Retention: 85.25% (avg 15/18)\n","Noise 17% ‚Üí Avg Retention: 83.14% (avg 14/18)\n","Noise 20% ‚Üí Avg Retention: 80.06% (avg 14/18)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}