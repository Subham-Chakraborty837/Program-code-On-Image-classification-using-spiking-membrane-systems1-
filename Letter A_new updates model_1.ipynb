{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGIqLn3dEk28qVQW/LWpLD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"MKiT661ybH9T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","A_CLASS_INDEX = 0\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'A'\n","# ------------------------\n","def encode_letter_A():\n","    grid = np.array([\n","        [0, 0, 1, 0, 0],\n","        [0, 1, 0, 1, 0],\n","        [1, 0, 0, 0, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 0, 0, 0, 1],\n","        [1, 0, 0, 0, 1],\n","        [1, 0, 0, 0, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_A()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([A_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_A = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_A = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_A)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_A()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == A_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == A_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_A()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","executionInfo":{"status":"ok","timestamp":1765272643825,"user_tz":-330,"elapsed":258289,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}},"outputId":"02484c04-ee47-450d-b81a-4bb959d64f57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 340.7761, Predicted Index: 8\n","Output: [[-107.46562   -86.58119   -65.648544   56.368416  -16.921783  -46.78425\n","  -146.7969    -30.6078    233.31049    94.30464  -106.851974   -7.716512\n","    15.722309  -71.16066    45.64531    95.45817     5.073925 -218.95131\n","    75.063416   51.873108   80.125595  169.40639  -201.54193  -210.65039\n","  -121.93263   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 390.41342   -129.106      -23.894978    57.598263    84.69662\n","   -45.53135    -96.03798    -87.2378       5.4866266   81.451225\n","   -26.010754    86.31819     23.728823   -42.01634    -97.48688\n","   121.13432    110.03923   -228.84438    -28.854805    37.37793\n","   197.76855   -166.73006   -147.02023   -116.64503    -43.462524\n","   -22.874529 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 0\n","Output: [[1069.8762    -102.818726     6.2571564   73.71859    147.01134\n","    15.168076  -101.34212   -136.21184      6.1322174   21.488968\n","    45.02735    174.30309     83.68564    -25.525467  -266.88217\n","   167.99283    200.96704   -345.828      -64.270355    80.34631\n","  -201.18146   -337.05936   -157.14816   -144.48082     -5.502652\n","   -11.795293 ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 7.87422485e+02 -9.80039291e+01 -3.16464195e+01  9.10416107e+01\n","   7.92130432e+01 -1.40615845e+00 -1.02975403e+02 -1.27040680e+02\n","   1.42350140e+01  7.64962769e+01 -1.99099579e+01  8.36759949e+01\n","   6.78381195e+01 -5.85059128e+01 -1.47087860e+02  1.17789398e+02\n","   1.15723976e+02 -2.78715424e+02 -2.69159355e+01  6.47296448e+01\n","  -2.02072235e+02 -1.86455566e+02 -1.49675873e+02 -1.50761780e+02\n","  -6.60935211e+00  4.17306423e-01]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 8.51005005e+02 -5.46707039e+01  1.72808456e+01  6.17298164e+01\n","   1.15698700e+02  8.94104767e+00 -1.17044891e+02 -1.21676880e+02\n","   2.98207169e+01  5.62776184e+00  1.21610489e+01  1.31793106e+02\n","   6.78996429e+01 -5.95159340e+01 -1.96443558e+02  1.14547356e+02\n","   1.37061432e+02 -2.90556366e+02 -1.74077034e+01  5.04313965e+01\n","  -1.82349030e+02 -2.46817657e+02 -1.64480301e+02 -1.10332169e+02\n","  -7.63995934e+00 -3.27192068e-01]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 1784.9119      302.88748     547.5658     -110.90588    1050.7255\n","    738.2489       72.8947        8.859985    531.95105    -851.05365\n","    564.4155      781.45715      20.349464    -83.93112   -1131.3151\n","    650.6453      450.95117    -267.1313     -248.28351     102.13025\n","    446.82858   -1438.4783       74.06131     371.84344       3.4042816\n","   -451.6787   ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 900.07605    80.38794   118.46781    79.657974  317.03174   203.21532\n","   -61.33835   -62.150055  166.75734  -212.33       77.4404    203.6796\n","    20.419548  -73.102844 -326.66266   200.56573   203.68863  -217.33035\n","   -60.183205  104.18933   -52.659172 -418.0777   -167.35507    -7.467972\n","   -22.296951 -100.17817 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 545.61334    -98.66873    -73.8828     132.95985    -21.359344\n","   -65.27208   -105.19798   -123.26931    -12.9296875  135.42426\n","  -111.66923    -22.459488    45.227875   -80.147995     6.9273148\n","    21.980385    56.945934  -218.24728      7.2438507   56.015907\n","  -248.61093      5.5203476 -189.8936    -173.65002    -15.719334\n","    47.8863   ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 5200.772       144.03777     276.43887     -49.282196  -3817.5237\n","    201.83252     -30.844131    -71.8148      228.33911    -405.7879\n","    151.36995     328.81723     -60.14267     -69.70424    -392.58978\n","    181.39496     170.98483    -188.87408     -52.6483       10.489899\n","     -5.2395477  -519.6425      -92.26903     188.37946     -28.799501\n","   -139.59387  ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 16973.162       845.61743    1231.2544     -481.38922  -13328.554\n","    1059.8733      297.42065     196.37482     945.9346    -1787.4592\n","     784.0361     1076.6022     -409.87506    -242.73007   -1326.6862\n","     798.3655      487.71375     162.29523    -290.17346      24.358154\n","     725.6428    -1905.0134       43.391357   1139.9915     -143.52144\n","    -828.1299  ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 512.1525    -113.96045    -87.806564   148.59686     52.000557\n","  -134.88489   -145.2739    -169.34685    -48.76615    142.91565\n","  -124.92057    -10.291358    64.67486    -24.366035     9.8239155\n","   -50.139034    78.8648    -313.81665     25.341057    51.831017\n","  -349.89166     46.30051   -227.07632   -203.85715     -3.8827956\n","   130.32504  ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 488.99435   -134.25299    -75.34145    129.65384     35.240875\n","   -87.01806    -94.41742   -161.64963    -13.294174   136.99083\n","  -106.69495     -3.500161    47.79476    -51.96368     -1.5326672\n","   -12.223244    39.53215   -252.87311      2.0321808   30.468071\n","  -279.79498     15.637085  -147.86629   -160.11427      4.5048714\n","    77.17999  ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 488.99435   -134.25299    -75.34145    129.65384     35.240875\n","   -87.01806    -94.41742   -161.64963    -13.294174   136.99083\n","  -106.69495     -3.500161    47.79476    -51.96368     -1.5326672\n","   -12.223244    39.53215   -252.87311      2.0321808   30.468071\n","  -279.79498     15.637085  -147.86629   -160.11427      4.5048714\n","    77.17999  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 16976.41      1036.8486    1434.8921    -618.7187  -13563.19\n","    1070.0598     504.06244    349.8867     966.43604  -1985.0955\n","     857.77985   1022.2421    -582.61487   -375.73984  -1210.5594\n","     700.61304    443.38623    533.95746   -403.17316   -111.54529\n","     922.25494  -1989.3105      70.2124    1377.9265    -132.91388\n","    -939.4006 ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 532.97516   -133.51646    -90.34504    161.21301     58.334084\n","   -91.44405   -110.19992   -171.95358    -18.809258   149.48244\n","  -122.279465   -15.751976    59.125923   -48.40543     -2.6253128\n","   -15.218571    65.80646   -287.39893      1.3881912   56.471046\n","  -325.15192     20.449642  -195.87802   -195.25537      2.288354\n","    97.09052  ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 490.9191    -122.15357    -81.11778    140.62839     46.584152\n","  -100.27103   -111.96519   -160.94402    -25.878273   137.40445\n","  -113.24638     -9.4538965   54.910572   -39.915234     1.8131008\n","   -24.825867    58.9451    -273.3084       9.203651    44.40644\n","  -305.5483      26.363907  -182.66258   -178.95258      0.9313524\n","    97.47055  ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 473.53516   -106.14783    -85.98166    154.60902     63.854332\n","   -92.16313   -113.75204   -151.12997    -28.158539   132.72054\n","  -114.67512    -20.523975    59.377922   -31.367577     0.493824\n","   -24.717976    77.85125   -273.67065      7.409233    64.8586\n","  -312.71167     27.880974  -207.84152   -191.72462     -1.4016044\n","   105.19728  ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 0\n","Output: [[11322.936      727.62744    963.4743    -369.72415  -9000.547\n","    730.9092     405.05066    268.70636    657.5614   -1331.5991\n","    532.71436    657.1921    -407.94232   -267.50232   -780.1265\n","    386.66223    330.15216    363.53558   -317.43024    -78.11194\n","    606.6739   -1306.2869     -61.99179    870.7449     -69.524155\n","   -622.2613  ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 519.12524   -120.18818    -81.67345    128.30817     31.56366\n","  -164.7132    -161.02403   -177.85753    -61.464325   144.31616\n","  -124.81238      3.5089874   62.982025   -20.894012    17.367798\n","   -67.70717     66.48781   -326.66315     39.111908    29.058834\n","  -355.09814     57.7089    -217.49655   -195.38599     -4.635432\n","   139.21558  ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 539.9479    -139.74419    -84.21193    140.92432     37.897133\n","  -121.27235   -125.95008   -180.46426    -31.507408   150.88297\n","  -122.17129     -1.9516096   57.433064   -44.93338      4.918564\n","   -32.78671     53.42945   -300.24548     15.159058    33.69886\n","  -330.3584      31.858025  -186.29825   -186.78421      1.5357213\n","   105.98105  ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 78239.78      6054.0386    7591.701    -3707.5508  -65206.82\n","    5989.1016    4037.4685    3125.066     5007.187   -10523.514\n","    4527.6055    4829.398    -3439.3276   -1781.5784   -5542.8184\n","    2693.4426    1875.9661    4628.4575   -2534.6277   -1125.9907\n","    6674.4155   -9557.667      793.35864   7529.926     -418.49075\n","   -5281.0635 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 27678.79      2070.3472    2640.4226   -1226.373   -22854.695\n","    2063.113     1398.7233    1029.3647    1769.437    -3624.8892\n","    1531.0132    1692.5555   -1195.2578    -663.8841   -1931.5549\n","     916.5967     673.0085    1510.1836    -905.08264   -383.89624\n","    2219.8887   -3343.2239     180.14185   2564.0874    -135.27982\n","   -1817.765  ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 71838.41      5696.76      7074.3066   -3412.9146  -60071.957\n","    5674.373     3963.5605    3038.3386    4727.538    -9780.172\n","    4196.8145    4417.1914   -3247.542    -1684.1755   -5074.63\n","    2420.6943    1713.031     4491.364    -2460.0312   -1053.4668\n","    6393.0586   -8838.367      706.8635    7006.5215    -344.16245\n","   -4966.755  ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 60350.33      4758.351     5936.0337   -2845.      -50402.75\n","    4765.156     3371.6333    2540.359     3985.0928   -8196.865\n","    3490.0513    3706.0527   -2736.808    -1446.098    -4243.873\n","    1981.8934    1425.0066    3756.9321   -2092.522     -916.2114\n","    5351.3154   -7405.202      564.0735    5852.9175    -276.61063\n","   -4179.4297 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 47685.656    3758.3186   4681.9087  -2240.174  -39780.605    3743.4026\n","    2675.897    2006.115    3128.138   -6463.626    2726.8357   2918.6602\n","   -2158.1626  -1138.3127  -3333.7505   1503.4485   1145.5598   2935.792\n","   -1665.6849   -743.6123   4193.1934  -5820.956     392.099    4580.922\n","    -214.3152  -3283.5857]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 483.9464    -115.92586    -87.25089    160.91708     67.021095\n","   -70.442696   -96.21504   -152.43335    -13.180107   136.00394\n","  -113.354576   -23.254282    56.60343    -43.387276    -5.730795\n","    -7.257744    71.322075  -260.46185     -4.5671997   67.17863\n","  -300.34186     14.955528  -192.24234   -187.42374      1.6839752\n","    88.58003  ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 17459.215      1324.7634     1668.5724     -721.6528   -14359.406\n","    1337.1316      954.612       675.2708     1148.0134    -2281.655\n","     933.4485     1042.6099     -768.4082     -445.70123   -1200.0554\n","     527.7208      446.49957     961.2793     -622.4911     -232.2168\n","    1399.8241    -2100.2986       29.114868   1573.1077      -68.21962\n","   -1153.6864  ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 5.6774316e+02 -1.6552792e+02 -8.0617317e+01  1.3325177e+02\n","   2.3793720e+01 -1.0765982e+02 -1.0662623e+02 -1.9158167e+02\n","  -1.4248642e+01  1.5885031e+02 -1.1942200e+02  6.3881488e+00\n","   5.0191265e+01 -6.5500725e+01  1.3242722e-02 -1.5434364e+01\n","   2.7994141e+01 -2.8667435e+02  4.9770813e+00  1.5566704e+01\n","  -3.1082516e+02  1.7415527e+01 -1.4552020e+02 -1.6971133e+02\n","   6.9542193e+00  8.1637070e+01]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 18852.154      1436.7122     1774.8859     -716.0521   -15413.566\n","    1494.2959     1063.2568      738.1612     1251.3285    -2451.3354\n","     981.3058     1088.4652     -820.6511     -488.23883   -1303.7273\n","     581.94574     532.44495    1035.9237     -709.394      -200.90137\n","    1480.6423    -2277.6006      -34.132996   1643.4817      -67.12579\n","   -1249.764   ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 0\n","Output: [[ 38499.08      3128.358     3850.2148   -1781.4594  -32176.883\n","    3096.9226    2307.07      1722.0238    2580.9607   -5282.4688\n","    2192.0327    2355.285    -1810.471     -960.6961   -2657.4617\n","    1143.0864     955.00195   2488.94     -1432.2217    -607.6128\n","    3487.054    -4714.251      228.04846   3714.8987    -125.31264\n","   -2696.5737 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.40% (487/500)\n","Noise 6% ‚Üí Accuracy: 96.80% (484/500)\n","Noise 9% ‚Üí Accuracy: 97.20% (486/500)\n","Noise 12% ‚Üí Accuracy: 96.60% (483/500)\n","Noise 14% ‚Üí Accuracy: 96.40% (482/500)\n","Noise 17% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 20% ‚Üí Accuracy: 98.20% (491/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 16/16)\n","Noise 3% ‚Üí Avg Retention: 97.47% (avg 15/16)\n","Noise 6% ‚Üí Avg Retention: 93.91% (avg 15/16)\n","Noise 9% ‚Üí Avg Retention: 91.00% (avg 14/16)\n","Noise 12% ‚Üí Avg Retention: 87.88% (avg 14/16)\n","Noise 14% ‚Üí Avg Retention: 85.03% (avg 13/16)\n","Noise 17% ‚Üí Avg Retention: 82.66% (avg 13/16)\n","Noise 20% ‚Üí Avg Retention: 81.19% (avg 12/16)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}