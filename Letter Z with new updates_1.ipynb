{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZDPwnA4ijfDFysccHQvD7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kTegR2BzxIP2"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","Z_CLASS_INDEX = 25\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'Z'\n","# ------------------------\n","def encode_letter_Z():\n","    grid = np.array([\n","    [1, 1, 1, 1, 1],\n","    [0, 0, 0, 0, 1],\n","    [0, 0, 0, 1, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 1, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 1, 1, 1, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_Z()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([Z_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_Z = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_Z = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_Z)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_Z()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == Z_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == Z_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_Z()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"52c659ee-0891-4f5d-ee67-bce66c84b372","executionInfo":{"status":"ok","timestamp":1764582246150,"user_tz":-330,"elapsed":415819,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 266.3856, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 25\n","Output: [[  47.33769    -85.24403     19.990112    92.52676    -18.38095\n","   -49.562523   -55.877174  -114.925415     1.3222122   66.46289\n","    11.369576   103.482956    59.724136   -52.97226    -85.920616\n","    53.759857   119.06274   -241.6483      -3.3545456   80.504654\n","  -128.98412    -43.362324  -222.81573   -166.2446    -115.20601\n","   549.6716   ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 25\n","Output: [[  64.75578   -128.71178     83.30377     96.93874     30.44625\n","   -15.575542    38.772995  -102.87537     67.979546     3.2819061\n","    37.20895    150.03943     93.68202    -65.87076   -164.44406\n","   -56.04685    186.07755   -390.56494    -65.418335    88.19203\n","   -17.213196   -76.44951   -337.1419    -260.74802   -178.06558\n","   673.8015   ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 25\n","Output: [[  12.241615   -68.108826    14.4743      89.15498    -23.00874\n","   -35.995598   -58.915085  -100.05296     38.628517    60.222702\n","    -3.7983313   79.876175    83.57313    -54.89035    -72.57267\n","     1.3050957  129.21298   -294.88004      1.2156029   94.15651\n","   -90.8199     -22.518585  -256.38263   -228.79788   -141.96428\n","   566.43945  ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 25\n","Output: [[   79.694084      3.0133438    57.220554    106.899284    -36.624237\n","    -12.120209    -64.33034    -147.96555      14.807327    -21.307999\n","     32.403214    123.42073     109.860214    -17.04338    -114.32096\n","    -73.05003     183.29266    -358.52344       8.189896    115.67256\n","  -1285.3573       -6.87648    -298.5192     -236.30449    -144.20581\n","   1769.7188   ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 25\n","Output: [[  161.17859   136.32036   601.2894     71.04346   832.50696   836.89453\n","    687.97003  -155.695     640.63306  -875.9527    292.71252   494.84677\n","    107.15988   -67.151    -667.11005  -398.6867    430.75888  -747.8268\n","   -416.84088   132.82864 -4666.5864   -473.58447  -315.1314   -267.5597\n","   -236.97661  5980.0117 ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 25\n","Output: [[   77.9629     109.80313    129.31541    140.05432    171.0502\n","    228.96924     83.72385   -131.04022    153.13008   -218.92722\n","     64.35815    140.03064     99.87466    -33.396194  -208.31383\n","    -37.66693    248.0101    -352.54813    -77.441154   203.11998\n","  -1713.7308    -110.71443   -296.55322   -236.9766    -132.15924\n","   2254.8052  ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 25\n","Output: [[  30.507828    6.610176  -68.88667   128.94012  -140.17412   -86.57566\n","  -172.72913  -138.83394   -60.79951   126.94374   -27.246447   17.827065\n","    88.750885  -33.639526   -9.9338     75.61495   109.92583  -199.23232\n","    78.14344   144.432    -442.53278    52.049778 -229.75072  -201.39575\n","   -93.00865   680.99524 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 25\n","Output: [[   87.70395    156.87631    263.51392     18.20826    340.04535\n","    282.78705    131.83711   -132.98164    221.3633    -435.1914\n","    102.226006   224.92017     42.339287   -54.13919   -218.83292\n","    -86.14038    200.31166   -353.24963   -109.49619    104.36833\n","  -2176.6978    -182.20093   -194.98087   -110.837265  -124.83453\n","   2697.772   ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 25\n","Output: [[  168.36975   590.0924   1109.5275   -172.41734  1742.7278   1421.8604\n","    949.5504    -80.99579  1028.4851  -1894.9191    430.9424    634.0256\n","   -124.70087  -222.12463  -741.5747   -240.70901   454.25348  -542.5774\n","   -666.7897    134.85986 -6563.5723   -882.9409   -125.5108    175.45746\n","   -226.80365  7649.5376 ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 25\n","Output: [[  52.42227     26.552109   -66.76788    113.04399   -193.16464\n","  -151.7862    -225.6886    -145.51843   -103.524185   125.017166\n","   -32.094517    29.570415    98.32816     -5.7657967    6.580761\n","    29.87587    125.267365  -243.77994    113.51686    136.20166\n","  -491.20605     88.22244   -272.54816   -216.41661   -102.91135\n","   742.3828   ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 25\n","Output: [[  30.235283   -9.605026  -56.72128    97.97854  -135.66394  -102.09252\n","  -165.89996  -140.40587   -61.629257  121.11203   -24.311827   31.89802\n","    77.63677   -35.160355   -4.299286   58.87285    80.648926 -190.86012\n","    80.36048   105.33177  -420.5166     53.294796 -187.96622  -171.36026\n","   -83.49551   639.2976  ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 25\n","Output: [[  30.235283   -9.605026  -56.72128    97.97854  -135.66394  -102.09252\n","  -165.89996  -140.40587   -61.629257  121.11203   -24.311827   31.89802\n","    77.63677   -35.160355   -4.299286   58.87285    80.648926 -190.86012\n","    80.36048   105.33177  -420.5166     53.294796 -187.96622  -171.36026\n","   -83.49551   639.2976  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 25\n","Output: [[  152.94885    743.2573    1233.6414    -322.99603   1965.0555\n","   1496.6228     949.21857     12.17334   1032.6423   -2155.4346\n","    490.9865     581.33386   -301.4483    -337.888     -642.78516\n","   -187.30429    313.002     -182.34938   -730.11005    -54.125305\n","  -6615.208    -1055.6992      83.54199    508.4458    -152.45293\n","   7281.0933  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 25\n","Output: [[  36.746674     7.7506866  -69.111435   124.944046  -157.65392\n","  -108.5195    -191.2811    -147.4187     -73.32605    131.43307\n","   -28.995571    24.36324     92.742836   -29.495693    -5.556389\n","    65.58812    112.22909   -216.89192     90.20688    141.08783\n","  -469.9713      62.802425  -241.18042   -207.92404    -97.631165\n","   718.5367   ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 25\n","Output: [[  38.20935      7.9032745  -61.63219    107.50931   -155.6744\n","  -115.96744   -186.51831   -138.66977    -76.31343    120.81993\n","   -27.328604    27.46614     85.98647    -22.534996    -1.0479736\n","    49.38778    101.80652   -208.49023     90.90695    122.43881\n","  -442.14206     65.38231   -224.54233   -190.6243     -90.89216\n","   672.0695   ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 25\n","Output: [[  39.944557    24.271095   -66.31834    121.036156  -158.20506\n","  -107.8985    -188.58466   -128.34888    -78.47108    116.03848\n","   -28.596268    16.498085    90.344246   -14.053467    -2.1740723\n","    49.929558   120.66086   -208.46075     89.39       142.89001\n","  -436.32898     66.71715   -249.68875   -203.36002    -93.66631\n","   667.29987  ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 25\n","Output: [[  110.04773    584.40405    800.7173    -198.0706    1281.6102\n","    983.53516    568.8284      23.509766   634.44934  -1475.7506\n","    346.2369     364.41064   -216.86378   -250.04346   -412.7861\n","   -121.653656   233.86082    -53.525772  -496.72287    -61.61798\n","  -4460.2563    -763.6774      21.587646   353.9085     -84.701996\n","   4883.788   ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 25\n","Output: [[  58.52485    19.585007  -60.909958   93.56715  -208.38934  -181.48845\n","  -240.826    -154.88916  -116.46559   126.59065   -32.376328   43.142067\n","    96.76304    -2.382393   13.775444   11.477959  112.93216  -257.25342\n","   126.6888    113.30736  -507.63654    99.597626 -263.08557  -207.92715\n","  -102.7773    759.07556 ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 25\n","Output: [[  42.84926      0.7835922  -63.253532   105.467186  -172.8786\n","  -138.2218    -206.41849   -156.78946    -86.26749    133.00656\n","   -29.277374    37.934887    91.17773    -26.11229      1.6383018\n","    47.190216    99.89389   -230.36542    103.378815   118.19355\n","  -486.4018      74.1776    -231.71785   -199.43457    -97.49709\n","   735.22943  ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 25\n","Output: [[   569.75977   4298.18      6228.508    -2254.2173   10291.826\n","    7852.2656    5276.335     1108.8555    4973.381   -11601.414\n","    2772.0298    2432.9556   -2270.4453   -1820.0332   -2912.3438\n","   -1248.3435     826.82654   1372.3223   -4279.8857   -1650.417\n","  -29200.705    -6208.885     1954.3086    4139.1084     149.19849\n","   30483.76   ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 25\n","Output: [[   218.4502     1522.7068     2145.4243     -742.0864     3538.9478\n","    2727.5986     1777.0269      328.6349     1727.4207    -4029.9\n","     959.3679      877.67676    -767.13495    -655.96265   -1018.89795\n","    -411.47046     321.1909      413.1455    -1473.7959     -541.4967\n","  -10430.713     -2165.7275      594.12976    1368.973        23.800232\n","   10967.643   ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 25\n","Output: [[   540.66406   4048.4084    5737.2197   -2078.9521    9575.964\n","    7504.208     5073.1953    1174.1206    4711.0283  -10845.613\n","    2561.777     2229.495    -2182.935    -1689.6602   -2701.9001\n","   -1165.7057     710.4507    1523.1641   -4099.23     -1609.802\n","  -26578.867    -5831.497     1902.5269    3895.7407     255.20117\n","   27538.645  ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 25\n","Output: [[   475.20947   3411.0107    4800.509    -1737.3694    8007.128\n","    6328.788     4268.8354     991.25      3963.704    -9104.496\n","    2139.2231    1898.8386   -1842.9451   -1434.1162   -2274.6294\n","    -982.06836    588.8117    1295.8026   -3456.315    -1380.0045\n","  -22323.34     -4898.6113    1581.4453    3255.0378     227.72217\n","   23128.828  ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 25\n","Output: [[   416.9546    2722.6104    3788.4343   -1362.3525    6272.6387\n","    4997.3       3361.8865     803.2634    3108.8945   -7186.914\n","    1679.9631    1511.0287   -1453.8289   -1126.0325   -1800.8206\n","    -810.417      487.72736   1011.2395   -2730.3877   -1108.679\n","  -17665.885    -3853.2048    1199.0273    2541.3662     188.85706\n","   18314.     ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 25\n","Output: [[  32.10676     14.870369   -67.4901     126.98617   -140.44968\n","   -86.26517   -171.38089   -129.29901    -63.372017   119.24642\n","   -27.046795    13.894485    87.55159    -25.918407    -8.2426605\n","    67.785675   114.14172   -195.01674     77.73499    145.33308\n","  -425.7116      54.007145  -234.00487   -199.11371    -91.02622\n","   655.3767   ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 25\n","Output: [[  168.03162  1013.9218   1327.3331   -428.87323  2209.2107   1804.4902\n","   1156.1705    246.9491   1117.3777  -2567.3015    593.0956    555.23096\n","   -493.64548  -415.05164  -654.5526   -258.90082   226.36786   303.3734\n","   -967.6832   -339.84088 -6555.4214  -1384.5897    325.2943    825.88464\n","     39.95749  6869.902  ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 25\n","Output: [[  33.276237   -24.98491    -59.73917     97.890366  -152.59256\n","  -124.6574    -187.1484    -168.06049    -69.01079    140.99597\n","   -26.46025     46.299366    84.027306   -46.458782    -3.3041763\n","    64.504585    74.52038   -216.95087     93.2408     100.18544\n","  -481.5974      60.13274   -190.88756   -182.45259    -92.08287\n","   728.0759   ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 25\n","Output: [[  191.07263   1128.5149    1413.3024    -399.79633   2382.526\n","   2010.6438    1264.5586     287.2069    1217.8469   -2765.4749\n","    632.82117    572.9147    -521.09595   -453.83252   -723.3158\n","   -249.53705    292.9449     341.8638   -1070.0486    -310.57697\n","  -7078.827    -1509.7163     286.7406     845.1857      42.099915\n","   7436.158   ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 25\n","Output: [[   380.0481    2304.6177    3048.015    -1078.9475    5093.1787\n","    4216.5254    2828.5688     744.0365    2588.824    -5923.664\n","    1352.6729    1228.5231   -1219.2402    -897.938    -1459.8597\n","    -682.4054     384.6079     956.9146   -2299.1501    -950.00464\n","  -14158.191    -3189.3535     982.77905   2072.9668     234.90607\n","   14555.73   ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 75.20% (376/500)\n","Noise 6% ‚Üí Accuracy: 67.00% (335/500)\n","Noise 9% ‚Üí Accuracy: 59.80% (299/500)\n","Noise 12% ‚Üí Accuracy: 53.20% (266/500)\n","Noise 14% ‚Üí Accuracy: 56.20% (281/500)\n","Noise 17% ‚Üí Accuracy: 44.40% (222/500)\n","Noise 20% ‚Üí Accuracy: 42.00% (210/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 15/15)\n","Noise 3% ‚Üí Avg Retention: 97.30% (avg 14/15)\n","Noise 6% ‚Üí Avg Retention: 93.90% (avg 14/15)\n","Noise 9% ‚Üí Avg Retention: 90.93% (avg 13/15)\n","Noise 12% ‚Üí Avg Retention: 88.13% (avg 13/15)\n","Noise 14% ‚Üí Avg Retention: 85.93% (avg 12/15)\n","Noise 17% ‚Üí Avg Retention: 82.57% (avg 12/15)\n","Noise 20% ‚Üí Avg Retention: 79.30% (avg 11/15)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}