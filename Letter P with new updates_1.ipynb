{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8IjXhmNB6sz1X3CCcdXC+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pncC-mDXysVw"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","P_CLASS_INDEX = 15\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'P'\n","# ------------------------\n","def encode_letter_P():\n","    grid = np.array([\n","    [1, 1, 1, 1, 0],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 1, 1, 1, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_P()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([P_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_P = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_P = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_P)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_P()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == P_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == P_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_P()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"c91bbd16-09e6-4f93-858b-e26422c4cc28","executionInfo":{"status":"ok","timestamp":1764576186615,"user_tz":-330,"elapsed":426510,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 137.8523, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 15\n","Output: [[ -10.883629 -159.95354    52.25608    38.49868    77.56505   -46.202198\n","   -51.908066 -130.59222   -10.998428   81.11286   -54.218956  142.74025\n","    -8.627472  -88.316956  -47.95024   551.05286    96.89732  -209.80626\n","    17.082722   54.432808  -94.42492    41.804604 -233.16185   -84.11717\n","  -106.84329   -10.504162]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 15\n","Output: [[  69.245384  -158.03503    149.37646      0.7404556  229.5787\n","     8.192975     5.1419067 -205.23413    -26.900215   -12.828049\n","   -52.574608   264.174       -4.583679  -153.469     -135.14919\n","   651.5562     240.43307   -302.16443     12.04623     63.285362\n","  -119.70934    -72.20892   -414.34082   -120.93291    -86.0571\n","   -13.237057 ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 15\n","Output: [[ -19.495682  -112.81427     57.16543      2.056778   133.89801\n","   -13.254101   -74.28197   -144.95688     -1.5692749   26.63564\n","   -82.416046   141.12468     -5.512308  -125.10694    -65.62866\n","   552.5647     146.7174    -227.48804     61.133526    54.903824\n","  -123.87649      9.386696  -292.08157   -123.229065   -69.84386\n","   -20.74733  ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 15\n","Output: [[ 4.48547363e-01 -1.18524185e+02  8.83307114e+01 -3.88828354e+01\n","  -9.15426270e+02 -1.71119003e+01 -8.28287659e+01 -1.87200455e+02\n","  -8.50026703e+00 -4.03569641e+01 -7.30833817e+01  2.11607986e+02\n","  -8.68796635e+00 -1.05880875e+02 -9.71217651e+01  1.66260571e+03\n","   1.92439362e+02 -2.75823853e+02  7.48734894e+01  3.87962799e+01\n","  -1.32074432e+02 -5.49967880e+01 -3.02407501e+02 -1.31381958e+02\n","  -4.82568703e+01  2.24393463e+00]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 15\n","Output: [[  401.20575     59.47406    723.2131    -273.51154  -3946.3784\n","    640.4107     619.2426    -405.30554    126.96091   -888.3074\n","    226.1079     800.7561      17.214828  -486.02914   -635.1808\n","   6030.459      715.13586   -361.79532   -262.9424     -91.08765\n","    281.74557  -1107.3645    -492.2509    -247.8683     179.12027\n","   -293.65234 ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 15\n","Output: [[ 7.6452637e+00  1.4764221e+01  2.0276213e+02 -4.4821312e+01\n","  -1.2593445e+03  1.7102802e+02  3.1214432e+01 -1.5756168e+02\n","   6.5951500e+01 -2.3356604e+02 -4.1080284e+00  2.1846912e+02\n","  -2.1055010e+01 -1.4722214e+02 -1.6105139e+02  2.2375024e+03\n","   2.6788989e+02 -2.3508624e+02 -1.3315220e+00  8.8424828e+01\n","   6.2015839e+00 -2.2399915e+02 -2.9319925e+02 -1.7085178e+02\n","  -4.5527184e+01 -6.3158447e+01]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 15\n","Output: [[-131.40887  -117.04428   -49.764732   29.791    -140.25302   -73.45366\n","  -187.88681  -102.41954    23.760185  112.82503  -114.292145   29.867935\n","   -25.196259  -34.466736   18.579117  653.80505    45.826473 -188.136\n","   113.574196   93.42106  -139.4776    135.7073   -179.06909  -110.90497\n","   -98.368515   19.648636]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 15\n","Output: [[   65.08232     125.87918     352.72058    -170.02512   -1686.9644\n","    195.97807      49.210693   -164.37616      71.311134   -429.30563\n","     68.29189     301.50397     -52.79033    -179.44847    -175.57016\n","   2654.8699      252.0477     -222.25388     -25.692108     -4.5560303\n","    105.44122    -336.78122    -182.59647    -105.534195    -58.497086\n","    -82.99593  ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 15\n","Output: [[  416.09216    808.69354   1334.474     -547.7426   -5302.954\n","   1093.1339     648.83386   -239.3794     352.68707  -1817.0846\n","    497.31662    844.4236    -164.98535   -619.8613    -668.952\n","   7879.7886     786.7262    -197.61157   -453.4297     -49.451294\n","    796.4157   -1533.7999    -170.51306   -111.04964    -60.737816\n","   -455.22797 ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 15\n","Output: [[-115.23223  -101.13841   -47.018745   10.297649 -189.43636  -138.30324\n","  -241.35849  -107.3481    -15.5765    110.47898  -121.99254    41.937325\n","   -19.385963   -6.415167   36.421715  619.03156    58.87767  -232.28043\n","   149.90314    83.18245  -178.19653   175.26172  -219.64554  -123.180626\n","  -108.554245   63.6616  ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 15\n","Output: [[-118.3344   -122.98545   -39.185146    7.010681 -149.02516   -90.10474\n","  -179.77417  -106.85388    16.061546  108.162766 -104.11767    42.9142\n","   -26.83208   -35.81026    21.94867   604.14307    21.792511 -180.74652\n","   112.81476    58.45675  -129.36539   129.65059  -141.33841   -88.49235\n","   -88.481285   18.25187 ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 15\n","Output: [[-118.3344   -122.98545   -39.185146    7.010681 -149.02516   -90.10474\n","  -179.77417  -106.85388    16.061546  108.162766 -104.11767    42.9142\n","   -26.83208   -35.81026    21.94867   604.14307    21.792511 -180.74652\n","   112.81476    58.45675  -129.36539   129.65059  -141.33841   -88.49235\n","   -88.481285   18.25187 ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 15\n","Output: [[  436.25983    972.4599    1468.7435    -603.41675  -5191.531\n","   1126.8428     650.1942    -108.28931    436.6015   -2041.6404\n","    571.8592     759.8506    -251.91144   -599.03687   -614.432\n","   7614.1265     677.8713       8.713699  -520.1512    -140.86725\n","    838.9557   -1536.734       59.554565   137.94138   -118.29288\n","   -498.1383  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 15\n","Output: [[-131.39807   -120.5664     -49.26716     21.964638  -159.81659\n","   -94.92717   -207.00885   -109.47089     14.5943985  116.790276\n","  -119.32428     36.838104   -25.509003   -30.285313    24.141739\n","   667.1633      45.651054  -205.38153    126.92235     88.055595\n","  -152.5609     149.68033   -188.42886   -114.08977   -103.23249\n","    29.96188  ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 15\n","Output: [[-116.788704 -110.30087   -43.35074    12.567355 -159.44899  -103.46723\n","  -201.00528  -103.57532     4.825409  107.33823  -110.53903    38.940674\n","   -22.952648  -23.203442   26.403881  604.9082     40.42279  -197.8907\n","   124.684875   73.502335 -147.2393    145.46964  -175.81209  -104.24409\n","   -96.08576    35.80011 ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 15\n","Output: [[-115.2538    -94.09422   -48.013905   25.95038  -150.3093    -95.35625\n","  -203.11432   -93.2454      2.755085  102.54849  -111.92828    27.996979\n","   -18.76049   -14.778048   25.296467  592.31494    59.228508 -197.78937\n","   123.20683    93.913376 -152.0299    147.31569  -200.92603  -116.811005\n","   -98.82626    43.03511 ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 15\n","Output: [[  287.4364     688.62805    969.1397    -381.68225  -3471.2783\n","    737.8922     396.5612     -41.15802    288.08313  -1399.0375\n","    390.3294     467.83517   -190.29947   -378.43597   -405.88223\n","   5042.7207     456.25497     39.17476   -355.5591    -104.020966\n","    528.1665   -1022.9003      30.23523    128.79659    -80.95499\n","   -293.70044 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 15\n","Output: [[-108.68421   -107.631134   -41.231377    -8.918875  -213.386\n","  -168.10228   -256.42422   -116.61662    -28.591637   112.11307\n","  -121.93745     55.43062    -20.516617    -2.9054756   43.669125\n","   607.55884     46.68527   -245.83122    162.87158     60.33483\n","  -186.22377    186.20639   -210.13997   -115.159134  -108.47463\n","    73.27647  ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 15\n","Output: [[-124.85005   -127.0591     -43.479797     2.748104  -183.76619\n","  -124.726166  -222.07463   -118.73941      1.5792694  118.424385\n","  -119.26918     50.331398   -26.639633   -26.775618    31.389141\n","   655.6907      33.45866   -218.9323     139.89076     65.207954\n","  -160.5881     160.62498   -178.92328   -106.0683    -103.15289\n","    39.576744 ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 15\n","Output: [[  3012.8774    5707.041     7273.0254   -2783.7148  -24056.756\n","    6261.4805    4492.636      606.22266   2235.592   -10930.362\n","    3614.088     3132.6267   -1302.4177   -2518.1409   -3205.9739\n","   31791.5       2812.643     1811.0947   -3603.543    -1515.5007\n","    5118.4497   -8457.668     1670.3042    1785.9146     188.84448\n","   -2438.2275 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 15\n","Output: [[ 1000.66064   1951.7905    2524.3398    -966.77075  -8521.721\n","   2176.4324    1501.9893     175.42078    813.07904  -3800.1528\n","   1218.8534    1120.1475    -479.61243   -894.65955  -1118.7004\n","  11415.7295     983.96515    563.6026   -1217.3745    -506.6115\n","   1752.0938   -2913.6626     529.0687     583.0471      31.006653\n","   -840.49414 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 15\n","Output: [[  2840.9429    5372.5537    6685.8857   -2474.9434  -22080.252\n","    6046.4497    4371.7344     720.75244   2190.834   -10209.68\n","    3405.1792    2820.7656   -1233.4141   -2305.5176   -3008.6191\n","   28852.281     2523.7888    1881.2086   -3488.1997   -1413.8926\n","    4906.5737   -7937.588     1667.5352    1698.2051     282.3689\n","   -2290.7114 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 15\n","Output: [[  2383.3896    4497.1084    5599.5815   -2064.622   -18573.89\n","    5108.3716    3679.3003     618.8528    1875.5925   -8576.4795\n","    2848.9236    2372.7942   -1050.399    -1929.4736   -2533.8452\n","   24230.43      2088.288     1578.5933   -2942.001    -1208.4609\n","    4141.326    -6656.8623    1410.242     1429.5908     248.62262\n","   -1924.2344 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 15\n","Output: [[  1903.4395    3559.2793    4411.7944   -1612.1199  -14709.537\n","    4042.2588    2905.317      515.2051    1484.1484   -6773.8735\n","    2241.9155    1868.7141    -839.16187  -1508.5773   -2007.5359\n","   19100.633     1646.0177    1229.2483   -2328.9846    -960.5906\n","    3261.7979   -5229.688     1082.8362    1118.053      202.5304\n","   -1502.9768 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 15\n","Output: [[-123.3367   -103.808205  -49.1381     31.783875 -135.49939   -73.6682\n","  -185.93951   -94.30679    17.840538  105.70413  -110.59416    25.447388\n","   -21.822014  -26.713123   19.156475  616.38086    52.615196 -184.3399\n","   111.71643    96.34995  -139.21207   134.52498  -185.31769  -112.26559\n","   -96.165375   26.185253]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 15\n","Output: [[  636.62354  1255.7786   1566.253    -560.5482  -5385.868    1454.0392\n","    983.2303    158.65063   563.17847 -2422.1821    764.80725   685.38855\n","   -319.6459   -550.81854  -722.63385  7157.202     614.5425    383.08667\n","   -803.31067  -300.8808   1136.8499  -1847.5883    316.79297   349.60324\n","     37.24875  -526.77295]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 15\n","Output: [[-134.46791  -152.97977   -39.940823   -4.801449 -178.09601  -111.14912\n","  -202.7908   -130.13072    18.735054  126.36978  -116.54581    58.725475\n","   -33.89333   -47.136047   26.356575  692.34985     8.039665 -205.58421\n","   129.87842    47.233482 -142.97972   145.98828  -138.20099   -88.95592\n","   -97.751526   15.491886]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 15\n","Output: [[  675.37506   1369.0714    1667.0013    -545.8875   -5778.8315\n","   1633.9572    1082.4052     203.39917    641.49243  -2610.221\n","    809.32935    702.6267    -345.777     -590.70276   -797.42816\n","   7760.709      698.2138     421.4726    -893.19165   -271.96423\n","   1234.2886   -1990.452      288.2323     345.03317     36.037537\n","   -585.19543 ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 15\n","Output: [[  1603.1257    2968.3853    3552.3176   -1245.3225  -11902.018\n","    3407.8108    2470.9438     532.6907    1282.8926   -5579.985\n","    1837.4453    1472.3717    -700.7356   -1172.3296   -1656.7129\n","   15187.083     1315.5743    1100.0537   -1976.1409    -804.8688\n","    2756.1685   -4291.834      920.6836     910.43225    217.60855\n","   -1227.079  ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.80% (489/500)\n","Noise 6% ‚Üí Accuracy: 96.60% (483/500)\n","Noise 9% ‚Üí Accuracy: 95.40% (477/500)\n","Noise 12% ‚Üí Accuracy: 93.80% (469/500)\n","Noise 14% ‚Üí Accuracy: 92.80% (464/500)\n","Noise 17% ‚Üí Accuracy: 89.60% (448/500)\n","Noise 20% ‚Üí Accuracy: 93.40% (467/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 15/15)\n","Noise 3% ‚Üí Avg Retention: 97.37% (avg 14/15)\n","Noise 6% ‚Üí Avg Retention: 94.00% (avg 14/15)\n","Noise 9% ‚Üí Avg Retention: 90.83% (avg 13/15)\n","Noise 12% ‚Üí Avg Retention: 87.83% (avg 13/15)\n","Noise 14% ‚Üí Avg Retention: 85.43% (avg 12/15)\n","Noise 17% ‚Üí Avg Retention: 83.23% (avg 12/15)\n","Noise 20% ‚Üí Avg Retention: 80.63% (avg 12/15)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}