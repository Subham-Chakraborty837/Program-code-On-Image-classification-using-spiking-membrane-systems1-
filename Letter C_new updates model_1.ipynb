{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMS06kIckEIFbJk+GrykFR9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"NwKoXARcYir7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","C_CLASS_INDEX = 2\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'C'\n","# ------------------------\n","def encode_letter_C():\n","    grid = np.array([\n","    [0, 1, 1, 1, 0],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 0, 1],\n","    [0, 1, 1, 1, 0]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_C()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([C_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_C = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_C = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_C)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_C()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == C_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == C_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_C()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","executionInfo":{"status":"ok","timestamp":1764517112732,"user_tz":-330,"elapsed":400580,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}},"outputId":"9b63ae29-1751-41a8-f7fc-c194feeaf88a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 298.9590, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 2\n","Output: [[  -3.1169891  -96.5331     442.23477     35.70835    120.40929\n","  -127.4731     -89.0029    -108.78136    -37.16792      1.3035355\n","   -38.372665   164.00232    -99.14857    -62.148693   101.74271\n","   154.21263     52.955822  -266.33075     36.996906   -23.032099\n","   311.13342    -35.50991   -216.91003    -53.86193   -131.431\n","    -6.147928 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 115.94591   -11.739342 1221.6782     69.059944  200.75102  -131.26315\n","  -127.67784  -169.96725  -155.89287  -140.71751   -11.546585  228.54968\n","  -137.38611   -65.458405  157.76274   104.323105  165.05865  -405.1553\n","    31.899658  -11.239193 -184.21506   -49.204437 -309.9901    -46.489082\n","  -131.3408     31.057606]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 2\n","Output: [[  26.081856   -15.302155   817.06055     54.08436    136.9173\n","   -98.506645  -152.67572   -109.31987    -78.87059    -36.39151\n","   -44.420715   101.51501    -84.725746   -83.62615    137.37689\n","    96.56102    111.49021   -296.33698     49.399002    -3.5642471\n","  -134.74632      1.8819189 -234.8282     -86.046616  -102.48509\n","     1.3191376]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 2\n","Output: [[  61.734856   19.365555  926.8325     24.44719   158.9084   -111.00628\n","  -190.88074  -118.6313   -112.74448   -96.51355   -26.407082  156.50528\n","  -105.61295   -49.473602  140.7814     46.61229   139.92102  -349.47266\n","    60.29029   -31.95631  -167.30351   -13.776417 -242.60574   -89.78212\n","   -93.86235    -6.256199]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 4.0489282e+02  3.0825046e+02  2.6677808e+03 -1.0457985e+02\n","   9.5810938e+02  3.4190500e+02 -4.2765259e+01 -2.6155872e+02\n","  -2.0315892e+02 -9.4836328e+02  2.7398117e+02  7.2705072e+02\n","  -4.3652649e+02  6.2362061e+01 -3.2026367e+00 -7.6725189e+01\n","   4.1363666e+02 -7.4923352e+02 -1.4775522e+02 -1.5035516e+02\n","  -1.9348602e+02 -6.1775189e+02 -9.7410339e+01 -1.2166046e+01\n","  -3.5987854e-01 -4.3643094e+02]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 2\n","Output: [[  81.302     105.52804  1076.4932     22.093616  325.32178    73.07642\n","  -110.28662  -103.70511   -36.26084  -252.23718    19.551292  175.52032\n","  -158.09044   -54.37976    68.07839    87.30229   179.8637   -347.9189\n","   -10.389507   24.94881  -131.32404  -144.09758  -215.92697  -102.67704\n","   -68.57183  -108.78799 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -47.19745    -46.859894   438.56323     59.375313    42.02872\n","   -99.61288   -151.16096    -74.64459     -2.9185371   82.81531\n","   -86.93692     -6.254654   -42.75038   -106.58433    123.93804\n","   132.16692     40.851635  -192.35095     67.90722     24.192078\n","   -96.32257     66.6472    -211.82574   -104.17723    -88.23681\n","    25.107912 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 157.16838   141.0809   1198.6615   -104.04669   413.32806    92.240326\n","   -82.41559  -121.370255  -23.310158 -403.55933    69.55829   272.30667\n","  -212.44136   -55.384308   16.612823    4.073532  135.51013  -343.24194\n","   -40.216423  -70.80351  -178.2322   -217.6387    -98.09354    -9.357269\n","   -36.40705  -169.78201 ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 2\n","Output: [[  608.8579     614.2103    3093.0193    -401.34415   1553.0265\n","    823.6644     256.62573   -168.43665    122.36426  -1639.9608\n","    441.06342    845.4843    -657.5117     -61.494263  -322.79126\n","   -118.6236     412.98267   -524.57513   -467.8321    -214.86588\n","   -330.79456  -1044.9246     165.10608    259.42093    103.21111\n","   -783.5713  ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -28.168694   -28.597004   459.58954     40.987854    -4.998726\n","  -165.16856   -203.47678    -78.884735   -43.52439     79.51227\n","   -93.80876      4.5923843  -37.37962    -80.971275   144.79944\n","    88.231766    53.770596  -236.39786    102.97235     11.99044\n","  -141.45424    103.88931   -253.64366   -116.131676   -97.99713\n","    69.39185  ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -41.33914    -58.677788   412.30048     33.997753    31.462858\n","  -113.99043   -146.18164    -81.22715     -8.287216    80.74669\n","   -79.09357      9.823551   -42.830944  -101.92362    118.32312\n","   110.72209     17.229046  -184.43782     70.95597     -4.9426193\n","   -91.70558     66.24126   -171.27237    -82.424576   -79.22508\n","    23.029339 ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -41.33914    -58.677788   412.30048     33.997753    31.462858\n","  -113.99043   -146.18164    -81.22715     -8.287216    80.74669\n","   -79.09357      9.823551   -42.830944  -101.92362    118.32312\n","   110.72209     17.229046  -184.43782     70.95597     -4.9426193\n","   -91.70558     66.24126   -171.27237    -82.424576   -79.22508\n","    23.029339 ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 2\n","Output: [[  659.109      642.87573   2836.4238    -483.77606   1664.3176\n","    944.88153    440.89124    -70.480286   281.71588  -1770.785\n","    469.6371     801.2264    -685.7622    -137.07935   -459.35388\n","   -171.96918    350.95596   -210.26035   -634.7821    -371.67737\n","   -374.42706  -1146.9795     343.02655    467.36237    219.76086\n","   -864.60535 ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -44.03676   -47.730988  458.80713    52.66471    31.436468 -122.01837\n","  -168.9256    -80.6615    -13.15287    85.675934  -90.96449    -0.649353\n","   -43.6745   -105.13811   133.3306    124.26238    40.494823 -209.66574\n","    79.58622    16.298347 -109.91469    77.98427  -222.43628  -107.10823\n","   -92.70536    35.59728 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -36.334274   -43.201843   425.82306     40.848095    18.528189\n","  -128.37675   -165.94688    -77.04748    -20.788628    78.699165\n","   -84.43738      4.405304   -39.643227   -92.17057    126.86501\n","   103.42919     35.67823   -201.76045     81.12466      7.4707794\n","  -109.78384     79.39674   -207.15276    -97.81264    -86.376816\n","    40.96592  ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -34.490105   -26.854801   419.1018      54.40905     16.18578\n","  -120.35759   -167.94748    -66.8509     -23.055706    73.79101\n","   -85.753624    -6.6182556  -35.531376   -83.86374    126.01435\n","   104.04083     54.484226  -201.7683      79.61433     27.777893\n","  -114.26997     81.21515   -232.42256   -110.2697     -89.06001\n","    48.41311  ]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 2\n","Output: [[  457.9117     459.54453   1880.0099    -304.80685   1089.3499\n","    627.46313    290.8652     -20.262085   209.42523  -1192.3295\n","    298.30048    492.47626   -466.23645   -128.87518   -313.68906\n","   -129.88443    239.62277   -117.10132   -440.84445   -253.7307\n","   -281.31552   -769.45575    169.33936    300.30197    155.37146\n","   -552.7943  ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -22.078812  -35.377037  466.702      21.588486  -20.873926 -194.76285\n","  -218.75172   -88.19291   -56.44305    81.33859   -93.91466    18.236824\n","   -38.34403   -77.194695  151.38454    69.60483    41.602486 -249.75609\n","   116.175766  -10.470634 -152.73787   115.02342  -243.97757  -108.18635\n","   -97.95982    78.841934]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -37.946884  -54.511024  465.9196     33.265343   15.561279 -151.61261\n","  -184.20059   -89.96969   -26.071533   87.50226   -91.07037    12.995079\n","   -44.6389   -101.36154   139.91568   105.63542    28.326717 -223.02393\n","    92.78961    -6.162712 -121.198326   89.11837  -212.77017   -99.162895\n","   -92.66806    45.047363]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 3696.3423   3539.8853  10302.67    -2462.7808   7596.171    5684.2173\n","   3596.1665    511.26733  1923.0691  -9140.196    2704.376    3531.8687\n","  -3098.3984   -488.73926 -3302.964   -1875.8777   1266.5044    701.311\n","  -3945.4934  -2072.0964  -1067.25    -6161.6396   2710.1162   2795.019\n","   1894.3547  -4375.836  ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 1289.6989   1206.0333   3766.3867   -846.45496  2668.3386   1959.0917\n","   1211.7861    154.02393   699.80835 -3162.4448    901.6565   1237.7498\n","  -1113.834    -236.7008  -1106.9056   -615.765     438.64954   169.62283\n","  -1369.8046   -737.3802   -401.44196 -2141.6963    862.079     925.71436\n","    646.88245 -1535.2731 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 3481.1091   3289.6045   9061.812   -2219.9116   6986.883    5519.0703\n","   3576.365     616.22144  1958.1544  -8455.497    2512.827    3175.748\n","  -2835.165    -504.94287 -3184.8767  -1803.8167   1130.4619    859.7115\n","  -3816.391   -1891.3123   -817.5073  -5805.4023   2559.2305   2552.0435\n","   1879.8712  -4126.9395 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 2934.912    2740.5847   7612.9453  -1858.3203   5849.0303   4655.935\n","   3033.4517    529.32935  1684.2998  -7086.126    2089.944    2667.4668\n","  -2393.4983   -466.4126  -2680.65    -1521.1091    920.4956    718.8035\n","  -3222.7256  -1613.376    -661.76514 -4873.494    2129.8115   2125.7014\n","   1589.9766  -3481.4985 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 2343.2017   2171.0986   6017.349   -1454.1865   4586.0713   3691.3867\n","   2413.6997    441.10107  1345.8025  -5587.1025   1637.2502   2094.4238\n","  -1874.5781   -393.84033 -2128.5547  -1245.1768    739.0453    555.4394\n","  -2560.2617  -1281.7665   -528.7915  -3836.89     1624.2151   1649.469\n","   1257.376   -2732.9888 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -42.424133   -36.421806   418.7106      60.247482    34.403374\n","   -98.78249   -150.67194    -67.739296    -7.869953    76.87283\n","   -84.33149     -9.2391205  -38.678814   -95.94714    120.27992\n","   122.056145    47.84634   -188.40224     67.92126     29.931839\n","   -98.50021     68.262634  -216.81888   -105.75797    -86.41413\n","    31.51583  ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 2\n","Output: [[  842.2649    771.6439   2314.6733   -490.62485  1665.7684   1315.3628\n","    827.5716    141.10077   505.56683 -1987.5203    548.81696   750.3102\n","   -703.3395   -191.099    -723.86584  -404.56613   276.96667   130.64816\n","   -913.1428   -449.0362   -219.07098 -1366.4645    486.41724   533.5978\n","    436.88208  -984.72266]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 2\n","Output: [[ -47.725075   -80.42504    472.24963     25.5428      36.121284\n","  -138.05667   -164.92441   -101.05465     -8.618706    95.49225\n","   -88.332       21.397766   -51.898182  -121.75178    135.0319\n","   123.03911      2.8828259 -209.65002     82.60689    -24.315865\n","  -100.94243     74.34744   -171.89665    -82.19411    -87.339005\n","    20.702877 ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 2\n","Output: [[  904.67126   856.60065  2516.649    -471.2833   1816.7185   1485.4862\n","    922.5381    179.55164   579.6046  -2146.6658    578.6296    772.2097\n","   -753.609    -226.43835  -794.3032   -405.71436   335.29364   151.26807\n","  -1012.36426  -432.97784  -222.09729 -1483.5281    458.2016    537.3772\n","    463.88675 -1069.407  ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 2\n","Output: [[ 1975.0927   1797.1976   4623.214   -1132.8202   3663.0955   3140.011\n","   2094.923     436.25537  1192.4362  -4555.3496   1317.3066   1665.5522\n","  -1518.0537   -338.48755 -1807.2014  -1090.4155    563.0502    544.76074\n","  -2165.0232  -1036.6052   -354.57556 -3146.6567   1310.5984   1292.043\n","   1105.7966  -2245.0688 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 27.80% (139/500)\n","Noise 6% ‚Üí Accuracy: 10.20% (51/500)\n","Noise 9% ‚Üí Accuracy: 2.40% (12/500)\n","Noise 12% ‚Üí Accuracy: 0.60% (3/500)\n","Noise 14% ‚Üí Accuracy: 0.20% (1/500)\n","Noise 17% ‚Üí Accuracy: 0.00% (0/500)\n","Noise 20% ‚Üí Accuracy: 0.00% (0/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 13/13)\n","Noise 3% ‚Üí Avg Retention: 97.12% (avg 12/13)\n","Noise 6% ‚Üí Avg Retention: 94.08% (avg 12/13)\n","Noise 9% ‚Üí Avg Retention: 90.27% (avg 11/13)\n","Noise 12% ‚Üí Avg Retention: 88.08% (avg 11/13)\n","Noise 14% ‚Üí Avg Retention: 84.69% (avg 11/13)\n","Noise 17% ‚Üí Avg Retention: 83.35% (avg 10/13)\n","Noise 20% ‚Üí Avg Retention: 80.08% (avg 10/13)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}