{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8z6ieb/in8zWKczjJMXOv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fw5y70c0-quK"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","I_CLASS_INDEX = 8\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'I'\n","# ------------------------\n","def encode_letter_I():\n","    grid = np.array([\n","    [1, 1, 1, 1, 1],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [1, 1, 1, 1, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_I()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([I_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_I = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_I = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_I)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_I()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == I_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == I_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_I()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"88baf4d4-2b62-4fed-b911-004544ad9acd","executionInfo":{"status":"ok","timestamp":1764565869561,"user_tz":-330,"elapsed":424703,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 0.0000, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 8\n","Output: [[ -50.53694   -168.68538      6.3119316   15.454079    57.44273\n","    86.4738     -54.360962  -105.84605    662.65515      5.045822\n","   -29.860842   120.96301      2.9321556 -115.67908    -42.478676\n","   102.870316     7.2615566 -269.18854    -13.362976     0.8840828\n","     3.7003021 -131.44211   -236.41127   -172.73566    -81.11737\n","   -53.357548 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 8\n","Output: [[  -7.45829   -100.61972     96.55481     -8.713333   173.84297\n","   233.77649    -28.117004  -126.2563     885.6489    -105.057816\n","    16.065552   195.8939      45.715313  -131.14133   -120.33796\n","    81.13071     92.39705   -416.71442    -15.9506035    2.7277203\n","    36.68769   -229.89417   -318.22617   -244.7103    -120.22871\n","   -64.29273  ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 8\n","Output: [[-5.40171661e+01 -1.05876762e+02 -2.32419968e+00 -4.60571289e-01\n","   8.05032043e+01  1.33962494e+02 -7.62942581e+01 -9.82212830e+01\n","   7.16344849e+02 -3.71245537e+01 -4.92685356e+01  9.76574478e+01\n","   3.07153778e+01 -1.11961548e+02 -4.66165466e+01  8.98239594e+01\n","   1.95911751e+01 -3.21858551e+02  2.49900837e+01 -3.04519272e+00\n","  -6.42185211e+00 -1.27463326e+02 -2.27752686e+02 -2.28871582e+02\n","  -9.35617065e+01 -7.55681458e+01]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 8\n","Output: [[ -16.387947  -61.992043   36.46972   -33.61866   137.62085   161.48027\n","  -114.20619   -96.59019   731.7002   -116.02416   -32.612167  157.6287\n","    34.369606 -100.22516   -69.92238    65.55374    60.172188 -354.58682\n","    28.441322  -25.690758   10.205132 -182.49448  -225.8749   -229.51979\n","   -87.37468   -75.27571 ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 8\n","Output: [[  305.7518     285.403      690.01917   -212.09033    917.1445\n","   1146.3514      62.625336  -106.56433   1837.1029   -1053.4321\n","    309.2044     763.48663     73.36815   -222.0492    -606.08105\n","    121.47281    519.9918    -569.5902    -264.56583    -92.20157\n","    520.5879   -1070.2642     -60.49463   -119.13858   -139.72581\n","   -392.30548 ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 8\n","Output: [[  41.340477   18.435974  135.50824   -14.748512  252.71196   366.1979\n","   -99.23163   -71.22806   931.52344  -292.43735     3.729477  205.7037\n","    25.758959 -132.80182  -135.736     126.24488   166.9693   -324.36145\n","   -55.537468   49.245895   96.07432  -347.00488  -186.76553  -176.77051\n","  -107.034706 -134.60645 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 8\n","Output: [[ -89.833145  -140.1986    -103.184814    35.991833   -54.189068\n","     5.240711  -125.604904   -84.76939    556.7842      68.548676\n","  -111.43375      1.8340073   14.078636   -95.08864     44.82296\n","   110.30844    -41.086662  -232.23886     54.569595    30.117252\n","   -65.38974    -19.733524  -192.95883   -205.80713    -71.3107\n","   -40.573498 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 8\n","Output: [[ 132.29239   107.3848    288.4483   -116.90822   365.00323   397.31964\n","  -169.73447   -76.72479   923.2215   -457.42334    52.60874   340.70502\n","   -19.943924 -143.19301  -152.36176    73.28593   188.26498  -315.79883\n","   -66.51514   -24.647831  162.1077   -445.22748   -49.55847   -39.240364\n","  -134.27026  -140.67624 ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 8\n","Output: [[  577.04553     803.6892     1263.5608     -377.65405    1599.7838\n","   1551.3455     -215.34879       4.6098633  2005.9319    -1800.6184\n","    421.12418    1079.2701     -156.27219    -358.42786    -637.338\n","    197.77379     787.5136     -384.24307    -455.41437       7.184723\n","    813.5785    -1539.4451      282.10394     351.69067    -360.3084\n","   -501.9515   ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 8\n","Output: [[ -82.5148    -173.20067   -125.5443      14.672159   119.576965\n","   -34.81736   -171.23172   -119.9741     349.14194     48.900635\n","  -124.07803     26.273941    22.06514    -46.96703     62.56649\n","    67.550835   -56.250916  -334.71155     87.48667     13.672974\n","   -94.03835      3.1238594 -233.20895   -247.7796     -77.895294\n","    10.318657 ]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 8\n","Output: [[ -89.27779   -187.18031   -108.76287     11.661333    99.979645\n","     1.0453873 -117.46424   -118.28402    382.2915      53.341343\n","  -105.85685     29.194427    10.266052   -70.467606    44.90876\n","    90.74401    -80.624306  -273.43018     58.18429     -3.0770416\n","   -57.969463   -15.499329  -153.49738   -199.90247    -62.26734\n","   -28.103096 ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 8\n","Output: [[  -49.279846   -158.95145     -23.268314    -22.5009    -1806.2695\n","    137.54962    -123.54855    -141.14777    2574.3296     -106.61857\n","    -72.387054    126.34875      -3.9694557   -73.076454     -6.395088\n","    100.610245    -42.09267    -342.08417      19.48002     -10.123207\n","     13.105537   -133.69504    -117.64143    -183.828       -86.541336\n","    -56.23379  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 8\n","Output: [[   671.9833      958.3644     1476.5111     -382.42963  -22864.45\n","    1634.9396       70.38672     120.092896  26441.637     -2042.7357\n","     489.9384     1088.3367     -301.8239     -361.7326     -670.6017\n","     142.91922     759.7682     -120.177124   -608.6912     -126.40839\n","     948.5955    -1544.8304      394.33624     559.3949     -350.60657\n","    -512.4983  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 8\n","Output: [[-5.2014206e+01 -1.5996750e+02 -2.8664822e+01 -1.2361549e+01\n","  -2.0609011e+03  1.6628452e+02 -1.4357928e+02 -1.4856163e+02\n","   2.9269790e+03 -1.3053339e+02 -8.2438599e+01  1.3377791e+02\n","  -2.7030945e-02 -7.2826805e+01 -9.3227863e+00  1.1317182e+02\n","  -2.5338081e+01 -3.8922086e+02  2.0199549e+01  1.0268517e+01\n","   1.1065453e+01 -1.5174179e+02 -1.6063268e+02 -2.2127142e+02\n","  -1.0170653e+02 -5.5254726e+01]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 8\n","Output: [[-4.4260895e+01 -1.4720389e+02 -2.5675589e+01 -1.8894829e+01\n","  -1.8925851e+03  1.3576839e+02 -1.4248955e+02 -1.3942038e+02\n","   2.6695171e+03 -1.1846055e+02 -7.7067299e+01  1.2700915e+02\n","   6.0071564e-01 -6.2668030e+01 -3.6813431e+00  9.3617523e+01\n","  -2.5553898e+01 -3.6611310e+02  2.6606133e+01  1.8572693e+00\n","   3.5114059e+00 -1.3335947e+02 -1.5062419e+02 -2.0307074e+02\n","  -9.4000748e+01 -4.2612984e+01]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 8\n","Output: [[-4.14626312e+01 -1.29819473e+02 -2.78626518e+01 -6.39362335e+00\n","  -1.91064355e+03  1.47532257e+02 -1.44709015e+02 -1.29406677e+02\n","   2.68847656e+03 -1.27567795e+02 -7.74854202e+01  1.18562164e+02\n","   4.46805954e+00 -5.45848999e+01 -6.14887238e+00  9.44768753e+01\n","  -5.60507202e+00 -3.67485596e+02  2.39998913e+01  2.20168381e+01\n","   1.03237915e+00 -1.34736298e+02 -1.74787415e+02 -2.15130310e+02\n","  -9.74158325e+01 -3.63073082e+01]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 8\n","Output: [[   451.1915      637.91846     934.1488     -191.20418  -14690.333\n","    1068.5076      236.08244     110.94971   16994.035     -1304.8658\n","     285.5597      639.4631     -231.53293    -234.13617    -448.7543\n","      26.237183    469.13293     -86.45358    -415.42447    -123.19223\n","     650.6501     -916.71265     101.989624    245.12207    -222.25946\n","    -319.90515 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 8\n","Output: [[  -32.323044   -149.04056     -25.93512     -42.59623   -2022.2278\n","     85.757      -193.21886    -154.70178    2778.9487     -125.18193\n","    -87.37697     146.72337       4.9567604   -46.571182     13.449394\n","     60.7137      -25.917496   -423.2146       57.70328     -16.805748\n","    -22.85054    -119.71957    -184.16019    -221.54962    -103.988304\n","    -11.193945 ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 8\n","Output: [[-4.73159866e+01 -1.67914810e+02 -2.62968712e+01 -3.07739105e+01\n","  -2.03597107e+03  1.31599426e+02 -1.58646118e+02 -1.57284149e+02\n","   2.86499561e+03 -1.22678070e+02 -8.38059692e+01  1.43724365e+02\n","  -9.43977356e-01 -6.94636993e+01 -8.70208740e-02  9.51128693e+01\n","  -3.88304367e+01 -3.99637085e+02  3.44382820e+01 -1.21959686e+01\n","   1.41277313e+00 -1.40149826e+02 -1.52366364e+02 -2.13324432e+02\n","  -1.00190384e+02 -4.47715874e+01]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 8\n","Output: [[  3538.9187    5451.3125    6767.7944   -1141.1777  -89965.484\n","    6521.856     3461.888     1814.604   100639.59     -8227.835\n","    2487.354     3459.5234   -1814.3389   -1315.9482   -3209.7646\n","    -752.8446    3193.747     2035.3385   -3210.0361   -1265.1509\n","    4750.5034   -5220.765     1536.4751    2945.1904    -833.43976\n","   -2012.3783 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 8\n","Output: [[  1211.88      1827.6606    2343.716     -396.52417 -32182.059\n","    2340.9688    1221.3073     574.0564   36269.855    -2910.9177\n","     822.12      1250.0233    -652.80133   -496.03046  -1123.728\n","    -232.53613   1071.0946     551.20514  -1114.5679    -471.64185\n","    1685.812    -1855.6154     442.63293    903.7694    -332.3192\n","    -727.66016]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 8\n","Output: [[  3245.5771    5082.0723    6178.699     -927.989   -80783.414\n","    5954.5474    3642.1677    1810.3262   90131.44     -7406.6333\n","    2279.7227    2958.8862   -1742.1566   -1203.1753   -2952.8462\n","    -800.49695   2845.913     2131.0498   -3018.6177   -1228.9137\n","    4460.333    -4576.7314    1298.9736    2647.1958    -698.65967\n","   -1853.0391 ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 8\n","Output: [[  2712.1865    4220.9546    5165.0225    -762.6708  -67588.93\n","    4983.37      3166.7869    1512.3892   75462.664    -6177.15\n","    1884.8757    2450.5886   -1491.5073   -1029.4331   -2470.3716\n","    -696.1448    2329.1343    1761.6082   -2538.208    -1080.3403\n","    3767.0327   -3788.688     1027.1328    2153.1018    -585.33344\n","   -1562.6218 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 8\n","Output: [[  2143.766     3323.7783    4057.324     -584.7306  -53229.85\n","    3904.9622    2563.366     1202.9502   59409.094    -4857.6826\n","    1469.3154    1903.5028   -1185.4011    -811.63086  -1951.2872\n","    -605.8166    1815.8301    1360.7277   -2002.6421    -884.5657\n","    2963.7766   -2936.8652     726.0532    1643.9731    -452.59277\n","   -1222.583  ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 8\n","Output: [[-4.89591141e+01 -1.39256592e+02 -2.80435162e+01 -4.82482910e-01\n","  -1.91751514e+03  1.70453491e+02 -1.27422661e+02 -1.30697845e+02\n","   2.73150000e+03 -1.26315865e+02 -7.56999130e+01  1.17062668e+02\n","   1.51769257e+00 -6.60311508e+01 -1.29170990e+01  1.11676468e+02\n","  -1.20615692e+01 -3.55696899e+02  1.23674049e+01  2.43217239e+01\n","   1.31640625e+01 -1.44951416e+02 -1.58890518e+02 -2.11017700e+02\n","  -9.55168915e+01 -5.30961380e+01]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 8\n","Output: [[   752.7352    1139.8951    1438.9802    -193.01648 -19899.197\n","    1486.2253     931.27905    384.10913  22477.465    -1792.7883\n","     484.778      718.19006   -440.39343   -319.7619    -709.3949\n","    -176.67163    636.3362     341.5408    -719.72876   -319.8638\n","    1093.1917   -1095.6932     156.79382    464.47345   -207.57939\n","    -459.00485]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 8\n","Output: [[  -57.610756   -194.73637     -24.29067     -37.363976  -2024.7844\n","    142.75684    -139.14026    -168.58905    2889.0596     -112.31891\n","    -81.60234     150.67184      -7.7617188   -88.99305      -4.3877087\n","    111.45308     -65.2357     -386.47577      25.412006    -30.050606\n","     16.023468   -148.98813    -112.306206   -197.1523      -94.87634\n","    -67.8661   ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 8\n","Output: [[   803.2869    1233.9393    1535.7965    -157.01523 -21588.516\n","    1680.9238    1059.0521     429.0055   24491.21     -1951.9174\n","     510.90906    744.96594   -478.36435   -355.60968   -786.2404\n","    -166.22061    711.7742     352.53644   -809.36523   -303.68076\n","    1197.0883   -1193.1727      97.69812    439.6033    -229.50957\n","    -514.85376]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 8\n","Output: [[  1750.7507    2716.025     3216.6738    -383.4855  -41844.812\n","    3117.6858    2376.8022    1042.8069   46572.85     -3823.8132\n","    1151.9246    1408.6606   -1009.90454   -637.323    -1581.972\n","    -579.91016   1417.0654    1205.1052   -1648.5027    -776.11304\n","    2442.7175   -2202.2832     444.38257   1214.9047    -327.5118\n","    -959.24927]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 98.20% (491/500)\n","Noise 6% ‚Üí Accuracy: 97.00% (485/500)\n","Noise 9% ‚Üí Accuracy: 97.40% (487/500)\n","Noise 12% ‚Üí Accuracy: 96.20% (481/500)\n","Noise 14% ‚Üí Accuracy: 95.80% (479/500)\n","Noise 17% ‚Üí Accuracy: 95.20% (476/500)\n","Noise 20% ‚Üí Accuracy: 97.60% (488/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 15/15)\n","Noise 3% ‚Üí Avg Retention: 97.13% (avg 14/15)\n","Noise 6% ‚Üí Avg Retention: 93.80% (avg 14/15)\n","Noise 9% ‚Üí Avg Retention: 91.07% (avg 13/15)\n","Noise 12% ‚Üí Avg Retention: 88.13% (avg 13/15)\n","Noise 14% ‚Üí Avg Retention: 85.67% (avg 12/15)\n","Noise 17% ‚Üí Avg Retention: 82.50% (avg 12/15)\n","Noise 20% ‚Üí Avg Retention: 79.80% (avg 11/15)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}