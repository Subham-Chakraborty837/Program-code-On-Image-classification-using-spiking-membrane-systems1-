{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHrg7ADxkkHjEs99i4ZJML"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hXlBNv-itac8"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","O_CLASS_INDEX = 14\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'O'\n","# ------------------------\n","def encode_letter_O():\n","    grid = np.array([\n","    [0, 1, 1, 1, 0],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [0, 1, 1, 1, 0]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_O()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([O_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_O = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_O = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_O)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_O()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == O_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == O_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_O()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"2e38de5a-6352-4fd0-baaa-42adb3a0e9f9","executionInfo":{"status":"ok","timestamp":1764574931253,"user_tz":-330,"elapsed":456097,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 187.6652, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -25.858994  -105.05028     88.74174     67.176285    64.433716\n","   -23.350048   -91.40706    -97.52841      6.015026    65.9682\n","   -37.040016    84.8018     -11.271254  -124.00601    331.79553\n","    84.70117     79.27082   -233.39812    -23.061743     5.6618004\n","   -29.12042    104.5683    -254.40967   -119.63007    -70.039314\n","   -47.855553 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -42.019478    25.777832   307.45132     60.413635   206.37521\n","   -14.833881  -142.36453    -57.31192    -19.392555   -35.490143\n","    -1.9604492  166.28174    -91.91409   -137.48938    918.7881\n","    53.811356  -205.56494   -417.2649     -20.364677    45.311657\n","   206.09253    107.022415  -351.31168   -170.92361   -109.19704\n","   -62.69597  ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -85.82112     -3.7682877  179.61649     30.166878   122.07695\n","   -40.981083  -181.74701    -66.50695     11.001984    33.290382\n","   -46.13159     65.773506   -84.21631   -138.90668    739.42896\n","    53.52822   -191.69095   -325.21732     42.006466    22.82383\n","    96.93523    138.69685   -247.18799   -170.88104   -111.55803\n","   -49.997894 ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -69.09098     87.96761    260.239        4.0946503  185.16385\n","   -23.278687  -186.5796     -51.989716    17.715431   -44.858322\n","   -30.037777    87.07776   -108.5175    -122.988365   797.5501\n","    40.592674  -219.45218   -387.71234     59.82367     50.134117\n","   190.78833    119.57169   -259.98996   -155.90402   -129.20908\n","   -24.443018 ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 14\n","Output: [[   32.032623   995.4434    1322.454      -29.445145  1460.781\n","    770.34985    257.78186    224.44604    267.33154   -909.9968\n","    303.1819     378.7444    -383.72864   -128.94458   7312.738\n","    272.2649    -486.34      -893.75085   -169.15271    510.70685\n","  -4015.5574    -404.75894   -292.2035      48.179306  -259.5434\n","   -142.45914 ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 14\n","Output: [[  -47.530922   277.62677    394.19492     52.09826    415.31256\n","    211.42125   -114.605286   -26.357483    96.40996   -198.61702\n","      8.780975    69.17047   -130.19244   -152.18147   2600.1729\n","    107.47153   -246.0633    -408.2794      16.901955   160.3923\n","  -1398.9082      23.901085  -268.83197   -124.961624  -149.55792\n","    -55.48227 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -87.74964  -104.878944   22.419216   52.498444  -55.08652   -85.496704\n","  -247.18529  -151.5785      4.83527   142.6026   -102.56832   -27.734467\n","   -44.798847 -173.16116   631.59753    32.610962 -178.14368  -219.41908\n","    75.658936  -37.219604 -247.742     211.01094  -223.3981   -167.31924\n","   -78.71948   -29.362823]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 14\n","Output: [[   13.136124   431.8869     529.8948     -39.40899    597.10626\n","    263.91565    -82.410706     8.802216   118.385605  -385.93622\n","     56.482105   180.91212   -142.89609   -125.924835  3170.858\n","    100.888275  -310.8698    -420.612       25.227432   145.97968\n","  -1839.0713     -72.32115   -153.26726     -9.178551  -187.19643\n","    -38.812027]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 14\n","Output: [[  232.66888  1736.8915   1757.7977   -148.00311  2372.2393   1355.3911\n","    414.62964   404.16364   546.7501  -1722.9381    428.45374   623.11475\n","   -379.74237  -132.96924  9428.146     451.34772  -661.5565   -764.00323\n","   -203.42572   697.5281  -5824.511    -837.9949     -9.84436   393.5105\n","   -485.30634  -178.30374]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -70.21912   -88.52131    27.535536   33.714493 -104.79584  -150.61693\n","  -302.60538  -158.19107   -35.182518  141.18356  -110.0025    -17.467552\n","   -39.824474 -149.87216   672.98804   -14.181198 -171.35507  -264.417\n","   110.95577   -51.603493 -299.1049    252.87773  -265.5538   -181.10938\n","   -88.26497    12.896399]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -78.306046 -111.6777     26.830112   27.832405  -57.36754  -101.08856\n","  -233.86224  -151.56497    -1.315918  135.339     -93.35603    -9.77544\n","   -44.638344 -162.71312   591.8219     19.659279 -184.91837  -209.2634\n","    78.06814   -60.976917 -232.87149   198.49594  -181.96417  -140.16473\n","   -70.567245  -26.662891]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -78.306046 -111.6777     26.830112   27.832405  -57.36754  -101.08856\n","  -233.86224  -151.56497    -1.315918  135.339     -93.35603    -9.77544\n","   -44.638344 -162.71312   591.8219     19.659279 -184.91837  -209.2634\n","    78.06814   -60.976917 -232.87149   198.49594  -181.96417  -140.16473\n","   -70.567245  -26.662891]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 14\n","Output: [[  410.28137  1735.0994   1771.4254   -202.17227  2442.058    1390.4213\n","    548.0887    415.35022   593.1517  -1891.3839    465.90344   677.74927\n","   -336.17398  -136.69855  9029.165     445.49368  -698.10834  -495.28644\n","   -247.61163   611.01074 -6028.3184   -929.85693   128.18994   659.12494\n","   -474.40875  -154.34372]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -86.10898  -107.89671    25.604185   45.521553  -69.18617  -107.38457\n","  -268.48392  -160.42114    -5.063511  147.65286  -107.18135   -22.891418\n","   -45.856987 -174.20236   662.7617     21.087234 -186.83055  -237.77074\n","    87.62656   -47.40767  -267.8375    227.74722  -234.45401  -172.5475\n","   -82.8653    -20.926071]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -75.08293   -98.59062    25.590345   34.2619    -74.03186  -114.90884\n","  -257.58447  -150.45671   -13.299824  135.73615   -99.37277   -16.043\n","   -41.702343 -155.77203   616.8229      8.500885 -173.79326  -227.66437\n","    88.52815   -51.196182 -255.94041   217.31868  -218.23105  -158.02292\n","   -77.3432    -11.101612]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -73.500465   -82.4858      21.165615    47.668312   -76.59653\n","  -106.841225  -260.0081    -140.5058     -15.384949   131.08301\n","  -100.776474   -27.153633   -37.70819   -147.7898     610.6598\n","     8.866226  -153.98132   -227.71367     87.020546   -31.227386\n","  -258.9139     219.40514   -243.442     -170.65282    -79.97336\n","    -3.9770966]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 14\n","Output: [[  298.4165   1143.3196   1181.6687   -121.03224  1593.1328    896.2593\n","    318.5196    253.40442   388.4596  -1276.6136    285.99002   458.5172\n","   -224.41309  -107.8501   6004.379     279.68832  -476.8225   -306.9756\n","   -170.7909    333.3902  -4084.7664   -590.79297    36.70691   457.12704\n","   -314.72092   -81.41373]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -63.85669   -94.93844    32.925957   14.404564 -120.035995 -180.3007\n","  -317.24252  -167.02693   -48.156902  142.60207  -110.00937    -3.645012\n","   -40.802353 -145.68933   684.26434   -32.18077  -183.4293   -277.69083\n","   124.127975  -73.670166 -311.76514   263.35654  -255.89276  -172.76036\n","   -88.33469    22.683117]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 14\n","Output: [[ -79.74652  -114.31383    30.994581   26.211601  -84.42636  -137.06836\n","  -283.12106  -169.257     -18.037914  149.07137  -107.18821    -9.068878\n","   -46.834877 -170.01952   674.03796     3.087677 -198.90477  -251.04456\n","   100.79877   -69.474335 -280.49777   238.22601  -224.79294  -164.1985\n","   -82.935005  -11.139347]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 14\n","Output: [[  2871.355     8799.662     8203.982    -1088.529    11783.715\n","    7364.4336    4268.6025    2848.5828    2902.7068  -10189.191\n","    2798.6401    3470.3403   -1300.6034     100.89551  38509.47\n","    1666.8892   -2431.5928    -358.6112   -2058.8892    2283.6255\n","  -27504.182    -6046.8037    1977.1123    4485.3726   -1504.4027\n","    -560.983  ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 14\n","Output: [[  995.921     3044.312     2876.9507    -349.63043   4091.7742\n","   2567.9795    1408.7297     934.6022    1035.3202   -3511.7593\n","    930.8623    1221.3997    -471.30927    -49.744385 13746.959\n","    573.3998    -944.68713   -213.36435   -699.917      755.98804\n","  -9739.434    -2038.4286     607.50916   1495.5466    -545.455\n","   -203.5867  ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 14\n","Output: [[  2801.7803    8183.2695    7457.766     -885.89844  10839.441\n","    7085.288     4261.8604    2768.1694    2799.392    -9487.426\n","    2620.1309    3207.1504   -1145.2072     119.01709  34877.14\n","    1439.9983   -2149.42       -83.90808  -2083.109     2076.5952\n","  -25066.256    -5796.412     1933.0127    4155.411    -1249.8965\n","    -543.94946]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 14\n","Output: [[  2370.032      6830.8955     6233.032      -725.58966    9042.874\n","    5978.384      3593.6384     2318.229      2375.7444    -7962.458\n","    2186.6626     2712.4624     -968.3806       62.195312  29261.291\n","    1162.1586    -1860.8872      -60.737244  -1774.268      1671.9236\n","  -21021.805     -4867.5776     1618.8037     3466.4497    -1024.1051\n","    -484.82825 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 14\n","Output: [[  1912.7761     5372.526      4899.8965     -554.6675     7066.8228\n","    4730.792      2854.1707     1830.7656     1875.8362    -6282.3076\n","    1714.4341     2145.9043     -756.3001       29.025146  23077.94\n","     839.4321    -1486.4858      -49.94806   -1426.8281     1265.8372\n","  -16595.992     -3838.8418     1232.4102     2699.1443     -781.2736\n","    -383.01837 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 14\n","Output: [[-8.1445396e+01 -9.2173492e+01  2.0199936e+01  5.3571831e+01\n","  -5.8791687e+01 -8.5225067e+01 -2.4294734e+02 -1.4162083e+02\n","  -3.2543945e-01  1.3431766e+02 -9.9365891e+01 -2.9865562e+01\n","  -4.0724449e+01 -1.5995488e+02  6.0554663e+02  2.6500458e+01\n","  -1.6171906e+02 -2.1439056e+02  7.5355934e+01 -2.9129478e+01\n","  -2.4328021e+02  2.0683987e+02 -2.2789209e+02 -1.6637189e+02\n","  -7.7273499e+01 -2.0888329e+01]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 14\n","Output: [[  673.9706    1919.97      1768.3442    -157.4416    2522.3433\n","   1707.8108     945.8647     610.71       699.0032   -2220.266\n","    570.6089     769.0256    -284.4064     -59.747314  8571.408\n","    307.63788   -604.8883     -97.39801   -495.56808    439.22186\n","  -6087.32     -1311.7524     345.39038    897.6782    -305.5109\n","   -143.01685 ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 14\n","Output: [[-8.9273880e+01 -1.4010634e+02  3.4453640e+01  1.8708717e+01\n","  -6.4056870e+01 -1.2351976e+02 -2.6363675e+02 -1.8032295e+02\n","  -8.9328766e-01  1.5695917e+02 -1.0437395e+02 -6.7018127e-01\n","  -5.3845272e+01 -1.9016690e+02  6.7508783e+02  2.0356583e+01\n","  -2.2645445e+02 -2.3767213e+02  9.0641754e+01 -8.7345230e+01\n","  -2.6189059e+02  2.2357436e+02 -1.8403210e+02 -1.4728766e+02\n","  -7.7605019e+01 -3.5175102e+01]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 14\n","Output: [[  724.3169    2072.1501    1885.3798    -114.147125  2717.0405\n","   1910.7668    1039.9426     671.227      782.2167   -2389.8682\n","    602.31934    797.0968    -305.32587    -91.73645   9251.094\n","    338.71832   -644.4575     -90.87384   -570.8445     494.71448\n","  -6553.457    -1423.9138     308.75427    918.76807   -321.7303\n","   -180.06305 ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 14\n","Output: [[  1660.96       4415.244      3893.5215     -371.1758     5668.898\n","    4007.8647     2469.253      1565.5277     1592.204     -5153.193\n","    1387.7847     1759.5409     -577.6206       41.320557  18361.672\n","     588.69214   -1170.6659       84.08801   -1255.2639      963.3352\n","  -13299.958     -3227.0332     1016.55054    2177.3083     -544.86237\n","    -312.11737 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.60% (488/500)\n","Noise 6% ‚Üí Accuracy: 96.80% (484/500)\n","Noise 9% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 12% ‚Üí Accuracy: 93.80% (469/500)\n","Noise 14% ‚Üí Accuracy: 92.80% (464/500)\n","Noise 17% ‚Üí Accuracy: 90.00% (450/500)\n","Noise 20% ‚Üí Accuracy: 93.40% (467/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 16/16)\n","Noise 3% ‚Üí Avg Retention: 97.25% (avg 15/16)\n","Noise 6% ‚Üí Avg Retention: 94.03% (avg 15/16)\n","Noise 9% ‚Üí Avg Retention: 90.38% (avg 14/16)\n","Noise 12% ‚Üí Avg Retention: 88.19% (avg 14/16)\n","Noise 14% ‚Üí Avg Retention: 85.28% (avg 13/16)\n","Noise 17% ‚Üí Avg Retention: 83.12% (avg 13/16)\n","Noise 20% ‚Üí Avg Retention: 80.09% (avg 12/16)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}