{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWX/TkwAz4tZsKg/y54uWk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-jhLz5ZRwQZt"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","Y_CLASS_INDEX = 24\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'Y'\n","# ------------------------\n","def encode_letter_Y():\n","    grid = np.array([\n","    [1, 0, 0, 0, 1],\n","    [0, 1, 0, 1, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0],\n","    [0, 0, 1, 0, 0]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_Y()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([Y_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_Y = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_Y = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_Y)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_Y()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == Y_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == Y_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_Y()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"7d0950d0-476e-4a68-ff9a-bdb8508ce9f6","executionInfo":{"status":"ok","timestamp":1764581598156,"user_tz":-330,"elapsed":427360,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 355.2431, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 24\n","Output: [[  -3.3917465 -116.29608      7.3666496   38.296032    61.596558\n","    -9.266342   -53.06804    -92.33681     66.051926    30.358253\n","   -17.687325    94.60799      6.163563  -113.7944     -38.411655\n","   111.003235    54.211105  -211.43164    -33.122253    29.900764\n","   185.77179   -167.89679   -195.16199   -159.77513    262.6388\n","   -62.253334 ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 24\n","Output: [[  83.18664   -71.828674   28.207386   23.740232  125.99828   117.61997\n","    14.977783 -166.82439   125.87596   -86.26358    17.656456  146.944\n","    31.24741  -198.44922  -191.68118   112.654      80.1706   -305.49277\n","   -40.327824   74.64371  -155.87323  -309.2154   -284.69623  -203.33417\n","   719.8041    -83.52577 ]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 24\n","Output: [[ 3.7565765e+01 -6.6473129e+01 -4.2782059e+01  3.5400902e+01\n","   6.0207146e+01  4.8629295e+01 -1.5081512e+01 -1.3492117e+02\n","   9.1205170e+01 -6.7971191e+00 -3.7097565e+01  6.5479813e+01\n","   2.9738888e+01 -1.6329846e+02 -9.7465958e+01  1.0577246e+02\n","   3.7017929e+01 -2.4256566e+02  2.5480461e-01  6.8549240e+01\n","  -1.8533963e+02 -1.9467557e+02 -2.0974339e+02 -2.0433073e+02\n","   5.8721991e+02 -7.4098053e+01]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 24\n","Output: [[  51.21644    -31.154312    -9.281715    -2.1864014   95.87857\n","    69.55609    -31.643394  -125.77019    122.54225    -91.98994\n","   -18.340645   109.03771     29.767204  -141.76207   -153.61526\n","    76.918434    49.109375  -275.83698     21.275238    38.135185\n","  -139.3719    -224.85815   -210.66707   -200.51785    592.23804\n","   -78.70469  ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 24\n","Output: [[  190.68326    271.43213    470.31647   -208.20247   1027.7809\n","  -5739.327      334.31537    -94.14703    824.1848   -1029.0381\n","    297.7675     573.6896     -53.722218  -301.31335  -1082.7372\n","    213.2857     131.89877   -443.3549     -89.513596   -96.96808\n","    591.108    -1047.6477    -110.43732   -116.29786   7816.9043\n","   -529.40393 ]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 24\n","Output: [[   75.36076     75.181946    75.22563     33.77066    303.81027\n","  -1808.1516      63.860092   -76.080414   246.97083   -248.61469\n","      9.918793   158.98087      5.538742  -137.99881   -284.51758\n","    123.004745   120.088486  -289.2723      15.696077    79.066444\n","     28.342361  -346.14658   -227.75708   -220.59726   2695.7034\n","   -163.77155 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 24\n","Output: [[   8.38781    -87.67562    -96.72897     77.449554   -44.853985\n","  -185.79059    -31.255516  -109.88312      1.4352531  114.296555\n","   -99.65416      5.192871    25.169876  -109.520485    50.62189\n","    91.04329     41.09445   -208.53006     39.689983    97.598434\n","  -231.69827    -73.42782   -209.17375   -218.70421    580.0292\n","   -30.162327 ]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 24\n","Output: [[  148.21422    156.16748    264.85556    -61.717075   442.794\n","  -2555.309       80.56108    -69.801895   292.74658   -451.1961\n","     68.30019    256.437      -43.629684  -109.83234   -362.91153\n","     54.634407   100.257805  -273.48444     27.61044    -57.32847\n","    165.65437   -375.39618   -121.15765    -62.16738   3357.3447\n","   -167.82935 ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 24\n","Output: [[  474.6624     817.9678    1236.6016    -278.4932    1858.7888\n","  -8337.809      528.79913     82.039734  1111.5613   -1912.2618\n","    475.6671     770.6324    -266.50494   -191.87524  -1374.1199\n","    127.4704     333.7989    -257.4391    -157.22684   -322.22244\n","   1162.2611   -1228.5626      92.99707    391.94623  10381.861\n","   -609.7837  ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 24\n","Output: [[  28.623978  -70.71707   -95.03507    59.284966  -94.10359  -221.33617\n","   -80.1319   -114.708626  -38.881622  112.13748  -107.10358    16.5886\n","    32.40083   -83.86055    69.472626   46.101692   54.081787 -253.25893\n","    74.17176    87.499626 -271.23923   -40.262547 -250.9318   -234.07089\n","   552.21564    12.250286]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 24\n","Output: [[   9.705238   -96.0432     -82.11201     50.604317   -48.095528\n","  -211.33893    -36.29257   -113.61641     -4.4759064  109.5784\n","   -90.784744    20.344398    19.259262  -104.66941     51.33272\n","    73.10304     17.51498   -199.37622     45.21476     62.312305\n","  -212.9093     -61.78675   -169.01837   -187.18077    552.4624\n","   -27.45391  ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 24\n","Output: [[   9.705238   -96.0432     -82.11201     50.604317   -48.095528\n","  -211.33893    -36.29257   -113.61641     -4.4759064  109.5784\n","   -90.784744    20.344398    19.259262  -104.66941     51.33272\n","    73.10304     17.51498   -199.37622     45.21476     62.312305\n","  -212.9093     -61.78675   -169.01837   -187.18077    552.4624\n","   -27.45391  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 24\n","Output: [[  573.1105     1021.07367    1494.1101     -304.86273    1978.9714\n","  -8446.97        625.0939      182.34546    1051.7068    -2119.4102\n","    569.35876     697.6421     -377.34216    -197.47003   -1297.7786\n","     14.3593445   344.6738       40.035477   -276.3086     -426.30457\n","   1258.6498    -1232.1095      291.43616     732.7044    10136.486\n","   -560.70056  ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 24\n","Output: [[  13.528244  -90.066666  -97.867035   71.347374  -58.56443  -208.2644\n","   -44.614822 -117.122025   -8.642361  118.36235  -104.203636   11.273628\n","    26.6875   -108.16541    57.38526    81.68109    40.77396  -226.5114\n","    50.40802    92.39678  -247.55594   -67.17412  -219.72916  -225.82608\n","   596.1666    -21.729042]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 24\n","Output: [[  16.594398  -82.1846    -88.00453    57.99573   -64.24434  -205.10065\n","   -51.53257  -110.54305   -16.639969  108.82504   -96.669426   15.426125\n","    25.071232  -94.94253    57.020992   64.28348    35.95863  -217.3269\n","    54.33426    77.50678  -234.14546   -54.151497 -204.69739  -207.06485\n","   544.27026   -11.818447]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 24\n","Output: [[  18.343124  -65.935005  -92.75897    71.48932   -66.68271  -176.38853\n","   -53.41324  -100.230804  -18.72641   104.00589   -98.00464     4.427086\n","    29.365574  -86.57071    55.9459     64.826065   54.72277  -217.2962\n","    52.735714   97.90292  -239.52393   -52.76993  -229.82101  -219.8271\n","   519.9407     -4.616287]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 24\n","Output: [[  422.1682     741.84174   1011.4102    -176.23524   1282.6749\n","  -5627.799      405.5952     135.73242    652.1246   -1430.9895\n","    367.16995    427.4209    -270.47452   -150.58398   -822.9127\n","    -26.384857   261.67264     42.14023   -193.8743    -264.21844\n","    786.1134    -828.5209     133.45886    493.01804   6723.435\n","   -333.55615 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 24\n","Output: [[  34.42311   -77.291885  -88.864716   39.760178 -109.434814 -256.5842\n","   -96.009796 -123.81416   -51.91483   113.84422  -107.21835    30.245132\n","    30.963137  -80.07994    76.59141    27.769371   41.97155  -266.66336\n","    87.65216    64.654915 -277.70242   -28.188324 -241.40952  -225.43112\n","   554.5697     22.0378  ]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 24\n","Output: [[  19.327393  -96.64147   -91.69661    51.822594  -73.89564  -243.51242\n","   -60.492687 -126.22758   -21.675545  120.06909  -104.318405   24.93015\n","    25.249825 -104.384796   64.504036   63.348793   28.66373  -239.91583\n","    63.88842    69.55208  -254.01913   -55.09989  -210.20686  -217.18628\n","   598.5207    -11.941555]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 24\n","Output: [[  3171.0842    5934.583     8019.2183   -1653.375     9580.144\n","  -39112.43      3567.1326    1831.9033    4835.8677  -11071.097\n","    3238.3193    3026.0503   -2211.5776    -501.58154  -6206.737\n","    -907.885     1556.3049    1893.0242   -1951.565    -2579.0342\n","    7417.229    -5522.1924    2429.1494    5032.7075   44654.375\n","   -2375.8472 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 24\n","Output: [[  1142.8411    2052.0122    2780.8665    -549.00446   3332.6877\n","  -13810.314     1257.6765     593.3585    1707.6099   -3836.8389\n","    1078.8123    1073.0284    -778.0774    -231.37146  -2145.9387\n","    -294.72748    547.5824     575.6915    -665.6982    -873.6304\n","    2511.0747   -1967.8811     763.36523   1677.484    15919.1875\n","    -844.6152 ]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 24\n","Output: [[  3009.9053   5580.7236   7464.0776  -1473.4148   8870.071  -35801.344\n","    3484.9077   1805.563    4537.9146 -10291.561    2990.7173   2765.0264\n","   -2098.076    -455.6548  -5725.3906   -905.4729   1419.2695   1936.1498\n","   -1913.2043  -2362.323    7035.1895  -5081.4556   2297.8477   4732.5234\n","   40827.05    -2210.6343]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 24\n","Output: [[  2556.251     4674.5996    6267.402    -1231.8296    7424.027\n","  -30076.164     2962.8882    1517.9612    3814.1543   -8625.445\n","    2477.7185    2333.707    -1785.0906    -417.08643  -4787.5093\n","    -779.75946   1172.4828    1614.0139   -1621.6201   -1993.2637\n","    5904.161    -4257.871     1901.8037    3959.5437   34335.664\n","   -1872.2784 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 24\n","Output: [[  2055.5962    3700.974     4952.156     -961.7696    5818.471\n","  -23753.023     2359.425     1204.5898    2988.1309   -6801.0874\n","    1935.2283    1843.3843   -1412.7585    -342.8181   -3749.0044\n","    -663.33       942.20685   1245.9526   -1295.5812   -1563.8115\n","    4631.807    -3342.1113    1441.1643    3095.295    27139.117\n","   -1463.6235 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 24\n","Output: [[  10.795227   -75.60979    -94.17493     77.520515   -48.913124\n","  -169.85265    -35.65471   -101.43749     -3.6067772  107.118324\n","   -96.55466      1.769577    26.508915   -98.72313     49.90221\n","    82.61577     48.068855  -203.92245     40.853836   100.35151\n","  -227.68225    -66.22572   -214.21967   -215.70468    541.9162\n","   -21.605953 ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 24\n","Output: [[  770.8702   1326.4567   1756.6077   -302.0805   2085.3684  -8646.748\n","    861.06805   401.23352  1097.7615  -2423.5374    645.6032    665.43774\n","   -509.8581   -167.89081 -1334.5789   -208.6412    360.8917    373.17993\n","   -454.58148  -513.9446   1590.4635  -1241.1057    417.97864  1024.305\n","  10037.318    -537.3849 ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 24\n","Output: [[  10.0308    -122.56584    -88.35813     44.360195   -53.6877\n","  -265.68863    -40.8535    -137.74655     -4.469486   128.00067\n","  -101.53322     33.271698    18.098824  -124.90905     59.53545\n","    80.59589      3.2456646 -226.57274     53.605072    51.604492\n","  -236.79903    -69.937256  -169.4819    -200.30164    644.8258\n","   -36.133392 ]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 24\n","Output: [[  837.27423  1448.6617   1874.4598   -269.24158  2255.2236  -9252.758\n","    965.6287    455.3203   1200.5778  -2606.8135    678.3836    682.9656\n","   -544.0209   -193.17285 -1437.6963   -203.52405   433.2132    404.20575\n","   -524.9326   -493.63266  1700.9557  -1357.3553    382.09875  1053.8094\n","  10858.147    -596.8314 ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 24\n","Output: [[  1766.1365    3099.5562    4060.3608    -733.7366    4702.515\n","  -19103.656     2024.0303    1059.1304    2466.9097   -5557.15\n","    1542.0828    1466.0977   -1176.9764    -253.24854  -3026.6362\n","    -614.4659     780.8327    1086.9668   -1103.1785   -1254.5876\n","    3845.7986   -2684.3237    1143.4277    2533.7708   21795.176\n","   -1178.5431 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.80% (489/500)\n","Noise 6% ‚Üí Accuracy: 96.60% (483/500)\n","Noise 9% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 12% ‚Üí Accuracy: 94.60% (473/500)\n","Noise 14% ‚Üí Accuracy: 93.40% (467/500)\n","Noise 17% ‚Üí Accuracy: 93.20% (466/500)\n","Noise 20% ‚Üí Accuracy: 96.00% (480/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 9/9)\n","Noise 3% ‚Üí Avg Retention: 97.17% (avg 8/9)\n","Noise 6% ‚Üí Avg Retention: 94.39% (avg 8/9)\n","Noise 9% ‚Üí Avg Retention: 90.50% (avg 8/9)\n","Noise 12% ‚Üí Avg Retention: 88.33% (avg 7/9)\n","Noise 14% ‚Üí Avg Retention: 86.33% (avg 7/9)\n","Noise 17% ‚Üí Avg Retention: 83.44% (avg 7/9)\n","Noise 20% ‚Üí Avg Retention: 80.06% (avg 7/9)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}