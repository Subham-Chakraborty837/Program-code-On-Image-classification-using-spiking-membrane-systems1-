{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQ7itQdWNnXMSCu57cFxXa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kMIDfMv6887b"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","G_CLASS_INDEX = 6\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'G'\n","# ------------------------\n","def encode_letter_G():\n","    grid = np.array([\n","    [0, 1, 1, 1, 0],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 0],\n","    [1, 0, 0, 1, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [0, 1, 1, 1, 0]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_G()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([G_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_G = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_G = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_G)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_G()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == G_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == G_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_G()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","executionInfo":{"status":"ok","timestamp":1764565209368,"user_tz":-330,"elapsed":396125,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}},"outputId":"d595b869-75a2-4f74-dca6-141a973dc045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 380.1074, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 6\n","Output: [[ 9.2432114e+01 -1.8430008e+02  8.3489609e-01  1.1743641e+02\n","   4.6922119e+01 -4.1401878e+01  6.4415228e+02 -7.5981476e+01\n","   2.9291763e+01  8.2023499e+01 -1.1910110e+01  6.0038246e+01\n","   8.0826790e+01 -1.5362723e+02 -1.1526976e+02  4.1756748e+01\n","   8.0587830e+01 -2.2979431e+02 -6.1966427e+01  9.3500214e+01\n","  -1.0909592e+02 -2.6968197e+01 -2.2069157e+02 -1.7688954e+02\n","  -6.1037827e-01  2.7471504e+00]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 6\n","Output: [[ 205.81075  -134.9302     88.914764  134.45267   141.6304     33.205612\n","   871.61847   -72.24858    38.517612   11.477661   41.59743    34.52278\n","   141.51012  -196.36496  -192.54242    39.84376   134.5971   -345.3838\n","  -111.97373    79.00834   -49.029083  -80.66066  -276.3246   -208.6823\n","   -91.73271    31.850388]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 6\n","Output: [[  93.35733   -119.966156    25.601585    96.311005    90.615875\n","    -2.657421   671.46783    -74.76593     60.930855    61.902935\n","   -18.311712    -6.0248985  110.74301   -184.39029   -119.23744\n","    70.97991     74.02179   -245.77878    -43.36949     84.33993\n","   -81.20089    -40.694206  -239.88892   -206.81418    -47.538227\n","     5.1254845]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 6\n","Output: [[ 139.08824   -87.99624    81.564316   81.46778   128.48122     9.173336\n","   686.85583   -76.78485    45.466034   12.580521   20.11651    27.806255\n","   118.91699  -179.47203  -155.17966    61.718033   90.30639  -273.1289\n","   -40.620407   54.72465   -55.939316  -73.97028  -250.95067  -191.33304\n","   -87.23657    33.19008 ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 6\n","Output: [[ 647.265      176.04184    792.5709     197.32968   1058.3813\n","   813.09033   1601.4194     -58.573364   171.85681   -609.39984\n","   588.28723    294.5522     219.69008   -363.64752   -802.2178\n","   333.22986    271.85767   -412.93146   -406.34872   -153.5148\n","   640.13074   -784.99475    -93.85614     28.703323  -549.5421\n","    -1.8357086]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 6\n","Output: [[ 180.08853    29.557693  212.66531   119.89305   331.3077    209.06755\n","   774.0666    -45.276398   81.49479  -141.0622    112.42644    45.76329\n","    97.13257  -189.39413  -242.40541   140.22693   142.44583  -213.10062\n","   -92.69057    73.55751    57.58661  -200.12878  -232.84167  -142.50221\n","  -143.97179   -11.434078]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 6\n","Output: [[  14.662039 -170.71      -87.96858    97.780525   -9.724564  -93.90288\n","   539.15546   -91.577545   81.37131   140.76056   -96.67894   -36.508217\n","    93.07529  -146.87262   -51.862896   46.336567   40.472065 -197.41846\n","     6.319708  152.73149  -196.29817    65.85505  -251.9958   -246.86325\n","    63.064182   12.223967]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 6\n","Output: [[  268.47125     86.45008    396.42297     28.89691  -3391.383\n","    238.34915   4573.202      -65.33646     72.664505  -313.10352\n","    210.46259    150.2775      36.53424   -169.45071   -264.66815\n","     72.74063    119.01434   -198.76498   -112.07919    -60.917465\n","    112.2419    -255.92853   -117.50464     10.008415  -176.43175\n","    -11.087242]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 6\n","Output: [[   834.7135      754.05945    1624.1384      -26.720657 -11530.458\n","    1299.9846    14731.742        66.447266    209.2985    -1508.1609\n","     955.04736     542.6354     -175.77963    -322.48926    -805.9093\n","     265.60773     393.33954     -26.90718    -564.4061     -477.44305\n","     915.41345   -1181.4445      187.18323     663.0849     -714.3846\n","    -227.32324 ]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 6\n","Output: [[ 3.48676949e+01 -1.55804443e+02 -8.61529312e+01  8.01470718e+01\n","  -3.94315033e+01 -1.59266205e+02  4.84353180e+02 -9.58558502e+01\n","   4.33563614e+01  1.39109482e+02 -1.03856140e+02 -2.63686600e+01\n","   1.02121971e+02 -1.22113075e+02 -3.57740593e+01  1.91789627e-01\n","   5.33125153e+01 -2.41577103e+02  3.97403259e+01  1.43847794e+02\n","  -2.36993530e+02  1.03671814e+02 -2.94577515e+02 -2.62858948e+02\n","   5.70357056e+01  5.57952614e+01]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 6\n","Output: [[  15.533375 -172.35349   -74.26133    69.35233   -40.210564 -108.891235\n","   512.6154    -97.02849    68.964584  133.81728   -88.00037   -17.901134\n","    81.59476  -138.7912    -42.684803   32.04531    16.911232 -189.38507\n","    14.508268  112.93271  -181.62604    66.12854  -208.21764  -213.17079\n","    59.563133   11.531738]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 6\n","Output: [[  15.533375 -172.35349   -74.26133    69.35233   -40.210564 -108.891235\n","   512.6154    -97.02849    68.964584  133.81728   -88.00037   -17.901134\n","    81.59476  -138.7912    -42.684803   32.04531    16.911232 -189.38507\n","    14.508268  112.93271  -181.62604    66.12854  -208.21764  -213.17079\n","    59.563133   11.531738]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 6\n","Output: [[   883.6996      972.04895    1753.0459      -77.741135 -11583.219\n","    1489.164     14513.923       228.64563     250.8833    -1750.3955\n","    1008.1546      593.8094     -371.19458    -296.9881     -732.415\n","      65.02069     399.6595      247.40578    -697.742      -628.91943\n","    1081.4359    -1309.4348      324.30005     871.89185    -627.32477\n","    -351.81747 ]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 6\n","Output: [[  20.003918 -176.12613   -88.852264   92.43922   -23.412018 -116.12167\n","   547.6001    -98.18044    74.27246   145.74036  -101.06542   -31.978859\n","    97.08129  -146.82812   -48.846386   35.330444   40.09306  -214.97855\n","    15.761707  149.49539  -211.5861     77.428764 -264.02563  -255.0207\n","    64.04863    22.23273 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 6\n","Output: [[  22.529594 -161.3709    -79.7653     77.420364  -32.97734  -122.96932\n","   494.262     -93.14073    59.7099    133.97348   -93.735     -24.399574\n","    89.85537  -130.47437   -40.737682   21.621613   35.301373 -206.70103\n","    22.40329   130.00829  -201.66583    79.11331  -245.38263  -233.93614\n","    57.807182   28.65912 ]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 6\n","Output: [[  24.183928 -144.97217   -84.38557    90.8297    -12.056641 -114.82858\n","   467.46396   -82.65008    57.554016  129.14987   -95.08319   -35.427357\n","    94.10997  -122.20203   -41.807068   22.20404    54.07055  -206.4569\n","    20.856321  150.31998  -206.41766    80.52438  -270.5178   -246.54404\n","    55.066788   35.777725]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 6\n","Output: [[  618.20245   673.49976  1151.6791    -21.35141 -7637.2734   1009.8987\n","   9595.516     185.49677   195.55176 -1192.3763    642.3186    399.25092\n","   -266.9643   -207.90607  -474.16232   -27.30513   299.6962    164.92464\n","   -490.5564   -386.88058   694.6177   -858.4569    129.57904   531.3494\n","   -369.2772   -243.4195 ]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 6\n","Output: [[  40.645256 -162.0423    -80.18297    60.591682  -68.36194  -188.97919\n","   479.52774  -105.184204   30.054167  140.61765  -103.903336  -12.535767\n","   100.38769  -118.02789   -28.16851   -17.959963   41.15306  -255.12053\n","    53.276638  120.71231  -244.94543   115.38226  -284.71826  -254.17018\n","    56.269638   65.457924]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 6\n","Output: [[  25.781483 -182.364     -82.882324   72.88381   -52.342484 -145.83467\n","   542.77466  -107.50879    60.97028   147.24852  -101.112595  -18.145973\n","    95.34701  -142.74297   -41.24084    17.178694   27.933624 -228.522\n","    29.298004  126.35994  -219.538      89.13923  -254.16641  -246.33194\n","    63.282547   31.895405]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 6\n","Output: [[  4331.463    5911.0586   8866.305    -768.641  -54622.58     8140.2534\n","   65551.82     2026.6313   1110.1646  -9575.2705   5200.9927   3168.413\n","   -2697.5886   -716.2566  -3054.0232   -613.9414   1818.6488   2710.1387\n","   -3805.689   -3819.8882   6442.6543  -6727.9365   2662.4067   5467.7637\n","   -2857.6257  -2090.546 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 6\n","Output: [[  1541.835     1995.8799    3075.4019    -231.20134 -19160.422\n","    2807.9155   23221.621      670.499      433.0108   -3300.0479\n","    1779.0741    1109.3928    -916.9274    -323.2433   -1082.7882\n","    -217.19708    644.38336    870.54865  -1336.4882   -1288.9851\n","    2173.5388   -2330.7954     828.2324    1809.8987    -961.58026\n","    -731.25696]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 6\n","Output: [[  4025.3682   5571.8447   8199.642    -693.2791 -50168.76     7675.34\n","   60086.85     1972.8293   1084.1833  -8939.418    4811.649    2931.5898\n","   -2574.9106   -632.7134  -2780.768    -633.975    1680.4453   2682.0818\n","   -3600.4958  -3556.5542   6070.8374  -6281.5107   2541.171    5122.676\n","   -2581.245   -2009.6348]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 6\n","Output: [[  3395.8015    4646.542     6867.8477    -572.828   -42077.39\n","    6439.843    50464.65      1648.1958     942.7871   -7502.236\n","    4013.0854    2480.4653   -2172.0461    -564.57153  -2332.6577\n","    -565.56165   1398.8806    2237.1797   -3036.6404   -2984.4448\n","    5071.134    -5263.188     2114.0613    4267.2515   -2124.207\n","   -1707.7463 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 6\n","Output: [[  2697.25      3670.9912    5413.1055    -453.6169  -33195.316\n","    5061.001    39828.63      1308.2205     751.3308   -5926.367\n","    3138.9817    1961.2476   -1713.4742    -456.55518  -1833.6611\n","    -503.02896   1123.5552    1734.6738   -2400.9197   -2346.4663\n","    3970.0198   -4131.3936    1610.1631    3329.0874   -1644.0388\n","   -1346.5427 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 6\n","Output: [[  16.752037  -155.13303    -85.73524     96.97575     -4.0468903\n","   -93.256355   499.0874     -83.81238     73.01207    132.4653\n","   -93.687836   -38.232456    91.58964   -134.55956    -48.343235\n","    39.773357    47.460808  -193.15761      8.866997   153.14377\n","  -193.71393     67.402855  -255.24188   -242.62492     58.57327\n","    18.996456 ]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 6\n","Output: [[   994.3876    1268.1052    1920.2131    -110.05313 -11992.069\n","    1803.4006   14606.977      445.14697    313.45068  -2092.2573\n","    1095.362      696.8603    -589.65314   -226.22351   -677.85815\n","    -172.96904    430.07867    557.3095    -874.0018    -777.12604\n","    1356.3013   -1470.9121     461.77136   1095.2861    -562.4263\n","    -481.26352]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 6\n","Output: [[  16.695261  -208.92357    -79.61173     65.62056    -65.2534\n","  -132.40312    601.19617   -119.16172     78.58418    155.38754\n","   -98.36904     -9.92329     88.57207   -163.37285    -46.707607\n","    34.165565     2.5547352 -215.46683     18.85564    108.87206\n","  -202.08246     74.60664   -213.7553    -229.8049      69.52942\n","     7.9955235]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 6\n","Output: [[  1066.502      1372.7969     2044.7035      -63.557297 -12845.287\n","    1994.2104    15779.248       500.58618     374.47754   -2253.6611\n","    1160.1788      718.04736    -625.7272     -265.02808    -749.58453\n","    -168.35544     506.9406      603.1759     -972.9059     -765.7816\n","    1445.4603    -1592.8547      423.74207    1123.1918     -585.0209\n","    -537.72107 ]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 6\n","Output: [[  2216.5994    3044.2927    4396.5205    -341.90244 -26770.105\n","    4168.9224   32046.76      1126.9084     634.855    -4861.328\n","    2544.8494    1603.6923   -1450.7513    -355.2273   -1450.3962\n","    -481.013      929.63794   1492.229    -1991.0804   -1904.3408\n","    3254.0286   -3367.252     1282.1211    2715.239    -1292.3306\n","   -1116.4155 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 97.80% (489/500)\n","Noise 6% ‚Üí Accuracy: 96.80% (484/500)\n","Noise 9% ‚Üí Accuracy: 97.20% (486/500)\n","Noise 12% ‚Üí Accuracy: 96.60% (483/500)\n","Noise 14% ‚Üí Accuracy: 96.40% (482/500)\n","Noise 17% ‚Üí Accuracy: 96.00% (480/500)\n","Noise 20% ‚Üí Accuracy: 98.40% (492/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 16/16)\n","Noise 3% ‚Üí Avg Retention: 97.25% (avg 15/16)\n","Noise 6% ‚Üí Avg Retention: 94.22% (avg 15/16)\n","Noise 9% ‚Üí Avg Retention: 90.41% (avg 14/16)\n","Noise 12% ‚Üí Avg Retention: 88.12% (avg 14/16)\n","Noise 14% ‚Üí Avg Retention: 85.03% (avg 13/16)\n","Noise 17% ‚Üí Avg Retention: 83.06% (avg 13/16)\n","Noise 20% ‚Üí Avg Retention: 79.91% (avg 12/16)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}