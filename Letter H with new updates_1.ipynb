{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUMOiILLVQZhWMRRAEEbt2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vs7qJtpx9xZL"},"outputs":[],"source":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import random\n","\n","# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Constants\n","ROWS, COLS = 7, 5\n","INPUT_NEURONS = 37          # padded input size\n","RECOGNIZE_NEURONS = 43      # upper bound for recognition layer\n","CLASS_NEURONS = 26\n","SPIKE_LENGTH = 35\n","H_CLASS_INDEX = 7\n","TRAIN_SAMPLES = 3000\n","TEST_SAMPLES = 400\n","use_biological_input = True  # üîÅ Toggle this to switch input mode\n","\n","# ------------------------\n","# Encode letter 'H'\n","# ------------------------\n","def encode_letter_H():\n","    grid = np.array([\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 1, 1, 1, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1],\n","    [1, 0, 0, 0, 1]\n","    ])\n","    flat = grid.flatten().tolist()\n","    flat += [0, 0]  # pad to 37\n","    return torch.tensor(flat[:INPUT_NEURONS], dtype=torch.float32)\n","\n","# ------------------------\n","# Noise injection\n","# ------------------------\n","def generate_noisy_sample(base_tensor, noise_level=0.20):\n","    base_array = base_tensor.detach().cpu().numpy()\n","    noise = np.random.rand(*base_array.shape) < noise_level\n","    noisy_array = np.where(noise, 1 - base_array, base_array)\n","    return torch.tensor(noisy_array, dtype=torch.float32)\n","\n","# ------------------------\n","# Dynamic Input Module\n","# ------------------------\n","def input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH):\n","    I = torch.zeros(num_inputs)\n","    for _ in range(num_spikes):\n","        i = random.randint(0, num_inputs - 1)\n","        I[i] += 1\n","    active_indices = []\n","    for i in range(num_inputs):\n","        if I[i] >= 2:\n","            I[i] -= 1\n","        if I[i] > 0:\n","            active_indices.append(i)\n","    R = I[active_indices]\n","    return R, active_indices\n","\n","# ------------------------\n","# Dynamic Recognize Module 1\n","# ------------------------\n","def recognize_module_1_dynamic(R, active_indices, group_size=7):\n","    num_active = len(active_indices)\n","    num_groups = (num_active + group_size - 1) // group_size\n","    T = torch.zeros(num_groups, group_size)\n","    for idx, r_val in enumerate(R):\n","        k = idx // group_size\n","        j = idx % group_size\n","        T[k, j] = r_val\n","    return T\n","\n","# ------------------------\n","# Dynamic Recognize Module 2\n","# ------------------------\n","def recognize_module_2_dynamic(T):\n","    Out = torch.zeros(T.shape[0])\n","    for k in range(T.shape[0]):\n","        Out[k] = T[k].sum()\n","    return Out\n","\n","# ------------------------\n","# Dynamic Structured Pipeline\n","# ------------------------\n","def simulate_structured_input_dynamic(noise_level=0.20):\n","    R, active_indices = input_module_dynamic(num_inputs=35, num_spikes=SPIKE_LENGTH)\n","    T = recognize_module_1_dynamic(R, active_indices, group_size=7)\n","    Out = recognize_module_2_dynamic(T)\n","\n","    # Pad to fixed recognition size (43)\n","    vec = torch.zeros(RECOGNIZE_NEURONS)\n","    for i in range(min(RECOGNIZE_NEURONS, len(Out))):\n","        vec[i] = Out[i]\n","\n","    noisy_vec = generate_noisy_sample(vec, noise_level=noise_level)\n","    return noisy_vec.unsqueeze(0)\n","\n","# ------------------------\n","# Noisy encoded input (direct grid)\n","# ------------------------\n","def simulate_noisy_encoded_input(noise_level=0.20):\n","    clean = encode_letter_H()\n","    noisy = generate_noisy_sample(clean, noise_level=noise_level)\n","    return noisy.unsqueeze(0)\n","\n","# ------------------------\n","# Pixel retention\n","# ------------------------\n","def count_matching_black_pixels(original, noisy):\n","    black_matches = torch.sum((original == 1) & (noisy == 1)).item()\n","    total_black = torch.sum(original == 1).item()\n","    retention_ratio = black_matches / total_black * 100\n","    return black_matches, total_black, retention_ratio\n","\n","# ------------------------\n","# Hebbian Spiking Layer\n","# ------------------------\n","class HebbianSpikingLayer(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(output_size, input_size))\n","        self.threshold = nn.Parameter(torch.ones(output_size) * 0.5)\n","\n","    def forward(self, x):\n","        spike_counts = torch.matmul(x, self.weights.T)\n","        self.last_input = x\n","        self.last_output = spike_counts\n","        return spike_counts\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        with torch.no_grad():\n","            for i in range(self.weights.shape[0]):\n","                for j in range(self.weights.shape[1]):\n","                    x = self.last_input[0][j]\n","                    y = self.last_output[0][i]\n","                    if x == 1 and y > self.threshold[i]:\n","                        self.weights[i][j] += learning_rate\n","                    elif x == 1 and y <= self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","                    elif x == 0 and y > self.threshold[i]:\n","                        self.weights[i][j] -= learning_rate\n","\n","# ------------------------\n","# Multi-layer Hebbian Network\n","# ------------------------\n","class HebbianSpikingNetwork(nn.Module):\n","    def __init__(self, layer_sizes):\n","        super().__init__()\n","        self.layers = nn.ModuleList([\n","            HebbianSpikingLayer(layer_sizes[i], layer_sizes[i+1])\n","            for i in range(len(layer_sizes) - 1)\n","        ])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def hebbian_update(self, learning_rate=0.2):\n","        for layer in self.layers:\n","            layer.hebbian_update(learning_rate)\n","\n","# ------------------------\n","# Initialize model\n","# ------------------------\n","net = HebbianSpikingNetwork([RECOGNIZE_NEURONS, RECOGNIZE_NEURONS, CLASS_NEURONS])\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","target_class = torch.tensor([H_CLASS_INDEX])\n","\n","# ------------------------\n","# Training Phase (Clean Only)\n","# ------------------------\n","print(\"üîß Training Phase (Clean Only)\")\n","for epoch in range(TRAIN_SAMPLES):\n","    # Always use clean input (no noise)\n","    if use_biological_input:\n","        input_H = simulate_structured_input_dynamic(noise_level=0.0)\n","    else:\n","        input_H = simulate_noisy_encoded_input(noise_level=0.0)\n","\n","    optimizer.zero_grad()\n","    output = net(input_H)\n","    loss = loss_fn(output, target_class)\n","    loss.backward()\n","    optimizer.step()\n","    net.hebbian_update()\n","\n","    if epoch % 100 == 0:\n","        predicted = torch.argmax(output).item()\n","        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predicted Index: {predicted}\")\n","        print(f\"Output: {output.detach().numpy()}\")\n","\n","# ------------------------\n","# Testing Phase\n","# ------------------------\n","print(\"\\nüß† Testing Phase\")\n","correct = 0\n","original = encode_letter_H()\n","for _ in range(TEST_SAMPLES):\n","    if use_biological_input:\n","        test_input = simulate_structured_input_dynamic(noise_level=0.0)\n","        predicted_class = torch.argmax(net(test_input)).item()\n","    else:\n","        predicted_class = torch.argmax(net(original.unsqueeze(0))).item()\n","    if predicted_class == H_CLASS_INDEX:\n","        correct += 1\n","\n","accuracy = correct / TEST_SAMPLES * 100\n","print(f\"‚Üí Recognition Accuracy (Clean Only): {accuracy:.2f}% ({correct}/{TEST_SAMPLES})\")\n","\n","# ------------------------\n","# Recognition accuracy across noise levels\n","# ------------------------\n","print(\"\\nRecognition Accuracy Across Noise Levels:\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","for nl in noise_levels:\n","    correct = 0\n","    for _ in range(500):\n","        if use_biological_input:\n","            test_input = simulate_structured_input_dynamic(noise_level=nl)\n","            predicted_class = torch.argmax(net(test_input)).item()\n","        else:\n","            noisy_input = generate_noisy_sample(original, noise_level=nl).unsqueeze(0)\n","            predicted_class = torch.argmax(net(noisy_input)).item()\n","        if predicted_class == H_CLASS_INDEX:\n","            correct += 1\n","    accuracy = correct / 500 * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Accuracy: {accuracy:.2f}% ({correct}/500)\")\n","\n","# ------------------------\n","# Pixel retention (averaged across trials)\n","# ------------------------\n","print(\"\\nBlack Pixel Retention Across Noise Levels (Averaged):\")\n","noise_levels = [0.00, 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.20]\n","trials = 200  # number of trials per noise level\n","\n","original = encode_letter_H()\n","\n","for nl in noise_levels:\n","    avg_retention = 0\n","    total_black_matches = 0\n","    total_black = 0\n","\n","    for _ in range(trials):\n","        noisy_sample = generate_noisy_sample(original, noise_level=nl)\n","        black_matches, total_black_pixels, retention = count_matching_black_pixels(original, noisy_sample)\n","        avg_retention += retention\n","        total_black_matches += black_matches\n","        total_black = total_black_pixels  # same across trials\n","\n","    avg_retention /= trials\n","    print(f\"Noise {int(nl*100)}% ‚Üí Avg Retention: {avg_retention:.2f}% \"\n","          f\"(avg {total_black_matches//trials}/{total_black})\")\n","\n","print(\"\\nüß™ Pixel-wise Fidelity Across Noise Levels:\")\n","for nl in noise_levels:\n","    pixel_matches = 0\n","    total_pixels = 0\n","    num_trials = 200\n","    for _ in range(num_trials):\n","        noisy = generate_noisy_sample(original, noise_level=nl)\n","        pixel_matches += torch.sum(noisy == original).item()\n","        total_pixels += noisy.numel()\n","    pixel_accuracy = pixel_matches / total_pixels * 100\n","    print(f\"Noise {int(nl*100)}% ‚Üí Fidelity: {pixel_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12LZNfpLPH5-","outputId":"5fa431f6-da86-4b8b-e818-170ae4d840cd","executionInfo":{"status":"ok","timestamp":1764565541186,"user_tz":-330,"elapsed":438320,"user":{"displayName":"subham chakraborty","userId":"15228624797476546463"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Training Phase (Clean Only)\n","Epoch 0, Loss: 263.9183, Predicted Index: 8\n","Output: [[-107.46559   -86.58119   -65.64853    56.368416  -16.921785  -46.784264\n","  -146.79694   -30.607794  233.31049    94.30464  -106.851974   -7.716522\n","    15.722305  -71.16066    45.64531    95.45817     5.073929 -218.9513\n","    75.063416   51.87311    80.12563   169.40639  -201.5419   -210.65042\n","  -121.93262   -33.075127]]\n","Epoch 100, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -71.61297    -29.900528   -17.5728      66.6202     124.57659\n","   -17.230724   -83.67193    381.0928      18.606907    57.142395\n","    -6.9251184    3.3581696   23.977692  -135.94785    -73.86191\n","    45.883255    96.59511   -141.40176    -40.079044    19.152882\n","   123.04857    -50.838272  -216.50314   -163.24866    -74.84804\n","   -57.33197  ]]\n","Epoch 200, Loss: 0.0000, Predicted Index: 7\n","Output: [[-5.5572433e+01  4.7684006e+01  4.1228081e+01  8.5730438e+01\n","   2.1691653e+02  5.3519096e+01 -1.4606969e+02  9.2888239e+02\n","  -1.3734097e+01 -3.6144196e+01  4.6768845e+01  1.3574146e+01\n","   6.1629196e+01 -2.0008960e+02 -1.4882693e+02  3.9833832e-01\n","   2.2651102e+02 -1.8340842e+02 -8.3073936e+01  1.9655058e+01\n","  -2.5232578e+02 -1.4254395e+02 -3.3175171e+02 -2.2663979e+02\n","  -4.8657711e+01 -6.9197212e+01]]\n","Epoch 300, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -95.022934   36.30669   -21.607246   68.34155   154.75937    12.059223\n","  -169.9866    697.55176    -8.617447   35.275932   -5.872573  -16.076653\n","    50.561367 -171.74022   -83.495316   40.277092  145.33078  -129.11017\n","   -18.926945   18.470417 -216.92035   -58.439995 -271.16095  -205.92126\n","   -69.873604  -56.9617  ]]\n","Epoch 400, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -77.47185     94.82312     22.351002    43.1545     198.01761\n","    25.868275  -201.16702    764.0023     -34.155983   -19.802856\n","    18.556248    34.02871     42.98691   -180.36124    -93.60315\n","     5.2576447  167.07498   -132.7982     -14.475132    -9.407932\n","  -222.24103   -104.68335   -283.74582   -191.42416    -58.596855\n","   -61.46128  ]]\n","Epoch 500, Loss: 0.0000, Predicted Index: 7\n","Output: [[-1.5312744e+01  4.9485550e+02  5.5489642e+02 -1.5441299e+01\n","   1.1886252e+03  8.3888281e+02 -4.7638336e+01  1.9151875e+03\n","   1.1551460e+02 -7.0508594e+02  4.2951871e+02  4.2796906e+02\n","   7.4591675e+00 -5.6473694e+02 -4.7618979e+02 -8.8806763e+00\n","   4.8845111e+02  8.7495178e+01 -4.4891541e+02 -1.7602423e+02\n","   3.1571518e+01 -1.1368870e+03 -2.2916425e+02 -1.8175354e+00\n","   1.5719403e+02 -5.3706500e+02]]\n","Epoch 600, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -66.60596   201.76398   100.0865     60.94113   414.2108    207.83801\n","  -121.24483   909.9816     24.18267  -157.3425     70.99504    84.693924\n","    12.158684 -234.00427  -143.43018    51.918396  226.20145   -51.015114\n","  -108.61536    37.66375  -149.64455  -279.47174  -283.281    -166.68161\n","   -44.345715 -160.84027 ]]\n","Epoch 700, Loss: 0.0000, Predicted Index: 7\n","Output: [[-102.391914   11.475388 -107.547516   80.785645   50.370205  -76.59097\n","  -165.03273   467.06314   -25.915236  121.28349   -71.967804  -52.73717\n","    33.6553   -113.47864   -22.134949   57.271744   67.5074   -105.73274\n","    42.993595   51.518932 -225.58846    86.0616   -248.11153  -206.77968\n","   -97.05874   -12.894854]]\n","Epoch 800, Loss: 0.0000, Predicted Index: 7\n","Output: [[   2.7148743  264.6988     256.22644    -63.71788    532.2695\n","   233.86333   -107.54703    874.25464     32.757538  -321.18268\n","   122.86343    213.4726     -46.148598  -265.1739    -132.32086\n","     8.730446   181.02914    -57.62906   -121.569466   -30.426643\n","  -109.079895  -390.66724   -156.97003    -32.743576   -44.192257\n","  -184.11818  ]]\n","Epoch 900, Loss: 0.0000, Predicted Index: 7\n","Output: [[ 2.32913940e+02  9.34548584e+02  1.18889258e+03 -2.74256653e+02\n","  -1.99850625e+04  1.28387073e+03  2.66689209e+02  2.40741738e+04\n","   3.88184448e+02 -1.55102039e+03  6.17067993e+02  7.42306213e+02\n","  -2.69857605e+02 -7.51806274e+02 -5.25249512e+02  2.57208862e+01\n","   5.40651611e+02  1.11862183e+02 -6.89207886e+02 -6.20849609e+01\n","   1.14023766e+02 -1.65303760e+03  3.30999756e+00  3.56453491e+02\n","   2.14378967e+01 -7.08296753e+02]]\n","Epoch 1000, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -106.64882     101.664154    -50.41513      55.461544  -1378.6151\n","    -56.437717   -218.2907     2182.63        -21.65266       7.537834\n","    -16.203018     13.449478     29.812513   -107.15252     -73.434746\n","     -8.214119    138.39212    -171.16205      16.026337     34.177948\n","   -234.30667      33.089645   -299.76434    -241.2566     -117.74097\n","     -3.0514603]]\n","Epoch 1100, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -110.615944     56.04755     -43.4559       47.26549   -1234.3506\n","    -18.89193    -159.29036    1972.4758       10.114899     18.701752\n","    -11.123813     16.461727     17.139576   -124.77406     -74.58359\n","     25.064491     91.526886   -126.0214       -5.2603245    14.949062\n","   -179.69942       5.8472996  -212.30768    -193.3544      -96.47927\n","    -40.39857  ]]\n","Epoch 1200, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -110.615944     56.04755     -43.4559       47.26549   -1234.3506\n","    -18.89193    -159.29036    1972.4758       10.114899     18.701752\n","    -11.123813     16.461727     17.139576   -124.77406     -74.58359\n","     25.064491     91.526886   -126.0214       -5.2603245    14.949062\n","   -179.69942       5.8472996  -212.30768    -193.3544      -96.47927\n","    -40.39857  ]]\n","Epoch 1300, Loss: 0.0000, Predicted Index: 7\n","Output: [[ 4.5879672e+02  8.2924188e+02  1.2658398e+03 -2.4811061e+02\n","  -1.8789598e+04  1.2905170e+03  6.9461115e+02  2.2221258e+04\n","   5.0643250e+02 -1.6954067e+03  5.6377460e+02  5.5531000e+02\n","  -3.1721063e+02 -7.4936932e+02 -5.1295984e+02 -8.5204330e+01\n","   4.1414166e+02  1.3868840e+02 -7.6088501e+02 -9.7636292e+01\n","   1.2589722e+00 -1.5400162e+03  1.2634082e+02  5.3059326e+02\n","   3.8922913e+01 -6.1721161e+02]]\n","Epoch 1400, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -122.77129      82.3488      -53.826736     67.51149   -1368.6688\n","    -13.981369   -183.8258     2211.4023        8.097286     15.0288925\n","    -13.78471       7.186722     24.217812   -131.00974     -85.41077\n","     27.267822    124.81668    -143.6641       -6.977127     38.770767\n","   -209.88007       8.600393   -268.7945     -232.92523    -112.398895\n","    -36.562943 ]]\n","Epoch 1500, Loss: 0.0000, Predicted Index: 7\n","Output: [[-1.0881154e+02  7.6819382e+01 -4.7263294e+01  5.4476341e+01\n","  -1.2741230e+03 -2.8579510e+01 -1.7965019e+02  2.0372825e+03\n","  -1.1009636e+00  1.3205917e+01 -1.3155701e+01  1.1871330e+01\n","   2.2774361e+01 -1.1613963e+02 -7.4697327e+01  1.4117844e+01\n","   1.1351542e+02 -1.4107120e+02  1.2124405e+00  2.8127266e+01\n","  -1.9964357e+02  1.5211937e+01 -2.4987726e+02 -2.1361160e+02\n","  -1.0451813e+02 -2.5604158e+01]]\n","Epoch 1600, Loss: 0.0000, Predicted Index: 7\n","Output: [[-1.07365456e+02  9.35181732e+01 -5.17262421e+01  6.79128113e+01\n","  -1.24917603e+03 -2.00965309e+01 -1.81729401e+02  2.02154883e+03\n","  -2.98097992e+00  7.88230896e+00 -1.41721268e+01  1.11241150e+00\n","   2.70058002e+01 -1.07857857e+02 -7.61873322e+01  1.45564423e+01\n","   1.32615814e+02 -1.41079987e+02 -6.55921936e-01  4.84330750e+01\n","  -2.04868805e+02  1.60635605e+01 -2.75129425e+02 -2.26480957e+02\n","  -1.07372978e+02 -1.85679836e+01]]\n","Epoch 1700, Loss: 0.0000, Predicted Index: 7\n","Output: [[ 3.70810974e+02  5.52252319e+02  8.24690918e+02 -1.05319824e+02\n","  -1.23801152e+04  8.85934875e+02  5.71848816e+02  1.46613047e+04\n","   3.98134552e+02 -1.16184631e+03  3.25000824e+02  3.18031189e+02\n","  -2.05453857e+02 -4.88909912e+02 -3.67918518e+02 -1.26629776e+02\n","   2.98742249e+02  2.00853882e+01 -5.35718628e+02 -2.76962280e+01\n","  -7.56422348e+01 -9.37707275e+02 -2.93864746e+01  2.68435181e+02\n","   2.27819824e+00 -3.82349121e+02]]\n","Epoch 1800, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -100.033676     94.623       -44.24636      36.000095  -1408.5354\n","    -86.14888    -233.44397    2183.9773      -34.64765       9.115913\n","    -16.395748     27.339775     28.37842    -103.50568     -65.956696\n","    -26.393646    126.0795     -184.90228      29.396412     11.575714\n","   -241.29474      44.48265    -289.99713    -232.5529     -117.55719\n","      6.6681128]]\n","Epoch 1900, Loss: 0.0000, Predicted Index: 7\n","Output: [[ -116.156166     75.307655    -47.657997     48.050037  -1398.5891\n","    -43.692535   -198.97908    2212.7498       -4.89769      16.606972\n","    -13.977435     21.077019     22.783722   -127.3629      -77.93275\n","      9.088242    112.50403    -157.4043        6.3929634    16.168522\n","   -216.86815      19.993406   -259.02728    -224.22153    -112.215096\n","    -26.843367 ]]\n","Epoch 2000, Loss: 0.0000, Predicted Index: 7\n","Output: [[  3657.1604    3248.9714    6287.088    -1083.044   -79744.43\n","    6622.22      5809.6636   90593.375     3118.4434   -8531.75\n","    2278.7104    2136.4307   -1671.8054   -2750.9966   -2204.0586\n","   -1230.2302    1217.1278     949.3028   -3949.8442    -502.82788\n","     716.23267  -6571.6436    1500.4756    3361.126      722.5932\n","   -2564.5168 ]]\n","Epoch 2100, Loss: 0.0000, Predicted Index: 7\n","Output: [[  1250.1282    1155.3008    2173.7615    -340.91815 -28479.742\n","    2317.9243    2001.5876   32625.648     1126.1385   -2989.7532\n","     774.25916    741.2814    -575.9301   -1029.9464    -811.5974\n","    -437.0384     463.46298    250.1505   -1393.4948    -161.09308\n","     141.83533  -2277.016      402.22034   1064.2291     201.15915\n","    -912.32275]]\n","Epoch 2200, Loss: 0.0000, Predicted Index: 7\n","Output: [[  3516.9873    2904.209     5775.375     -912.1279  -72391.32\n","    6226.04      5689.534    81959.766     3030.105    -7905.862\n","    2023.6154    1866.1162   -1546.7981   -2497.0552   -2025.9985\n","   -1192.7292    1046.6279     883.0989   -3708.4436    -416.83105\n","     696.1446   -5974.087     1408.814     3108.6277     707.1942\n","   -2362.479  ]]\n","Epoch 2300, Loss: 0.0000, Predicted Index: 7\n","Output: [[  2978.1655    2409.382     4833.3853    -739.7846  -60778.867\n","    5239.599     4826.329    68855.67      2592.0798   -6639.6006\n","    1667.427     1554.7905   -1301.9357   -2116.0085   -1720.2341\n","   -1037.829      865.42065    686.9481   -3127.043     -357.21875\n","     535.76624  -4968.6836    1144.5535    2562.9287     579.91705\n","   -1988.3029 ]]\n","Epoch 2400, Loss: 0.0000, Predicted Index: 7\n","Output: [[  2381.2627    1910.167     3815.05      -569.8895  -48059.13\n","    4129.8535    3821.888    54467.        2055.5703   -5258.449\n","    1295.5892    1220.3021   -1025.9509   -1664.7705   -1372.1034\n","    -872.8762     698.5276     493.65106  -2468.1978    -290.6582\n","     373.6224   -3872.1284     842.30835   1985.269      443.10455\n","   -1555.6475 ]]\n","Epoch 2500, Loss: 0.0000, Predicted Index: 7\n","Output: [[-1.15426704e+02  8.38605118e+01 -5.34320450e+01  7.39377899e+01\n","  -1.24420288e+03  1.13164520e+00 -1.64496964e+02  2.03593518e+03\n","   1.18939896e+01  1.16278381e+01 -1.29629574e+01 -2.01898956e+00\n","   2.42084503e+01 -1.19786461e+02 -8.21753540e+01  3.22973938e+01\n","   1.25828072e+02 -1.27330986e+02 -1.21576500e+01  5.07294998e+01\n","  -1.92655518e+02  3.81892776e+00 -2.59644501e+02 -2.22315292e+02\n","  -1.04701950e+02 -3.53237305e+01]]\n","Epoch 2600, Loss: 0.0000, Predicted Index: 7\n","Output: [[   829.14075     720.4404     1344.1935     -153.07416  -17840.879\n","    1508.0975     1350.6306    20493.492       777.5236    -1903.168\n","     445.76233     422.90326    -359.54688    -658.2411     -535.43445\n","    -312.8997      305.12003     106.50174    -908.52045     -66.1142\n","      32.089233  -1381.725       169.07153     598.9623      109.24065\n","    -573.06256 ]]\n","Epoch 2700, Loss: 0.0000, Predicted Index: 7\n","Output: [[-1.25663483e+02  4.89511566e+01 -4.49008636e+01  4.06385612e+01\n","  -1.41856299e+03 -3.09473572e+01 -1.79667496e+02  2.24286987e+03\n","   1.18572998e+01  2.56760864e+01 -1.17518463e+01  2.87045517e+01\n","   1.57549343e+01 -1.47573273e+02 -8.24307251e+01  2.63906250e+01\n","   8.66159363e+01 -1.43646530e+02 -3.24040985e+00 -1.84084320e+00\n","  -1.99429596e+02  6.89716911e+00 -2.18290222e+02 -2.07186493e+02\n","  -1.06689186e+02 -5.06352730e+01]]\n","Epoch 2800, Loss: 0.0000, Predicted Index: 7\n","Output: [[ 8.84802063e+02  8.03649902e+02  1.43367151e+03 -1.07293289e+02\n","  -1.92795938e+04  1.68987097e+03  1.49009448e+03  2.22702305e+04\n","   8.72103149e+02 -2.06337891e+03  4.71495789e+02  4.17802979e+02\n","  -3.82010803e+02 -7.20223145e+02 -6.08108643e+02 -3.16528564e+02\n","   3.77551056e+02  1.12419624e+02 -1.01392548e+03 -1.46411133e+01\n","   1.35311127e+01 -1.48839282e+03  1.08114746e+02  5.89006287e+02\n","   1.01759674e+02 -6.30698730e+02]]\n","Epoch 2900, Loss: 0.0000, Predicted Index: 7\n","Output: [[  2034.87      1513.2572    3075.5964    -394.89624 -38345.766\n","    3407.0518    3304.9458   43320.74      1770.9961   -4299.1753\n","     986.54645    913.21625   -838.14246  -1326.5198   -1120.3295\n","    -769.8195     547.5176     356.47852  -2048.092     -187.83423\n","     264.12335  -3040.854      630.6211    1568.949      353.8106\n","   -1222.9717 ]]\n","\n","üß† Testing Phase\n","‚Üí Recognition Accuracy (Clean Only): 100.00% (400/400)\n","\n","Recognition Accuracy Across Noise Levels:\n","Noise 0% ‚Üí Accuracy: 100.00% (500/500)\n","Noise 3% ‚Üí Accuracy: 98.00% (490/500)\n","Noise 6% ‚Üí Accuracy: 97.00% (485/500)\n","Noise 9% ‚Üí Accuracy: 97.40% (487/500)\n","Noise 12% ‚Üí Accuracy: 96.20% (481/500)\n","Noise 14% ‚Üí Accuracy: 95.60% (478/500)\n","Noise 17% ‚Üí Accuracy: 95.00% (475/500)\n","Noise 20% ‚Üí Accuracy: 97.60% (488/500)\n","\n","Black Pixel Retention Across Noise Levels (Averaged):\n","Noise 0% ‚Üí Avg Retention: 100.00% (avg 17/17)\n","Noise 3% ‚Üí Avg Retention: 97.59% (avg 16/17)\n","Noise 6% ‚Üí Avg Retention: 94.15% (avg 16/17)\n","Noise 9% ‚Üí Avg Retention: 90.62% (avg 15/17)\n","Noise 12% ‚Üí Avg Retention: 88.09% (avg 14/17)\n","Noise 14% ‚Üí Avg Retention: 85.06% (avg 14/17)\n","Noise 17% ‚Üí Avg Retention: 83.18% (avg 14/17)\n","Noise 20% ‚Üí Avg Retention: 80.26% (avg 13/17)\n","\n","üß™ Pixel-wise Fidelity Across Noise Levels:\n","Noise 0% ‚Üí Fidelity: 100.00%\n","Noise 3% ‚Üí Fidelity: 97.26%\n","Noise 6% ‚Üí Fidelity: 93.86%\n","Noise 9% ‚Üí Fidelity: 90.85%\n","Noise 12% ‚Üí Fidelity: 88.11%\n","Noise 14% ‚Üí Fidelity: 86.26%\n","Noise 17% ‚Üí Fidelity: 83.01%\n","Noise 20% ‚Üí Fidelity: 79.58%\n"]}]}]}